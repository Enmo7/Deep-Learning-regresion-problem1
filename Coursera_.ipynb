{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "oe2C5jvxh7Pv"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "hidden": true,
        "id": "9t0iRIU2fROa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "hidden": true,
        "id": "5_GIWhAHhRnT"
      },
      "outputs": [],
      "source": [
        "from keras import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "676UIcVPikxN"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "hidden": true,
        "id": "BU5JnbcFiiDy",
        "outputId": "932be2fc-9040-4cb4-d778-8cb803029fa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "0      540.0                 0.0      0.0  162.0               2.5   \n",
              "1      540.0                 0.0      0.0  162.0               2.5   \n",
              "2      332.5               142.5      0.0  228.0               0.0   \n",
              "3      332.5               142.5      0.0  228.0               0.0   \n",
              "4      198.6               132.4      0.0  192.0               0.0   \n",
              "...      ...                 ...      ...    ...               ...   \n",
              "1025   276.4               116.0     90.3  179.6               8.9   \n",
              "1026   322.2                 0.0    115.6  196.0              10.4   \n",
              "1027   148.5               139.4    108.6  192.7               6.1   \n",
              "1028   159.1               186.7      0.0  175.6              11.3   \n",
              "1029   260.9               100.5     78.3  200.6               8.6   \n",
              "\n",
              "      Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
              "0               1040.0           676.0   28     79.99  \n",
              "1               1055.0           676.0   28     61.89  \n",
              "2                932.0           594.0  270     40.27  \n",
              "3                932.0           594.0  365     41.05  \n",
              "4                978.4           825.5  360     44.30  \n",
              "...                ...             ...  ...       ...  \n",
              "1025             870.1           768.3   28     44.28  \n",
              "1026             817.9           813.4   28     31.18  \n",
              "1027             892.4           780.0   28     23.70  \n",
              "1028             989.6           788.9   28     32.77  \n",
              "1029             864.5           761.5   28     32.40  \n",
              "\n",
              "[1030 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee3e8b85-c3e0-475d-86f0-05c3c5a0f0d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>276.4</td>\n",
              "      <td>116.0</td>\n",
              "      <td>90.3</td>\n",
              "      <td>179.6</td>\n",
              "      <td>8.9</td>\n",
              "      <td>870.1</td>\n",
              "      <td>768.3</td>\n",
              "      <td>28</td>\n",
              "      <td>44.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>322.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.6</td>\n",
              "      <td>196.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>817.9</td>\n",
              "      <td>813.4</td>\n",
              "      <td>28</td>\n",
              "      <td>31.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>148.5</td>\n",
              "      <td>139.4</td>\n",
              "      <td>108.6</td>\n",
              "      <td>192.7</td>\n",
              "      <td>6.1</td>\n",
              "      <td>892.4</td>\n",
              "      <td>780.0</td>\n",
              "      <td>28</td>\n",
              "      <td>23.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>159.1</td>\n",
              "      <td>186.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>175.6</td>\n",
              "      <td>11.3</td>\n",
              "      <td>989.6</td>\n",
              "      <td>788.9</td>\n",
              "      <td>28</td>\n",
              "      <td>32.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>260.9</td>\n",
              "      <td>100.5</td>\n",
              "      <td>78.3</td>\n",
              "      <td>200.6</td>\n",
              "      <td>8.6</td>\n",
              "      <td>864.5</td>\n",
              "      <td>761.5</td>\n",
              "      <td>28</td>\n",
              "      <td>32.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1030 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee3e8b85-c3e0-475d-86f0-05c3c5a0f0d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee3e8b85-c3e0-475d-86f0-05c3c5a0f0d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee3e8b85-c3e0-475d-86f0-05c3c5a0f0d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/sample_data/concrete_data.csv\")\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "hidden": true,
        "id": "07zYGyNamhWd",
        "outputId": "2e42d34f-c02f-4404-c3bd-2adae11cab05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "0      540.0                 0.0      0.0  162.0               2.5   \n",
              "1      540.0                 0.0      0.0  162.0               2.5   \n",
              "2      332.5               142.5      0.0  228.0               0.0   \n",
              "3      332.5               142.5      0.0  228.0               0.0   \n",
              "4      198.6               132.4      0.0  192.0               0.0   \n",
              "...      ...                 ...      ...    ...               ...   \n",
              "1025   276.4               116.0     90.3  179.6               8.9   \n",
              "1026   322.2                 0.0    115.6  196.0              10.4   \n",
              "1027   148.5               139.4    108.6  192.7               6.1   \n",
              "1028   159.1               186.7      0.0  175.6              11.3   \n",
              "1029   260.9               100.5     78.3  200.6               8.6   \n",
              "\n",
              "      Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
              "0               1040.0           676.0   28     79.99  \n",
              "1               1055.0           676.0   28     61.89  \n",
              "2                932.0           594.0  270     40.27  \n",
              "3                932.0           594.0  365     41.05  \n",
              "4                978.4           825.5  360     44.30  \n",
              "...                ...             ...  ...       ...  \n",
              "1025             870.1           768.3   28     44.28  \n",
              "1026             817.9           813.4   28     31.18  \n",
              "1027             892.4           780.0   28     23.70  \n",
              "1028             989.6           788.9   28     32.77  \n",
              "1029             864.5           761.5   28     32.40  \n",
              "\n",
              "[1030 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94c50530-0ad9-46ff-b492-ceb223e162af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>276.4</td>\n",
              "      <td>116.0</td>\n",
              "      <td>90.3</td>\n",
              "      <td>179.6</td>\n",
              "      <td>8.9</td>\n",
              "      <td>870.1</td>\n",
              "      <td>768.3</td>\n",
              "      <td>28</td>\n",
              "      <td>44.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>322.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.6</td>\n",
              "      <td>196.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>817.9</td>\n",
              "      <td>813.4</td>\n",
              "      <td>28</td>\n",
              "      <td>31.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>148.5</td>\n",
              "      <td>139.4</td>\n",
              "      <td>108.6</td>\n",
              "      <td>192.7</td>\n",
              "      <td>6.1</td>\n",
              "      <td>892.4</td>\n",
              "      <td>780.0</td>\n",
              "      <td>28</td>\n",
              "      <td>23.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>159.1</td>\n",
              "      <td>186.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>175.6</td>\n",
              "      <td>11.3</td>\n",
              "      <td>989.6</td>\n",
              "      <td>788.9</td>\n",
              "      <td>28</td>\n",
              "      <td>32.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>260.9</td>\n",
              "      <td>100.5</td>\n",
              "      <td>78.3</td>\n",
              "      <td>200.6</td>\n",
              "      <td>8.6</td>\n",
              "      <td>864.5</td>\n",
              "      <td>761.5</td>\n",
              "      <td>28</td>\n",
              "      <td>32.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1030 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94c50530-0ad9-46ff-b492-ceb223e162af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94c50530-0ad9-46ff-b492-ceb223e162af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94c50530-0ad9-46ff-b492-ceb223e162af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# we will copy the data to new dataframe to use it.\n",
        "df = data.copy()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "nm99uEWblOzi"
      },
      "source": [
        "# Split the Data to train & test & Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "KPHyjH66l5BZ",
        "outputId": "4f9b15ec-9430-4010-8174-50ce69125449"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       79.99\n",
              "1       61.89\n",
              "2       40.27\n",
              "3       41.05\n",
              "4       44.30\n",
              "        ...  \n",
              "1025    44.28\n",
              "1026    31.18\n",
              "1027    23.70\n",
              "1028    32.77\n",
              "1029    32.40\n",
              "Name: Strength, Length: 1030, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# we will split first the data into x & y\n",
        "# y is the target column\n",
        "y = df['Strength']\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "WIRFLGXLpR-j",
        "outputId": "e6fd7fd1-f1b9-4d90-981c-74fe3e4a9e77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1030,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Look at y\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "hidden": true,
        "id": "PwyaMgLQnE7b",
        "outputId": "2e14be8b-fbd7-47b4-f54c-d37bb2c45f7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "0      540.0                 0.0      0.0  162.0               2.5   \n",
              "1      540.0                 0.0      0.0  162.0               2.5   \n",
              "2      332.5               142.5      0.0  228.0               0.0   \n",
              "3      332.5               142.5      0.0  228.0               0.0   \n",
              "4      198.6               132.4      0.0  192.0               0.0   \n",
              "...      ...                 ...      ...    ...               ...   \n",
              "1025   276.4               116.0     90.3  179.6               8.9   \n",
              "1026   322.2                 0.0    115.6  196.0              10.4   \n",
              "1027   148.5               139.4    108.6  192.7               6.1   \n",
              "1028   159.1               186.7      0.0  175.6              11.3   \n",
              "1029   260.9               100.5     78.3  200.6               8.6   \n",
              "\n",
              "      Coarse Aggregate  Fine Aggregate  Age  \n",
              "0               1040.0           676.0   28  \n",
              "1               1055.0           676.0   28  \n",
              "2                932.0           594.0  270  \n",
              "3                932.0           594.0  365  \n",
              "4                978.4           825.5  360  \n",
              "...                ...             ...  ...  \n",
              "1025             870.1           768.3   28  \n",
              "1026             817.9           813.4   28  \n",
              "1027             892.4           780.0   28  \n",
              "1028             989.6           788.9   28  \n",
              "1029             864.5           761.5   28  \n",
              "\n",
              "[1030 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-780781ff-8147-46c8-8dbc-20d2ef62e7b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>276.4</td>\n",
              "      <td>116.0</td>\n",
              "      <td>90.3</td>\n",
              "      <td>179.6</td>\n",
              "      <td>8.9</td>\n",
              "      <td>870.1</td>\n",
              "      <td>768.3</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>322.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.6</td>\n",
              "      <td>196.0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>817.9</td>\n",
              "      <td>813.4</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>148.5</td>\n",
              "      <td>139.4</td>\n",
              "      <td>108.6</td>\n",
              "      <td>192.7</td>\n",
              "      <td>6.1</td>\n",
              "      <td>892.4</td>\n",
              "      <td>780.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>159.1</td>\n",
              "      <td>186.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>175.6</td>\n",
              "      <td>11.3</td>\n",
              "      <td>989.6</td>\n",
              "      <td>788.9</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>260.9</td>\n",
              "      <td>100.5</td>\n",
              "      <td>78.3</td>\n",
              "      <td>200.6</td>\n",
              "      <td>8.6</td>\n",
              "      <td>864.5</td>\n",
              "      <td>761.5</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1030 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-780781ff-8147-46c8-8dbc-20d2ef62e7b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-780781ff-8147-46c8-8dbc-20d2ef62e7b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-780781ff-8147-46c8-8dbc-20d2ef62e7b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x = df.drop('Strength' , axis = 1)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "w98VXZBXpZum",
        "outputId": "46e4b9ba-0540-4c76-a3c8-e89b9b550522"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1030, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Look at x.\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "hidden": true,
        "id": "G331PnAtkUqg"
      },
      "outputs": [],
      "source": [
        "# second we will take 20% from the data to x_test & y_test Randomly.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "7NptsN8koNYh",
        "outputId": "3a19be37-2134-4ce2-8691-c61361669c7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((824, 8), (206, 8), (824,), (206,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Look at the shape.\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "hidden": true,
        "id": "DB0cwe9kqExL"
      },
      "outputs": [],
      "source": [
        "# Third split x_train & y_train into x_valid, y_valid & xnew_train, ynew_train.\n",
        "# we will use it after splitting in the model.\n",
        "xnew_train, x_valid, ynew_train, y_valid = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "Cvm6FGlArgqh",
        "outputId": "df5db9d1-7516-4d6a-8b0f-1ec80f5c8e3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((576, 8), (248, 8), (576,), (248,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Look at the shape.\n",
        "xnew_train.shape, x_valid.shape, ynew_train.shape, y_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "9fnHf7CisLvT"
      },
      "source": [
        "Look at the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "hidden": true,
        "id": "sXiPRWcLrrnn",
        "outputId": "1659e5d4-c5d6-46fc-dbfb-2bc2322d594f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "214   190.3                 0.0    125.2  161.9               9.9   \n",
              "225   168.0                42.1    163.8  121.8               5.7   \n",
              "15    380.0                 0.0      0.0  228.0               0.0   \n",
              "439   173.8                93.4    159.9  172.3               9.7   \n",
              "341   297.2                 0.0    117.5  174.8               9.5   \n",
              "..      ...                 ...      ...    ...               ...   \n",
              "319   249.1                 0.0     98.8  158.1              12.8   \n",
              "526   359.0                19.0    141.0  154.0              10.9   \n",
              "285   181.4                 0.0    167.0  169.6               7.6   \n",
              "743   397.0                 0.0      0.0  186.0               0.0   \n",
              "357   277.2                97.8     24.5  160.7              11.2   \n",
              "\n",
              "     Coarse Aggregate  Fine Aggregate  Age  \n",
              "214            1088.1           802.6    3  \n",
              "225            1058.7           780.1   14  \n",
              "15              932.0           670.0   90  \n",
              "439            1007.2           746.6   28  \n",
              "341            1022.8           753.5   28  \n",
              "..                ...             ...  ...  \n",
              "319             987.8           889.0    3  \n",
              "526             942.0           801.0    3  \n",
              "285            1055.6           777.8   14  \n",
              "743            1040.0           734.0   28  \n",
              "357            1061.7           782.5   56  \n",
              "\n",
              "[576 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceeef0b5-d6aa-4488-875c-d00f83ac860c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>190.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>125.2</td>\n",
              "      <td>161.9</td>\n",
              "      <td>9.9</td>\n",
              "      <td>1088.1</td>\n",
              "      <td>802.6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>168.0</td>\n",
              "      <td>42.1</td>\n",
              "      <td>163.8</td>\n",
              "      <td>121.8</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1058.7</td>\n",
              "      <td>780.1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>380.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>670.0</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>173.8</td>\n",
              "      <td>93.4</td>\n",
              "      <td>159.9</td>\n",
              "      <td>172.3</td>\n",
              "      <td>9.7</td>\n",
              "      <td>1007.2</td>\n",
              "      <td>746.6</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>297.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.5</td>\n",
              "      <td>174.8</td>\n",
              "      <td>9.5</td>\n",
              "      <td>1022.8</td>\n",
              "      <td>753.5</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>249.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.8</td>\n",
              "      <td>158.1</td>\n",
              "      <td>12.8</td>\n",
              "      <td>987.8</td>\n",
              "      <td>889.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>359.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>10.9</td>\n",
              "      <td>942.0</td>\n",
              "      <td>801.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>181.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>169.6</td>\n",
              "      <td>7.6</td>\n",
              "      <td>1055.6</td>\n",
              "      <td>777.8</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>397.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>734.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>277.2</td>\n",
              "      <td>97.8</td>\n",
              "      <td>24.5</td>\n",
              "      <td>160.7</td>\n",
              "      <td>11.2</td>\n",
              "      <td>1061.7</td>\n",
              "      <td>782.5</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>576 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceeef0b5-d6aa-4488-875c-d00f83ac860c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ceeef0b5-d6aa-4488-875c-d00f83ac860c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ceeef0b5-d6aa-4488-875c-d00f83ac860c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "xnew_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "hidden": true,
        "id": "dwLT7z8wstzP",
        "outputId": "eb1b25a8-1da0-43ca-9ecc-9fe7258d0f8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "224   168.0                42.1    163.8  121.8               5.7   \n",
              "125   531.3                 0.0      0.0  141.8              28.2   \n",
              "601   339.0                 0.0      0.0  197.0               0.0   \n",
              "572   220.8               147.2      0.0  185.7               0.0   \n",
              "12    427.5                47.5      0.0  228.0               0.0   \n",
              "..      ...                 ...      ...    ...               ...   \n",
              "273   231.8                 0.0    121.6  174.0               6.7   \n",
              "20    427.5                47.5      0.0  228.0               0.0   \n",
              "228   168.0                42.1    163.8  121.8               5.7   \n",
              "386   528.0                 0.0      0.0  185.0               6.9   \n",
              "773   382.0                 0.0      0.0  186.0               0.0   \n",
              "\n",
              "     Coarse Aggregate  Fine Aggregate  Age  \n",
              "224            1058.7           780.1    3  \n",
              "125             852.1           893.7   28  \n",
              "601             968.0           781.0   28  \n",
              "572            1055.0           744.3    7  \n",
              "12              932.0           594.0  270  \n",
              "..                ...             ...  ...  \n",
              "273            1056.4           778.5  100  \n",
              "20              932.0           594.0  180  \n",
              "228            1058.7           780.1  100  \n",
              "386             920.0           720.0   28  \n",
              "773            1047.0           739.0   28  \n",
              "\n",
              "[248 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94bf37ca-9e19-4e0d-bb66-e24638c499e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>168.0</td>\n",
              "      <td>42.1</td>\n",
              "      <td>163.8</td>\n",
              "      <td>121.8</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1058.7</td>\n",
              "      <td>780.1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>531.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>141.8</td>\n",
              "      <td>28.2</td>\n",
              "      <td>852.1</td>\n",
              "      <td>893.7</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>339.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>968.0</td>\n",
              "      <td>781.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>220.8</td>\n",
              "      <td>147.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>185.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>744.3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>427.5</td>\n",
              "      <td>47.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>231.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>121.6</td>\n",
              "      <td>174.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>1056.4</td>\n",
              "      <td>778.5</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>427.5</td>\n",
              "      <td>47.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>168.0</td>\n",
              "      <td>42.1</td>\n",
              "      <td>163.8</td>\n",
              "      <td>121.8</td>\n",
              "      <td>5.7</td>\n",
              "      <td>1058.7</td>\n",
              "      <td>780.1</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>528.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>920.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>382.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1047.0</td>\n",
              "      <td>739.0</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>248 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94bf37ca-9e19-4e0d-bb66-e24638c499e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94bf37ca-9e19-4e0d-bb66-e24638c499e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94bf37ca-9e19-4e0d-bb66-e24638c499e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "x_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "eP4UfXVusuQL",
        "outputId": "452b8ef4-fd85-4024-fae7-8529b0910849"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "214     9.45\n",
              "225    17.82\n",
              "15     52.91\n",
              "439    37.81\n",
              "341    47.40\n",
              "       ...  \n",
              "319    15.36\n",
              "526    23.64\n",
              "285    21.60\n",
              "743    36.94\n",
              "357    66.82\n",
              "Name: Strength, Length: 576, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "ynew_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "KL-rgVMnsxj6",
        "outputId": "b5c0944b-666f-48e3-9387-54857087c2f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224     7.75\n",
              "125    56.40\n",
              "601    32.04\n",
              "572    13.09\n",
              "12     43.01\n",
              "       ...  \n",
              "273    45.84\n",
              "20     41.84\n",
              "228    39.23\n",
              "386    56.83\n",
              "773    37.42\n",
              "Name: Strength, Length: 248, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_valid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "84fJ1pjds2s8"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize"
      ],
      "metadata": {
        "id": "YOOxuH-SE51M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "header = list(data.columns.values)\n",
        "for name in header:\n",
        "  data[[name]] =  (data[[name]] - data[[name]].mean())/ (data[[name]].std())\n"
      ],
      "metadata": {
        "id": "L4DSdMNvKMIa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LSyBM7C6KQzG",
        "outputId": "7420cec9-d177-4789-cf72-b68f04f4da71"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
              "0     2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "1     2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
              "2     0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "3     0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
              "4    -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
              "...        ...                 ...       ...       ...               ...   \n",
              "1025 -0.045623            0.487998  0.564271 -0.092126          0.451190   \n",
              "1026  0.392628           -0.856472  0.959602  0.675872          0.702285   \n",
              "1027 -1.269472            0.759210  0.850222  0.521336         -0.017520   \n",
              "1028 -1.168042            1.307430 -0.846733 -0.279443          0.852942   \n",
              "1029 -0.193939            0.308349  0.376762  0.891286          0.400971   \n",
              "\n",
              "      Coarse Aggregate  Fine Aggregate       Age  Strength  \n",
              "0             0.862735       -1.217079 -0.279597  2.644123  \n",
              "1             1.055651       -1.217079 -0.279597  1.560663  \n",
              "2            -0.526262       -2.239829  3.551340  0.266498  \n",
              "3            -0.526262       -2.239829  5.055221  0.313188  \n",
              "4             0.070492        0.647569  4.976069  0.507732  \n",
              "...                ...             ...       ...       ...  \n",
              "1025         -1.322363       -0.065861 -0.279597  0.506535  \n",
              "1026         -1.993711        0.496651 -0.279597 -0.277627  \n",
              "1027         -1.035561        0.080068 -0.279597 -0.725377  \n",
              "1028          0.214537        0.191074 -0.279597 -0.182450  \n",
              "1029         -1.394385       -0.150675 -0.279597 -0.204598  \n",
              "\n",
              "[1030 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bfa84c2-1944-4f90-a140-e351cabd674f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>0.862735</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "      <td>2.644123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.476712</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.916319</td>\n",
              "      <td>-0.620147</td>\n",
              "      <td>1.055651</td>\n",
              "      <td>-1.217079</td>\n",
              "      <td>-0.279597</td>\n",
              "      <td>1.560663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>3.551340</td>\n",
              "      <td>0.266498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491187</td>\n",
              "      <td>0.795140</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>2.174405</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>-0.526262</td>\n",
              "      <td>-2.239829</td>\n",
              "      <td>5.055221</td>\n",
              "      <td>0.313188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.790075</td>\n",
              "      <td>0.678079</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>0.488555</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>0.070492</td>\n",
              "      <td>0.647569</td>\n",
              "      <td>4.976069</td>\n",
              "      <td>0.507732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>-0.045623</td>\n",
              "      <td>0.487998</td>\n",
              "      <td>0.564271</td>\n",
              "      <td>-0.092126</td>\n",
              "      <td>0.451190</td>\n",
              "      <td>-1.322363</td>\n",
              "      <td>-0.065861</td>\n",
              "      <td>-0.279597</td>\n",
              "      <td>0.506535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>0.392628</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>0.959602</td>\n",
              "      <td>0.675872</td>\n",
              "      <td>0.702285</td>\n",
              "      <td>-1.993711</td>\n",
              "      <td>0.496651</td>\n",
              "      <td>-0.279597</td>\n",
              "      <td>-0.277627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>-1.269472</td>\n",
              "      <td>0.759210</td>\n",
              "      <td>0.850222</td>\n",
              "      <td>0.521336</td>\n",
              "      <td>-0.017520</td>\n",
              "      <td>-1.035561</td>\n",
              "      <td>0.080068</td>\n",
              "      <td>-0.279597</td>\n",
              "      <td>-0.725377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>-1.168042</td>\n",
              "      <td>1.307430</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>-0.279443</td>\n",
              "      <td>0.852942</td>\n",
              "      <td>0.214537</td>\n",
              "      <td>0.191074</td>\n",
              "      <td>-0.279597</td>\n",
              "      <td>-0.182450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1029</th>\n",
              "      <td>-0.193939</td>\n",
              "      <td>0.308349</td>\n",
              "      <td>0.376762</td>\n",
              "      <td>0.891286</td>\n",
              "      <td>0.400971</td>\n",
              "      <td>-1.394385</td>\n",
              "      <td>-0.150675</td>\n",
              "      <td>-0.279597</td>\n",
              "      <td>-0.204598</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1030 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bfa84c2-1944-4f90-a140-e351cabd674f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bfa84c2-1944-4f90-a140-e351cabd674f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bfa84c2-1944-4f90-a140-e351cabd674f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "hidden": true,
        "id": "g8ajmBVEs0NC"
      },
      "outputs": [],
      "source": [
        "#  Design Model\n",
        "\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "hidden": true,
        "id": "3m08QQV3tPG8"
      },
      "outputs": [],
      "source": [
        "# Define Sequential model with 1 hidden layers\n",
        "\n",
        "tf.random.set_seed(500)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [  \n",
        "        layers.InputLayer(input_shape=(8,)),\n",
        "        layers.Dense(10, activation=\"relu\", name=\"hiddenlayer1\"),\n",
        "        layers.Dense(10, activation=\"relu\", name=\"hiddenlayer2\"),\n",
        "        layers.Dense(10, activation=\"relu\", name=\"hiddenlayer3\"),\n",
        "        layers.Dense(1, name=\"outputlayer\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "4lIiYEN4uPVI",
        "outputId": "553b6588-71bc-4683-8ad4-ed73e91de6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hiddenlayer1 (Dense)        (None, 10)                90        \n",
            "                                                                 \n",
            " hiddenlayer2 (Dense)        (None, 10)                110       \n",
            "                                                                 \n",
            " hiddenlayer3 (Dense)        (None, 10)                110       \n",
            "                                                                 \n",
            " outputlayer (Dense)         (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Look at model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "hidden": true,
        "id": "-SRovLtcuZlz",
        "outputId": "a19d428f-da7d-4b0a-c89c-b18fe47121b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file= 'model_plot.png', show_shapes = True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "hidden": true,
        "id": "8JUF0AK1vDVF"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "ykseGF7K6CF6",
        "outputId": "83a834db-e1be-4633-cd1d-8b3266d6b93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "18/18 [==============================] - 2s 31ms/step - loss: 68250.9375 - accuracy: 0.0000e+00 - val_loss: 38701.3984 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 20299.6836 - accuracy: 0.0000e+00 - val_loss: 5761.3379 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1857.2515 - accuracy: 0.0000e+00 - val_loss: 678.0529 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 755.0232 - accuracy: 0.0000e+00 - val_loss: 576.2147 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 443.9942 - accuracy: 0.0000e+00 - val_loss: 381.7224 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 379.0140 - accuracy: 0.0000e+00 - val_loss: 344.0259 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 337.4313 - accuracy: 0.0000e+00 - val_loss: 319.6487 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 309.9518 - accuracy: 0.0000e+00 - val_loss: 295.3521 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 288.7935 - accuracy: 0.0000e+00 - val_loss: 277.5067 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 270.6295 - accuracy: 0.0000e+00 - val_loss: 262.5828 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 256.9549 - accuracy: 0.0000e+00 - val_loss: 250.5781 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 245.4311 - accuracy: 0.0000e+00 - val_loss: 242.8099 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 235.9170 - accuracy: 0.0000e+00 - val_loss: 232.7013 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 226.3712 - accuracy: 0.0000e+00 - val_loss: 225.7538 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 218.6030 - accuracy: 0.0000e+00 - val_loss: 218.9978 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 211.8693 - accuracy: 0.0000e+00 - val_loss: 213.1154 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 205.2103 - accuracy: 0.0000e+00 - val_loss: 208.0327 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 199.6707 - accuracy: 0.0000e+00 - val_loss: 203.0173 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 196.0876 - accuracy: 0.0000e+00 - val_loss: 199.8325 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 190.8113 - accuracy: 0.0000e+00 - val_loss: 194.3369 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 186.3258 - accuracy: 0.0000e+00 - val_loss: 191.0402 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 180.9103 - accuracy: 0.0000e+00 - val_loss: 185.7291 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 177.3871 - accuracy: 0.0000e+00 - val_loss: 184.1668 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 173.5830 - accuracy: 0.0000e+00 - val_loss: 178.2652 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 171.2275 - accuracy: 0.0000e+00 - val_loss: 178.4065 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 166.4279 - accuracy: 0.0000e+00 - val_loss: 171.0263 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 163.3710 - accuracy: 0.0000e+00 - val_loss: 170.8925 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 166.8312 - accuracy: 0.0000e+00 - val_loss: 165.0939 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 158.3598 - accuracy: 0.0000e+00 - val_loss: 163.4654 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 155.5252 - accuracy: 0.0000e+00 - val_loss: 163.1715 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 153.6067 - accuracy: 0.0000e+00 - val_loss: 161.7789 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 150.1054 - accuracy: 0.0000e+00 - val_loss: 155.5278 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 146.9478 - accuracy: 0.0000e+00 - val_loss: 154.0402 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 145.2048 - accuracy: 0.0000e+00 - val_loss: 150.7203 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 142.6593 - accuracy: 0.0000e+00 - val_loss: 148.0665 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 140.6929 - accuracy: 0.0000e+00 - val_loss: 151.1558 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 139.4212 - accuracy: 0.0000e+00 - val_loss: 143.6475 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 137.2192 - accuracy: 0.0000e+00 - val_loss: 142.2492 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 134.6123 - accuracy: 0.0000e+00 - val_loss: 143.9498 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 134.3521 - accuracy: 0.0000e+00 - val_loss: 139.2426 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 131.1529 - accuracy: 0.0000e+00 - val_loss: 137.6822 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 130.3642 - accuracy: 0.0000e+00 - val_loss: 135.5540 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 128.3286 - accuracy: 0.0000e+00 - val_loss: 133.9013 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 126.0538 - accuracy: 0.0000e+00 - val_loss: 132.3554 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 125.3154 - accuracy: 0.0000e+00 - val_loss: 134.8943 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 123.7694 - accuracy: 0.0000e+00 - val_loss: 135.1590 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 122.4846 - accuracy: 0.0000e+00 - val_loss: 127.3891 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 120.3096 - accuracy: 0.0000e+00 - val_loss: 129.9982 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 118.8000 - accuracy: 0.0000e+00 - val_loss: 128.3226 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 117.4139 - accuracy: 0.0000e+00 - val_loss: 126.0113 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "model_training = model.fit(x=xnew_train, y=ynew_train, batch_size=32, validation_data=(x_valid, y_valid), verbose=1, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "hidden": true,
        "id": "2qV5m5go6Phn",
        "outputId": "e9dc7585-f527-4ae8-be5c-04d4f3a565b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            loss  accuracy      val_loss  val_accuracy\n",
              "0   68250.937500       0.0  38701.398438           0.0\n",
              "1   20299.683594       0.0   5761.337891           0.0\n",
              "2    1857.251465       0.0    678.052917           0.0\n",
              "3     755.023193       0.0    576.214661           0.0\n",
              "4     443.994232       0.0    381.722351           0.0\n",
              "5     379.014038       0.0    344.025909           0.0\n",
              "6     337.431274       0.0    319.648651           0.0\n",
              "7     309.951843       0.0    295.352112           0.0\n",
              "8     288.793549       0.0    277.506714           0.0\n",
              "9     270.629456       0.0    262.582764           0.0\n",
              "10    256.954926       0.0    250.578079           0.0\n",
              "11    245.431076       0.0    242.809891           0.0\n",
              "12    235.916992       0.0    232.701309           0.0\n",
              "13    226.371201       0.0    225.753799           0.0\n",
              "14    218.602966       0.0    218.997772           0.0\n",
              "15    211.869339       0.0    213.115433           0.0\n",
              "16    205.210312       0.0    208.032669           0.0\n",
              "17    199.670731       0.0    203.017349           0.0\n",
              "18    196.087585       0.0    199.832474           0.0\n",
              "19    190.811279       0.0    194.336929           0.0\n",
              "20    186.325821       0.0    191.040222           0.0\n",
              "21    180.910339       0.0    185.729095           0.0\n",
              "22    177.387146       0.0    184.166809           0.0\n",
              "23    173.583038       0.0    178.265198           0.0\n",
              "24    171.227524       0.0    178.406525           0.0\n",
              "25    166.427902       0.0    171.026260           0.0\n",
              "26    163.371033       0.0    170.892517           0.0\n",
              "27    166.831238       0.0    165.093887           0.0\n",
              "28    158.359756       0.0    163.465408           0.0\n",
              "29    155.525208       0.0    163.171463           0.0\n",
              "30    153.606735       0.0    161.778915           0.0\n",
              "31    150.105362       0.0    155.527817           0.0\n",
              "32    146.947815       0.0    154.040176           0.0\n",
              "33    145.204773       0.0    150.720261           0.0\n",
              "34    142.659302       0.0    148.066483           0.0\n",
              "35    140.692932       0.0    151.155777           0.0\n",
              "36    139.421219       0.0    143.647507           0.0\n",
              "37    137.219223       0.0    142.249207           0.0\n",
              "38    134.612289       0.0    143.949753           0.0\n",
              "39    134.352112       0.0    139.242569           0.0\n",
              "40    131.152893       0.0    137.682190           0.0\n",
              "41    130.364243       0.0    135.553986           0.0\n",
              "42    128.328598       0.0    133.901276           0.0\n",
              "43    126.053795       0.0    132.355392           0.0\n",
              "44    125.315445       0.0    134.894257           0.0\n",
              "45    123.769424       0.0    135.159012           0.0\n",
              "46    122.484650       0.0    127.389122           0.0\n",
              "47    120.309608       0.0    129.998230           0.0\n",
              "48    118.799995       0.0    128.322647           0.0\n",
              "49    117.413940       0.0    126.011314           0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5bd9a2c4-b6cf-4300-858e-865e4b728823\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>68250.937500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38701.398438</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20299.683594</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5761.337891</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1857.251465</td>\n",
              "      <td>0.0</td>\n",
              "      <td>678.052917</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>755.023193</td>\n",
              "      <td>0.0</td>\n",
              "      <td>576.214661</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>443.994232</td>\n",
              "      <td>0.0</td>\n",
              "      <td>381.722351</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>379.014038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>344.025909</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>337.431274</td>\n",
              "      <td>0.0</td>\n",
              "      <td>319.648651</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>309.951843</td>\n",
              "      <td>0.0</td>\n",
              "      <td>295.352112</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>288.793549</td>\n",
              "      <td>0.0</td>\n",
              "      <td>277.506714</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>270.629456</td>\n",
              "      <td>0.0</td>\n",
              "      <td>262.582764</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>256.954926</td>\n",
              "      <td>0.0</td>\n",
              "      <td>250.578079</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>245.431076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>242.809891</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>235.916992</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232.701309</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>226.371201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>225.753799</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>218.602966</td>\n",
              "      <td>0.0</td>\n",
              "      <td>218.997772</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>211.869339</td>\n",
              "      <td>0.0</td>\n",
              "      <td>213.115433</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>205.210312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>208.032669</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>199.670731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>203.017349</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>196.087585</td>\n",
              "      <td>0.0</td>\n",
              "      <td>199.832474</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>190.811279</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194.336929</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>186.325821</td>\n",
              "      <td>0.0</td>\n",
              "      <td>191.040222</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>180.910339</td>\n",
              "      <td>0.0</td>\n",
              "      <td>185.729095</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>177.387146</td>\n",
              "      <td>0.0</td>\n",
              "      <td>184.166809</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>173.583038</td>\n",
              "      <td>0.0</td>\n",
              "      <td>178.265198</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>171.227524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>178.406525</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>166.427902</td>\n",
              "      <td>0.0</td>\n",
              "      <td>171.026260</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>163.371033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>170.892517</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>166.831238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>165.093887</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>158.359756</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163.465408</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>155.525208</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163.171463</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>153.606735</td>\n",
              "      <td>0.0</td>\n",
              "      <td>161.778915</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>150.105362</td>\n",
              "      <td>0.0</td>\n",
              "      <td>155.527817</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>146.947815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>154.040176</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>145.204773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150.720261</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>142.659302</td>\n",
              "      <td>0.0</td>\n",
              "      <td>148.066483</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>140.692932</td>\n",
              "      <td>0.0</td>\n",
              "      <td>151.155777</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>139.421219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>143.647507</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>137.219223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>142.249207</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>134.612289</td>\n",
              "      <td>0.0</td>\n",
              "      <td>143.949753</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>134.352112</td>\n",
              "      <td>0.0</td>\n",
              "      <td>139.242569</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>131.152893</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.682190</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>130.364243</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.553986</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>128.328598</td>\n",
              "      <td>0.0</td>\n",
              "      <td>133.901276</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>126.053795</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.355392</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>125.315445</td>\n",
              "      <td>0.0</td>\n",
              "      <td>134.894257</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>123.769424</td>\n",
              "      <td>0.0</td>\n",
              "      <td>135.159012</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>122.484650</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.389122</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>120.309608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>129.998230</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>118.799995</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.322647</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>117.413940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>126.011314</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bd9a2c4-b6cf-4300-858e-865e4b728823')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5bd9a2c4-b6cf-4300-858e-865e4b728823 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5bd9a2c4-b6cf-4300-858e-865e4b728823');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# History\n",
        "pd.DataFrame(model_training.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "hidden": true,
        "id": "lIHEHow48iho",
        "outputId": "f071bdbd-1761-40b3-cc19-b7c1d50ce8df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ffa4d991690>]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot the Losses\n",
        "plt.plot(model_training.history['loss'])\n",
        "plt.plot(model_training.history['val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "PNHTVyZp9zJo",
        "outputId": "9f2dc1e2-c042-44a8-97e8-841278123011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Predection\n",
        "pred = model.predict(x_test).argmax(axis=-1)\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "yHx5pE-x8wGd",
        "outputId": "69a91ca6-1887-472f-e1e4-6e779cc3443a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step - loss: 114.9587 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[114.95870208740234, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "hidden": true,
        "id": "f9KFTkQEqT5l",
        "outputId": "e8fd600d-f9ae-46bc-c8bc-81663f09c3ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1529.1947844660197"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Evaluation by mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "MSE = []\n",
        "for i in range(50):\n",
        "  model.fit(x=xnew_train, y=ynew_train, batch_size=32, validation_data=(x_valid, y_valid), verbose=1, epochs=50)\n",
        "  pred = model.predict(x_test).argmax(axis=-1)\n",
        "  MSE.append(mean_squared_error(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubDV6VNoysym",
        "outputId": "9861db14-96e3-4c1c-c0f3-9d18c940735f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 92.6454 - accuracy: 0.0000e+00 - val_loss: 101.9766 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 90.4044 - accuracy: 0.0000e+00 - val_loss: 106.8348 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 95.0169 - accuracy: 0.0000e+00 - val_loss: 111.0148 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 93.8100 - accuracy: 0.0000e+00 - val_loss: 103.1902 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 89.6458 - accuracy: 0.0000e+00 - val_loss: 100.5195 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 89.7275 - accuracy: 0.0000e+00 - val_loss: 103.1183 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 89.5793 - accuracy: 0.0000e+00 - val_loss: 105.3034 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 88.4080 - accuracy: 0.0000e+00 - val_loss: 101.1742 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 87.3792 - accuracy: 0.0000e+00 - val_loss: 100.3253 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 87.9286 - accuracy: 0.0000e+00 - val_loss: 98.9109 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 86.8571 - accuracy: 0.0000e+00 - val_loss: 100.1065 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 86.6095 - accuracy: 0.0000e+00 - val_loss: 98.8064 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 86.9616 - accuracy: 0.0000e+00 - val_loss: 98.0941 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 85.1049 - accuracy: 0.0000e+00 - val_loss: 100.1605 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 85.1420 - accuracy: 0.0000e+00 - val_loss: 99.1090 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 85.2486 - accuracy: 0.0000e+00 - val_loss: 97.0491 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 85.6190 - accuracy: 0.0000e+00 - val_loss: 96.8628 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 84.0710 - accuracy: 0.0000e+00 - val_loss: 96.6334 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 83.9122 - accuracy: 0.0000e+00 - val_loss: 96.1857 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 83.2764 - accuracy: 0.0000e+00 - val_loss: 95.5319 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 82.6021 - accuracy: 0.0000e+00 - val_loss: 97.6821 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 82.4588 - accuracy: 0.0000e+00 - val_loss: 95.2891 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 83.5911 - accuracy: 0.0000e+00 - val_loss: 97.7093 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 82.1525 - accuracy: 0.0000e+00 - val_loss: 94.1383 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 81.6734 - accuracy: 0.0000e+00 - val_loss: 94.1376 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 82.7607 - accuracy: 0.0000e+00 - val_loss: 93.6972 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 80.7524 - accuracy: 0.0000e+00 - val_loss: 93.0382 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 82.6722 - accuracy: 0.0000e+00 - val_loss: 97.3548 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 83.0377 - accuracy: 0.0000e+00 - val_loss: 98.0400 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 79.4475 - accuracy: 0.0000e+00 - val_loss: 92.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 79.1689 - accuracy: 0.0000e+00 - val_loss: 93.3086 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 78.5373 - accuracy: 0.0000e+00 - val_loss: 90.9166 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 78.4519 - accuracy: 0.0000e+00 - val_loss: 92.0086 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 80.9717 - accuracy: 0.0000e+00 - val_loss: 92.8078 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 82.2806 - accuracy: 0.0000e+00 - val_loss: 98.4744 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 78.2434 - accuracy: 0.0000e+00 - val_loss: 93.2897 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 78.2948 - accuracy: 0.0000e+00 - val_loss: 88.9151 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 77.0878 - accuracy: 0.0000e+00 - val_loss: 88.8836 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 76.4879 - accuracy: 0.0000e+00 - val_loss: 88.1619 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 76.5265 - accuracy: 0.0000e+00 - val_loss: 88.5270 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 76.6518 - accuracy: 0.0000e+00 - val_loss: 87.7810 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 78.5638 - accuracy: 0.0000e+00 - val_loss: 90.7886 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 75.0167 - accuracy: 0.0000e+00 - val_loss: 87.0157 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 74.6597 - accuracy: 0.0000e+00 - val_loss: 88.4777 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 75.7177 - accuracy: 0.0000e+00 - val_loss: 88.0325 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 77.4966 - accuracy: 0.0000e+00 - val_loss: 89.5261 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 77.1275 - accuracy: 0.0000e+00 - val_loss: 86.4948 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 76.8221 - accuracy: 0.0000e+00 - val_loss: 87.9994 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 73.5252 - accuracy: 0.0000e+00 - val_loss: 85.6610 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 74.6248 - accuracy: 0.0000e+00 - val_loss: 85.1326 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 76.6435 - accuracy: 0.0000e+00 - val_loss: 85.6976 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 73.5302 - accuracy: 0.0000e+00 - val_loss: 90.4651 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 76.4508 - accuracy: 0.0000e+00 - val_loss: 106.9532 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 75.2164 - accuracy: 0.0000e+00 - val_loss: 84.9087 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 73.0483 - accuracy: 0.0000e+00 - val_loss: 84.1966 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 74.7275 - accuracy: 0.0000e+00 - val_loss: 85.6948 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 75.4819 - accuracy: 0.0000e+00 - val_loss: 86.9197 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 72.4493 - accuracy: 0.0000e+00 - val_loss: 83.7807 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 71.8603 - accuracy: 0.0000e+00 - val_loss: 83.4068 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 72.9392 - accuracy: 0.0000e+00 - val_loss: 91.0206 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 73.3651 - accuracy: 0.0000e+00 - val_loss: 82.7400 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 71.7738 - accuracy: 0.0000e+00 - val_loss: 83.3311 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 72.1781 - accuracy: 0.0000e+00 - val_loss: 82.6349 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 71.6681 - accuracy: 0.0000e+00 - val_loss: 83.4318 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 72.0056 - accuracy: 0.0000e+00 - val_loss: 84.3826 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 72.2161 - accuracy: 0.0000e+00 - val_loss: 82.6887 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 72.7705 - accuracy: 0.0000e+00 - val_loss: 81.7839 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 72.4439 - accuracy: 0.0000e+00 - val_loss: 82.1016 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 70.4960 - accuracy: 0.0000e+00 - val_loss: 82.1407 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 70.8330 - accuracy: 0.0000e+00 - val_loss: 81.5285 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 70.7588 - accuracy: 0.0000e+00 - val_loss: 84.2721 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 71.4724 - accuracy: 0.0000e+00 - val_loss: 81.8611 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 70.4952 - accuracy: 0.0000e+00 - val_loss: 81.5154 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 69.7094 - accuracy: 0.0000e+00 - val_loss: 80.3721 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 68.9257 - accuracy: 0.0000e+00 - val_loss: 80.3278 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 70.9085 - accuracy: 0.0000e+00 - val_loss: 81.1730 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 68.9049 - accuracy: 0.0000e+00 - val_loss: 82.0582 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 71.9816 - accuracy: 0.0000e+00 - val_loss: 80.1547 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 72.8092 - accuracy: 0.0000e+00 - val_loss: 79.4568 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 69.3683 - accuracy: 0.0000e+00 - val_loss: 80.2450 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 68.3415 - accuracy: 0.0000e+00 - val_loss: 79.3870 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 67.9597 - accuracy: 0.0000e+00 - val_loss: 79.2243 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 67.8766 - accuracy: 0.0000e+00 - val_loss: 79.0453 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 70.0661 - accuracy: 0.0000e+00 - val_loss: 92.1521 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 69.8044 - accuracy: 0.0000e+00 - val_loss: 78.4083 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 67.0750 - accuracy: 0.0000e+00 - val_loss: 78.7754 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 66.9130 - accuracy: 0.0000e+00 - val_loss: 78.2341 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 66.9618 - accuracy: 0.0000e+00 - val_loss: 77.3189 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 65.9442 - accuracy: 0.0000e+00 - val_loss: 77.3501 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 65.6939 - accuracy: 0.0000e+00 - val_loss: 77.1169 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 64.8709 - accuracy: 0.0000e+00 - val_loss: 78.8218 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 67.8350 - accuracy: 0.0000e+00 - val_loss: 76.9610 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 65.6093 - accuracy: 0.0000e+00 - val_loss: 77.8941 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 64.0231 - accuracy: 0.0000e+00 - val_loss: 76.4123 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 64.1061 - accuracy: 0.0000e+00 - val_loss: 75.2695 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 65.9648 - accuracy: 0.0000e+00 - val_loss: 74.9933 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 62.5027 - accuracy: 0.0000e+00 - val_loss: 76.0878 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 62.0542 - accuracy: 0.0000e+00 - val_loss: 74.3461 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 61.0995 - accuracy: 0.0000e+00 - val_loss: 74.1931 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 60.1686 - accuracy: 0.0000e+00 - val_loss: 77.5895 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 62.7527 - accuracy: 0.0000e+00 - val_loss: 75.2345 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 60.1240 - accuracy: 0.0000e+00 - val_loss: 72.5639 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 62.5964 - accuracy: 0.0000e+00 - val_loss: 89.8204 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 60.9475 - accuracy: 0.0000e+00 - val_loss: 72.0734 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 59.1007 - accuracy: 0.0000e+00 - val_loss: 72.1175 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 59.5268 - accuracy: 0.0000e+00 - val_loss: 70.8242 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 59.8737 - accuracy: 0.0000e+00 - val_loss: 70.2948 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 62.3901 - accuracy: 0.0000e+00 - val_loss: 77.8079 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 58.3666 - accuracy: 0.0000e+00 - val_loss: 70.4901 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 58.0395 - accuracy: 0.0000e+00 - val_loss: 81.4040 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 59.3530 - accuracy: 0.0000e+00 - val_loss: 68.9644 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 56.2019 - accuracy: 0.0000e+00 - val_loss: 68.8766 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 54.5946 - accuracy: 0.0000e+00 - val_loss: 69.1714 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 55.1718 - accuracy: 0.0000e+00 - val_loss: 68.2756 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 54.5248 - accuracy: 0.0000e+00 - val_loss: 77.3153 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 56.6781 - accuracy: 0.0000e+00 - val_loss: 70.7073 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 55.4397 - accuracy: 0.0000e+00 - val_loss: 72.7970 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 56.2067 - accuracy: 0.0000e+00 - val_loss: 71.6054 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 54.4546 - accuracy: 0.0000e+00 - val_loss: 67.7070 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.7569 - accuracy: 0.0000e+00 - val_loss: 70.2365 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 56.8437 - accuracy: 0.0000e+00 - val_loss: 73.7603 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 55.2567 - accuracy: 0.0000e+00 - val_loss: 67.8473 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 55.9558 - accuracy: 0.0000e+00 - val_loss: 66.6350 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.5051 - accuracy: 0.0000e+00 - val_loss: 66.8924 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 52.4558 - accuracy: 0.0000e+00 - val_loss: 66.2206 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 56.4550 - accuracy: 0.0000e+00 - val_loss: 71.3360 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.6801 - accuracy: 0.0000e+00 - val_loss: 76.0187 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 55.4173 - accuracy: 0.0000e+00 - val_loss: 66.3433 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 52.9547 - accuracy: 0.0000e+00 - val_loss: 76.5554 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 52.5096 - accuracy: 0.0000e+00 - val_loss: 68.3978 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.4738 - accuracy: 0.0000e+00 - val_loss: 66.1778 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.3930 - accuracy: 0.0000e+00 - val_loss: 64.6982 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.9394 - accuracy: 0.0000e+00 - val_loss: 64.9821 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 52.4529 - accuracy: 0.0000e+00 - val_loss: 68.9319 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.0950 - accuracy: 0.0000e+00 - val_loss: 64.4949 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.6395 - accuracy: 0.0000e+00 - val_loss: 64.0720 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.2231 - accuracy: 0.0000e+00 - val_loss: 65.6376 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.9604 - accuracy: 0.0000e+00 - val_loss: 67.8436 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 52.2456 - accuracy: 0.0000e+00 - val_loss: 64.2664 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.5488 - accuracy: 0.0000e+00 - val_loss: 63.5544 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.7091 - accuracy: 0.0000e+00 - val_loss: 65.8324 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.7507 - accuracy: 0.0000e+00 - val_loss: 65.6092 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 52.8712 - accuracy: 0.0000e+00 - val_loss: 66.1294 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.0161 - accuracy: 0.0000e+00 - val_loss: 68.2433 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 54.1100 - accuracy: 0.0000e+00 - val_loss: 65.2001 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.5895 - accuracy: 0.0000e+00 - val_loss: 64.7548 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.8276 - accuracy: 0.0000e+00 - val_loss: 64.1955 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.5071 - accuracy: 0.0000e+00 - val_loss: 67.2665 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.0033 - accuracy: 0.0000e+00 - val_loss: 63.4135 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 55.6358 - accuracy: 0.0000e+00 - val_loss: 70.5664 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.1768 - accuracy: 0.0000e+00 - val_loss: 65.8581 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.1703 - accuracy: 0.0000e+00 - val_loss: 66.1558 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.4054 - accuracy: 0.0000e+00 - val_loss: 63.6862 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.5114 - accuracy: 0.0000e+00 - val_loss: 71.7196 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.0025 - accuracy: 0.0000e+00 - val_loss: 63.2879 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 55.4843 - accuracy: 0.0000e+00 - val_loss: 64.4651 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.8628 - accuracy: 0.0000e+00 - val_loss: 66.4128 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 58.1557 - accuracy: 0.0000e+00 - val_loss: 61.8312 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.8895 - accuracy: 0.0000e+00 - val_loss: 63.7019 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.1504 - accuracy: 0.0000e+00 - val_loss: 73.9490 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.0445 - accuracy: 0.0000e+00 - val_loss: 66.4320 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.7946 - accuracy: 0.0000e+00 - val_loss: 62.0008 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.1740 - accuracy: 0.0000e+00 - val_loss: 60.9650 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.4475 - accuracy: 0.0000e+00 - val_loss: 61.0899 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.1245 - accuracy: 0.0000e+00 - val_loss: 64.6439 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.8921 - accuracy: 0.0000e+00 - val_loss: 62.2470 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.3961 - accuracy: 0.0000e+00 - val_loss: 63.1041 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.5123 - accuracy: 0.0000e+00 - val_loss: 61.3236 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.0829 - accuracy: 0.0000e+00 - val_loss: 62.1926 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.5098 - accuracy: 0.0000e+00 - val_loss: 61.1607 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.4575 - accuracy: 0.0000e+00 - val_loss: 61.9181 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.7166 - accuracy: 0.0000e+00 - val_loss: 60.1257 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.8223 - accuracy: 0.0000e+00 - val_loss: 63.4592 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.6491 - accuracy: 0.0000e+00 - val_loss: 62.5902 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.7111 - accuracy: 0.0000e+00 - val_loss: 61.8050 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 51.5782 - accuracy: 0.0000e+00 - val_loss: 59.9314 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.0728 - accuracy: 0.0000e+00 - val_loss: 64.4930 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.7246 - accuracy: 0.0000e+00 - val_loss: 60.6275 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.2354 - accuracy: 0.0000e+00 - val_loss: 77.7007 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.9267 - accuracy: 0.0000e+00 - val_loss: 62.0299 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.2542 - accuracy: 0.0000e+00 - val_loss: 59.7937 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.4695 - accuracy: 0.0000e+00 - val_loss: 60.6850 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.2332 - accuracy: 0.0000e+00 - val_loss: 60.4761 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.2881 - accuracy: 0.0000e+00 - val_loss: 61.4164 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.4500 - accuracy: 0.0000e+00 - val_loss: 60.5566 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.7214 - accuracy: 0.0000e+00 - val_loss: 60.2635 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.4261 - accuracy: 0.0000e+00 - val_loss: 59.6149 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.5836 - accuracy: 0.0000e+00 - val_loss: 68.4060 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.8616 - accuracy: 0.0000e+00 - val_loss: 62.5784 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.7810 - accuracy: 0.0000e+00 - val_loss: 60.2764 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.1637 - accuracy: 0.0000e+00 - val_loss: 59.7579 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.3374 - accuracy: 0.0000e+00 - val_loss: 60.6104 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.1627 - accuracy: 0.0000e+00 - val_loss: 65.7341 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.1899 - accuracy: 0.0000e+00 - val_loss: 61.0193 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 52.5553 - accuracy: 0.0000e+00 - val_loss: 72.3543 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.7262 - accuracy: 0.0000e+00 - val_loss: 59.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.0244 - accuracy: 0.0000e+00 - val_loss: 59.4153 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.2030 - accuracy: 0.0000e+00 - val_loss: 68.8987 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.9930 - accuracy: 0.0000e+00 - val_loss: 63.2051 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 54.4922 - accuracy: 0.0000e+00 - val_loss: 79.4273 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.1210 - accuracy: 0.0000e+00 - val_loss: 60.0004 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.8352 - accuracy: 0.0000e+00 - val_loss: 62.9880 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.6923 - accuracy: 0.0000e+00 - val_loss: 59.9165 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.6989 - accuracy: 0.0000e+00 - val_loss: 69.0278 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.6337 - accuracy: 0.0000e+00 - val_loss: 63.5056 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 54.5983 - accuracy: 0.0000e+00 - val_loss: 69.7448 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.2505 - accuracy: 0.0000e+00 - val_loss: 61.0615 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 55.9406 - accuracy: 0.0000e+00 - val_loss: 57.6415 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.4496 - accuracy: 0.0000e+00 - val_loss: 58.6668 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.8590 - accuracy: 0.0000e+00 - val_loss: 67.7397 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.3698 - accuracy: 0.0000e+00 - val_loss: 62.0420 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.0579 - accuracy: 0.0000e+00 - val_loss: 59.5685 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.5469 - accuracy: 0.0000e+00 - val_loss: 57.9273 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.5527 - accuracy: 0.0000e+00 - val_loss: 58.2005 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.0208 - accuracy: 0.0000e+00 - val_loss: 60.7878 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.2443 - accuracy: 0.0000e+00 - val_loss: 60.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.1073 - accuracy: 0.0000e+00 - val_loss: 59.2582 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.0618 - accuracy: 0.0000e+00 - val_loss: 58.7766 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.9668 - accuracy: 0.0000e+00 - val_loss: 61.4317 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.0672 - accuracy: 0.0000e+00 - val_loss: 57.6788 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.6717 - accuracy: 0.0000e+00 - val_loss: 59.0693 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.4325 - accuracy: 0.0000e+00 - val_loss: 57.8233 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.9434 - accuracy: 0.0000e+00 - val_loss: 65.7336 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.4502 - accuracy: 0.0000e+00 - val_loss: 62.0461 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.5148 - accuracy: 0.0000e+00 - val_loss: 59.6630 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 51.0584 - accuracy: 0.0000e+00 - val_loss: 57.3050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.3910 - accuracy: 0.0000e+00 - val_loss: 58.8526 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.3200 - accuracy: 0.0000e+00 - val_loss: 57.8651 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.6111 - accuracy: 0.0000e+00 - val_loss: 75.2484 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.4965 - accuracy: 0.0000e+00 - val_loss: 60.3331 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.6666 - accuracy: 0.0000e+00 - val_loss: 57.4472 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.5691 - accuracy: 0.0000e+00 - val_loss: 60.3065 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.8271 - accuracy: 0.0000e+00 - val_loss: 59.5233 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.2869 - accuracy: 0.0000e+00 - val_loss: 58.2059 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.2602 - accuracy: 0.0000e+00 - val_loss: 58.8741 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.0032 - accuracy: 0.0000e+00 - val_loss: 58.9263 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.2939 - accuracy: 0.0000e+00 - val_loss: 58.9230 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.6832 - accuracy: 0.0000e+00 - val_loss: 69.7985 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 52.0363 - accuracy: 0.0000e+00 - val_loss: 62.9456 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.3437 - accuracy: 0.0000e+00 - val_loss: 59.9679 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.9350 - accuracy: 0.0000e+00 - val_loss: 57.5366 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.9058 - accuracy: 0.0000e+00 - val_loss: 58.7663 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.0809 - accuracy: 0.0000e+00 - val_loss: 63.6085 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.1948 - accuracy: 0.0000e+00 - val_loss: 59.4510 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.5806 - accuracy: 0.0000e+00 - val_loss: 74.9124 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.0200 - accuracy: 0.0000e+00 - val_loss: 57.8936 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.6730 - accuracy: 0.0000e+00 - val_loss: 57.7458 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.5936 - accuracy: 0.0000e+00 - val_loss: 69.8616 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.5468 - accuracy: 0.0000e+00 - val_loss: 62.0635 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.1556 - accuracy: 0.0000e+00 - val_loss: 82.6955 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.1930 - accuracy: 0.0000e+00 - val_loss: 58.2153 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.1212 - accuracy: 0.0000e+00 - val_loss: 61.1243 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.4848 - accuracy: 0.0000e+00 - val_loss: 57.9460 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.9172 - accuracy: 0.0000e+00 - val_loss: 66.0305 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.4656 - accuracy: 0.0000e+00 - val_loss: 62.4530 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.8584 - accuracy: 0.0000e+00 - val_loss: 72.0359 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.8998 - accuracy: 0.0000e+00 - val_loss: 59.5448 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 56.2290 - accuracy: 0.0000e+00 - val_loss: 56.5318 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.0099 - accuracy: 0.0000e+00 - val_loss: 57.0236 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.2649 - accuracy: 0.0000e+00 - val_loss: 65.2846 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.3530 - accuracy: 0.0000e+00 - val_loss: 59.6553 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.4576 - accuracy: 0.0000e+00 - val_loss: 57.9824 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.1017 - accuracy: 0.0000e+00 - val_loss: 56.8068 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.3265 - accuracy: 0.0000e+00 - val_loss: 56.9812 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.5875 - accuracy: 0.0000e+00 - val_loss: 59.7490 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.8199 - accuracy: 0.0000e+00 - val_loss: 59.0126 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.4953 - accuracy: 0.0000e+00 - val_loss: 57.7319 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7485 - accuracy: 0.0000e+00 - val_loss: 57.7083 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.5955 - accuracy: 0.0000e+00 - val_loss: 61.0211 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.4690 - accuracy: 0.0000e+00 - val_loss: 56.6102 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.3043 - accuracy: 0.0000e+00 - val_loss: 57.8566 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.8837 - accuracy: 0.0000e+00 - val_loss: 56.9989 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 51.9611 - accuracy: 0.0000e+00 - val_loss: 67.0372 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.9030 - accuracy: 0.0000e+00 - val_loss: 61.3061 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.5357 - accuracy: 0.0000e+00 - val_loss: 58.6857 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 51.0321 - accuracy: 0.0000e+00 - val_loss: 56.3903 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.1886 - accuracy: 0.0000e+00 - val_loss: 57.2848 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.9876 - accuracy: 0.0000e+00 - val_loss: 56.7333 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9764 - accuracy: 0.0000e+00 - val_loss: 73.2394 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.3625 - accuracy: 0.0000e+00 - val_loss: 60.0654 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.4605 - accuracy: 0.0000e+00 - val_loss: 56.5147 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.4843 - accuracy: 0.0000e+00 - val_loss: 60.4927 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.5943 - accuracy: 0.0000e+00 - val_loss: 58.9008 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.8331 - accuracy: 0.0000e+00 - val_loss: 57.0992 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.1916 - accuracy: 0.0000e+00 - val_loss: 58.2685 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.7538 - accuracy: 0.0000e+00 - val_loss: 58.2367 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.8001 - accuracy: 0.0000e+00 - val_loss: 58.5878 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.7283 - accuracy: 0.0000e+00 - val_loss: 69.9860 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 52.1760 - accuracy: 0.0000e+00 - val_loss: 63.0564 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.2369 - accuracy: 0.0000e+00 - val_loss: 59.8110 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.8630 - accuracy: 0.0000e+00 - val_loss: 56.8013 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.7271 - accuracy: 0.0000e+00 - val_loss: 58.0936 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.7872 - accuracy: 0.0000e+00 - val_loss: 62.4728 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.8494 - accuracy: 0.0000e+00 - val_loss: 58.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 51.0958 - accuracy: 0.0000e+00 - val_loss: 75.3593 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 50.3590 - accuracy: 0.0000e+00 - val_loss: 57.5268 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.5609 - accuracy: 0.0000e+00 - val_loss: 57.0449 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.2175 - accuracy: 0.0000e+00 - val_loss: 69.6668 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 51.2335 - accuracy: 0.0000e+00 - val_loss: 61.2493 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 52.7808 - accuracy: 0.0000e+00 - val_loss: 83.0719 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 53.1583 - accuracy: 0.0000e+00 - val_loss: 57.5658 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.8328 - accuracy: 0.0000e+00 - val_loss: 60.5383 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.4634 - accuracy: 0.0000e+00 - val_loss: 57.2576 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.6434 - accuracy: 0.0000e+00 - val_loss: 64.9468 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.0687 - accuracy: 0.0000e+00 - val_loss: 61.9985 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 53.3912 - accuracy: 0.0000e+00 - val_loss: 70.6102 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.7164 - accuracy: 0.0000e+00 - val_loss: 58.9391 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 56.1491 - accuracy: 0.0000e+00 - val_loss: 56.0893 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.8371 - accuracy: 0.0000e+00 - val_loss: 56.4635 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.9868 - accuracy: 0.0000e+00 - val_loss: 63.8576 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.9330 - accuracy: 0.0000e+00 - val_loss: 58.5891 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.1514 - accuracy: 0.0000e+00 - val_loss: 57.1738 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.9392 - accuracy: 0.0000e+00 - val_loss: 56.3719 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.2660 - accuracy: 0.0000e+00 - val_loss: 56.3229 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.3107 - accuracy: 0.0000e+00 - val_loss: 59.4021 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.6363 - accuracy: 0.0000e+00 - val_loss: 58.6682 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.4209 - accuracy: 0.0000e+00 - val_loss: 57.1490 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.5515 - accuracy: 0.0000e+00 - val_loss: 57.1363 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.2390 - accuracy: 0.0000e+00 - val_loss: 60.6045 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1456 - accuracy: 0.0000e+00 - val_loss: 56.2059 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1253 - accuracy: 0.0000e+00 - val_loss: 57.2574 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.6679 - accuracy: 0.0000e+00 - val_loss: 56.6382 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.7658 - accuracy: 0.0000e+00 - val_loss: 66.7632 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.7706 - accuracy: 0.0000e+00 - val_loss: 60.7382 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.4633 - accuracy: 0.0000e+00 - val_loss: 58.2313 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.9887 - accuracy: 0.0000e+00 - val_loss: 56.0171 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.0430 - accuracy: 0.0000e+00 - val_loss: 56.7944 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 44.8380 - accuracy: 0.0000e+00 - val_loss: 56.3059 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.7025 - accuracy: 0.0000e+00 - val_loss: 72.2405 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.1781 - accuracy: 0.0000e+00 - val_loss: 59.8417 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.2200 - accuracy: 0.0000e+00 - val_loss: 56.0645 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 52.9356 - accuracy: 0.0000e+00 - val_loss: 59.7815 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2092 - accuracy: 0.0000e+00 - val_loss: 58.2712 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.6416 - accuracy: 0.0000e+00 - val_loss: 56.8389 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.0102 - accuracy: 0.0000e+00 - val_loss: 57.8618 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6241 - accuracy: 0.0000e+00 - val_loss: 57.9491 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.7867 - accuracy: 0.0000e+00 - val_loss: 58.1764 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.6402 - accuracy: 0.0000e+00 - val_loss: 68.9289 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 52.1677 - accuracy: 0.0000e+00 - val_loss: 63.1213 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.3447 - accuracy: 0.0000e+00 - val_loss: 59.4127 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.7309 - accuracy: 0.0000e+00 - val_loss: 56.4638 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.4098 - accuracy: 0.0000e+00 - val_loss: 57.8380 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.8089 - accuracy: 0.0000e+00 - val_loss: 62.1607 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.6917 - accuracy: 0.0000e+00 - val_loss: 57.7585 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.9025 - accuracy: 0.0000e+00 - val_loss: 74.6113 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.3537 - accuracy: 0.0000e+00 - val_loss: 57.3246 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4983 - accuracy: 0.0000e+00 - val_loss: 56.7783 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.1459 - accuracy: 0.0000e+00 - val_loss: 69.3343 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.0955 - accuracy: 0.0000e+00 - val_loss: 60.6597 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 52.9055 - accuracy: 0.0000e+00 - val_loss: 81.5283 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 52.8784 - accuracy: 0.0000e+00 - val_loss: 57.2960 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.6588 - accuracy: 0.0000e+00 - val_loss: 60.4104 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.4218 - accuracy: 0.0000e+00 - val_loss: 57.1515 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.5800 - accuracy: 0.0000e+00 - val_loss: 65.0798 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.0954 - accuracy: 0.0000e+00 - val_loss: 61.9433 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.3271 - accuracy: 0.0000e+00 - val_loss: 69.7925 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.4414 - accuracy: 0.0000e+00 - val_loss: 58.6777 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 55.6488 - accuracy: 0.0000e+00 - val_loss: 55.7256 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.6694 - accuracy: 0.0000e+00 - val_loss: 56.5013 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.7351 - accuracy: 0.0000e+00 - val_loss: 62.8108 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.4276 - accuracy: 0.0000e+00 - val_loss: 58.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.8731 - accuracy: 0.0000e+00 - val_loss: 56.9079 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.7912 - accuracy: 0.0000e+00 - val_loss: 56.1670 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.1889 - accuracy: 0.0000e+00 - val_loss: 56.0346 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2344 - accuracy: 0.0000e+00 - val_loss: 59.2056 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.4962 - accuracy: 0.0000e+00 - val_loss: 58.5936 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3282 - accuracy: 0.0000e+00 - val_loss: 56.9181 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.3771 - accuracy: 0.0000e+00 - val_loss: 56.8101 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.9259 - accuracy: 0.0000e+00 - val_loss: 60.2358 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.9766 - accuracy: 0.0000e+00 - val_loss: 55.9889 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.0294 - accuracy: 0.0000e+00 - val_loss: 57.0819 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.5435 - accuracy: 0.0000e+00 - val_loss: 56.3744 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.3360 - accuracy: 0.0000e+00 - val_loss: 65.8932 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.3568 - accuracy: 0.0000e+00 - val_loss: 60.3078 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.1844 - accuracy: 0.0000e+00 - val_loss: 57.6239 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.8193 - accuracy: 0.0000e+00 - val_loss: 55.8853 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.9816 - accuracy: 0.0000e+00 - val_loss: 56.7861 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.7451 - accuracy: 0.0000e+00 - val_loss: 56.3481 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.6054 - accuracy: 0.0000e+00 - val_loss: 72.0408 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.9461 - accuracy: 0.0000e+00 - val_loss: 59.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.0538 - accuracy: 0.0000e+00 - val_loss: 55.9645 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 52.3726 - accuracy: 0.0000e+00 - val_loss: 58.7877 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9539 - accuracy: 0.0000e+00 - val_loss: 57.6881 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.6386 - accuracy: 0.0000e+00 - val_loss: 56.9358 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.7090 - accuracy: 0.0000e+00 - val_loss: 57.4261 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.5041 - accuracy: 0.0000e+00 - val_loss: 57.6911 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.9808 - accuracy: 0.0000e+00 - val_loss: 57.6475 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.4707 - accuracy: 0.0000e+00 - val_loss: 68.0756 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 52.0256 - accuracy: 0.0000e+00 - val_loss: 62.5128 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.3294 - accuracy: 0.0000e+00 - val_loss: 58.9113 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.4971 - accuracy: 0.0000e+00 - val_loss: 56.3363 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.0393 - accuracy: 0.0000e+00 - val_loss: 57.7897 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.8247 - accuracy: 0.0000e+00 - val_loss: 61.7743 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.5189 - accuracy: 0.0000e+00 - val_loss: 57.4513 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.8204 - accuracy: 0.0000e+00 - val_loss: 73.1259 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.1083 - accuracy: 0.0000e+00 - val_loss: 57.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3607 - accuracy: 0.0000e+00 - val_loss: 56.6424 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.1066 - accuracy: 0.0000e+00 - val_loss: 68.6483 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.9021 - accuracy: 0.0000e+00 - val_loss: 60.0136 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.2336 - accuracy: 0.0000e+00 - val_loss: 78.6698 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 52.4308 - accuracy: 0.0000e+00 - val_loss: 57.5102 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.5994 - accuracy: 0.0000e+00 - val_loss: 60.5820 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.3511 - accuracy: 0.0000e+00 - val_loss: 57.4786 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.6345 - accuracy: 0.0000e+00 - val_loss: 65.7352 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.4178 - accuracy: 0.0000e+00 - val_loss: 62.1684 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.5009 - accuracy: 0.0000e+00 - val_loss: 68.6234 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.9216 - accuracy: 0.0000e+00 - val_loss: 58.5247 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 54.9303 - accuracy: 0.0000e+00 - val_loss: 55.5624 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.5270 - accuracy: 0.0000e+00 - val_loss: 57.0781 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5316 - accuracy: 0.0000e+00 - val_loss: 61.8351 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.1574 - accuracy: 0.0000e+00 - val_loss: 57.6285 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6389 - accuracy: 0.0000e+00 - val_loss: 56.7760 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.6807 - accuracy: 0.0000e+00 - val_loss: 56.1147 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.0355 - accuracy: 0.0000e+00 - val_loss: 55.9679 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1445 - accuracy: 0.0000e+00 - val_loss: 59.0987 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.3536 - accuracy: 0.0000e+00 - val_loss: 58.7257 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.3206 - accuracy: 0.0000e+00 - val_loss: 56.9330 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.1767 - accuracy: 0.0000e+00 - val_loss: 56.6447 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.5919 - accuracy: 0.0000e+00 - val_loss: 59.8306 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.8516 - accuracy: 0.0000e+00 - val_loss: 55.9135 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.9445 - accuracy: 0.0000e+00 - val_loss: 57.1417 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.4154 - accuracy: 0.0000e+00 - val_loss: 56.2271 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.7816 - accuracy: 0.0000e+00 - val_loss: 64.5334 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.6985 - accuracy: 0.0000e+00 - val_loss: 59.8055 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.7556 - accuracy: 0.0000e+00 - val_loss: 57.3077 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 50.5844 - accuracy: 0.0000e+00 - val_loss: 55.9587 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.8202 - accuracy: 0.0000e+00 - val_loss: 57.1636 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.6923 - accuracy: 0.0000e+00 - val_loss: 56.5870 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.6047 - accuracy: 0.0000e+00 - val_loss: 72.3603 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.6842 - accuracy: 0.0000e+00 - val_loss: 59.1841 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.8752 - accuracy: 0.0000e+00 - val_loss: 56.0266 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 51.7170 - accuracy: 0.0000e+00 - val_loss: 57.9116 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.6109 - accuracy: 0.0000e+00 - val_loss: 57.1157 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.5836 - accuracy: 0.0000e+00 - val_loss: 57.3646 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.3678 - accuracy: 0.0000e+00 - val_loss: 57.1016 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.3767 - accuracy: 0.0000e+00 - val_loss: 56.9801 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.1629 - accuracy: 0.0000e+00 - val_loss: 57.1665 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.2382 - accuracy: 0.0000e+00 - val_loss: 67.0145 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.8326 - accuracy: 0.0000e+00 - val_loss: 61.6294 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.3112 - accuracy: 0.0000e+00 - val_loss: 58.2248 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.1920 - accuracy: 0.0000e+00 - val_loss: 56.3194 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.7310 - accuracy: 0.0000e+00 - val_loss: 57.8133 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.8446 - accuracy: 0.0000e+00 - val_loss: 61.4362 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.3979 - accuracy: 0.0000e+00 - val_loss: 57.4949 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.7987 - accuracy: 0.0000e+00 - val_loss: 71.2853 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.7445 - accuracy: 0.0000e+00 - val_loss: 56.7852 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.2226 - accuracy: 0.0000e+00 - val_loss: 56.6166 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.0410 - accuracy: 0.0000e+00 - val_loss: 67.6224 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.6169 - accuracy: 0.0000e+00 - val_loss: 59.2905 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.5109 - accuracy: 0.0000e+00 - val_loss: 75.4374 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.9802 - accuracy: 0.0000e+00 - val_loss: 58.0303 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.5905 - accuracy: 0.0000e+00 - val_loss: 60.9172 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.1571 - accuracy: 0.0000e+00 - val_loss: 57.9318 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.6746 - accuracy: 0.0000e+00 - val_loss: 66.2314 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.6032 - accuracy: 0.0000e+00 - val_loss: 61.7978 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.4767 - accuracy: 0.0000e+00 - val_loss: 66.7362 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.3735 - accuracy: 0.0000e+00 - val_loss: 58.6047 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 54.2114 - accuracy: 0.0000e+00 - val_loss: 55.6164 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.3894 - accuracy: 0.0000e+00 - val_loss: 57.7121 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.4176 - accuracy: 0.0000e+00 - val_loss: 61.3643 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.9838 - accuracy: 0.0000e+00 - val_loss: 57.5008 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.4275 - accuracy: 0.0000e+00 - val_loss: 56.6759 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5855 - accuracy: 0.0000e+00 - val_loss: 56.0471 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8797 - accuracy: 0.0000e+00 - val_loss: 55.9240 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.0576 - accuracy: 0.0000e+00 - val_loss: 59.1043 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.2454 - accuracy: 0.0000e+00 - val_loss: 58.8905 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3018 - accuracy: 0.0000e+00 - val_loss: 57.0748 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.9977 - accuracy: 0.0000e+00 - val_loss: 56.5404 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.2852 - accuracy: 0.0000e+00 - val_loss: 59.2485 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.6049 - accuracy: 0.0000e+00 - val_loss: 55.9777 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9505 - accuracy: 0.0000e+00 - val_loss: 57.1989 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.2216 - accuracy: 0.0000e+00 - val_loss: 56.1069 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.3127 - accuracy: 0.0000e+00 - val_loss: 63.5870 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.2226 - accuracy: 0.0000e+00 - val_loss: 59.4682 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.4643 - accuracy: 0.0000e+00 - val_loss: 56.8105 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.2116 - accuracy: 0.0000e+00 - val_loss: 56.3779 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.4204 - accuracy: 0.0000e+00 - val_loss: 57.8721 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.6788 - accuracy: 0.0000e+00 - val_loss: 57.0669 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.6267 - accuracy: 0.0000e+00 - val_loss: 72.4980 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.3070 - accuracy: 0.0000e+00 - val_loss: 59.3333 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7395 - accuracy: 0.0000e+00 - val_loss: 56.1370 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 51.1217 - accuracy: 0.0000e+00 - val_loss: 57.3981 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.2980 - accuracy: 0.0000e+00 - val_loss: 56.8398 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.3542 - accuracy: 0.0000e+00 - val_loss: 57.8526 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.9734 - accuracy: 0.0000e+00 - val_loss: 56.8313 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.2098 - accuracy: 0.0000e+00 - val_loss: 56.7684 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.4107 - accuracy: 0.0000e+00 - val_loss: 57.0183 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.0447 - accuracy: 0.0000e+00 - val_loss: 65.9441 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.5778 - accuracy: 0.0000e+00 - val_loss: 60.7263 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.1600 - accuracy: 0.0000e+00 - val_loss: 57.6584 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.8897 - accuracy: 0.0000e+00 - val_loss: 56.5923 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.5145 - accuracy: 0.0000e+00 - val_loss: 57.9989 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.9970 - accuracy: 0.0000e+00 - val_loss: 61.3732 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3658 - accuracy: 0.0000e+00 - val_loss: 57.6268 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.7930 - accuracy: 0.0000e+00 - val_loss: 70.0542 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.4908 - accuracy: 0.0000e+00 - val_loss: 56.6869 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.1180 - accuracy: 0.0000e+00 - val_loss: 56.4337 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9838 - accuracy: 0.0000e+00 - val_loss: 66.3152 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.3734 - accuracy: 0.0000e+00 - val_loss: 58.6106 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.6824 - accuracy: 0.0000e+00 - val_loss: 72.9752 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.6099 - accuracy: 0.0000e+00 - val_loss: 58.6294 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.6295 - accuracy: 0.0000e+00 - val_loss: 61.1991 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9645 - accuracy: 0.0000e+00 - val_loss: 58.2094 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6855 - accuracy: 0.0000e+00 - val_loss: 66.3852 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.7095 - accuracy: 0.0000e+00 - val_loss: 61.3731 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.3682 - accuracy: 0.0000e+00 - val_loss: 65.2790 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 48.0540 - accuracy: 0.0000e+00 - val_loss: 58.7783 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.9009 - accuracy: 0.0000e+00 - val_loss: 55.7870 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.2491 - accuracy: 0.0000e+00 - val_loss: 58.3128 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.3681 - accuracy: 0.0000e+00 - val_loss: 61.1296 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9656 - accuracy: 0.0000e+00 - val_loss: 57.5567 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3477 - accuracy: 0.0000e+00 - val_loss: 56.4706 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5601 - accuracy: 0.0000e+00 - val_loss: 56.1776 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8404 - accuracy: 0.0000e+00 - val_loss: 55.9364 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.0289 - accuracy: 0.0000e+00 - val_loss: 59.2960 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1956 - accuracy: 0.0000e+00 - val_loss: 59.0646 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3435 - accuracy: 0.0000e+00 - val_loss: 57.2696 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.8078 - accuracy: 0.0000e+00 - val_loss: 56.4941 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.9969 - accuracy: 0.0000e+00 - val_loss: 58.7874 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.4417 - accuracy: 0.0000e+00 - val_loss: 55.9082 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.1062 - accuracy: 0.0000e+00 - val_loss: 57.1687 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.0288 - accuracy: 0.0000e+00 - val_loss: 56.0883 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.8569 - accuracy: 0.0000e+00 - val_loss: 62.8630 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.0040 - accuracy: 0.0000e+00 - val_loss: 59.4833 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1728 - accuracy: 0.0000e+00 - val_loss: 56.7429 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.9709 - accuracy: 0.0000e+00 - val_loss: 56.6949 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.1664 - accuracy: 0.0000e+00 - val_loss: 58.5812 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.6970 - accuracy: 0.0000e+00 - val_loss: 57.1554 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.5957 - accuracy: 0.0000e+00 - val_loss: 72.1846 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.1809 - accuracy: 0.0000e+00 - val_loss: 59.3932 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.6639 - accuracy: 0.0000e+00 - val_loss: 56.2703 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.7574 - accuracy: 0.0000e+00 - val_loss: 57.1209 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.9586 - accuracy: 0.0000e+00 - val_loss: 56.5919 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.2061 - accuracy: 0.0000e+00 - val_loss: 58.4058 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.7710 - accuracy: 0.0000e+00 - val_loss: 56.5367 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.1059 - accuracy: 0.0000e+00 - val_loss: 56.5908 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.5162 - accuracy: 0.0000e+00 - val_loss: 56.7937 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.9233 - accuracy: 0.0000e+00 - val_loss: 65.1936 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.4102 - accuracy: 0.0000e+00 - val_loss: 60.0419 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.0372 - accuracy: 0.0000e+00 - val_loss: 57.1743 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.6268 - accuracy: 0.0000e+00 - val_loss: 56.8823 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.3476 - accuracy: 0.0000e+00 - val_loss: 58.0410 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.0495 - accuracy: 0.0000e+00 - val_loss: 60.8987 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.2764 - accuracy: 0.0000e+00 - val_loss: 57.7641 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.5836 - accuracy: 0.0000e+00 - val_loss: 68.1458 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.0969 - accuracy: 0.0000e+00 - val_loss: 56.4909 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.9390 - accuracy: 0.0000e+00 - val_loss: 56.4284 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.7955 - accuracy: 0.0000e+00 - val_loss: 65.2495 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.0671 - accuracy: 0.0000e+00 - val_loss: 58.0440 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.7762 - accuracy: 0.0000e+00 - val_loss: 70.3972 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 51.2308 - accuracy: 0.0000e+00 - val_loss: 59.5443 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.6432 - accuracy: 0.0000e+00 - val_loss: 61.2475 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.4957 - accuracy: 0.0000e+00 - val_loss: 58.4636 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.7076 - accuracy: 0.0000e+00 - val_loss: 66.6994 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 49.9296 - accuracy: 0.0000e+00 - val_loss: 61.1632 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 53.4866 - accuracy: 0.0000e+00 - val_loss: 63.5193 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.7007 - accuracy: 0.0000e+00 - val_loss: 58.9548 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.7482 - accuracy: 0.0000e+00 - val_loss: 56.0927 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.2235 - accuracy: 0.0000e+00 - val_loss: 58.9044 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3637 - accuracy: 0.0000e+00 - val_loss: 61.0692 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9064 - accuracy: 0.0000e+00 - val_loss: 57.5168 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.1964 - accuracy: 0.0000e+00 - val_loss: 56.4258 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.4667 - accuracy: 0.0000e+00 - val_loss: 56.0906 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7110 - accuracy: 0.0000e+00 - val_loss: 55.9016 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.9681 - accuracy: 0.0000e+00 - val_loss: 59.5922 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.1423 - accuracy: 0.0000e+00 - val_loss: 58.6545 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.4392 - accuracy: 0.0000e+00 - val_loss: 57.8213 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6715 - accuracy: 0.0000e+00 - val_loss: 56.4001 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.8059 - accuracy: 0.0000e+00 - val_loss: 58.4082 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.4039 - accuracy: 0.0000e+00 - val_loss: 55.9161 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1300 - accuracy: 0.0000e+00 - val_loss: 57.3363 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8544 - accuracy: 0.0000e+00 - val_loss: 55.9406 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.3903 - accuracy: 0.0000e+00 - val_loss: 61.6061 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.4409 - accuracy: 0.0000e+00 - val_loss: 58.8885 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.9318 - accuracy: 0.0000e+00 - val_loss: 56.4729 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.8399 - accuracy: 0.0000e+00 - val_loss: 57.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.8842 - accuracy: 0.0000e+00 - val_loss: 59.5165 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 44.7371 - accuracy: 0.0000e+00 - val_loss: 57.3447 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.5882 - accuracy: 0.0000e+00 - val_loss: 71.3078 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8738 - accuracy: 0.0000e+00 - val_loss: 59.2250 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3401 - accuracy: 0.0000e+00 - val_loss: 56.3351 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.0726 - accuracy: 0.0000e+00 - val_loss: 56.3637 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.6875 - accuracy: 0.0000e+00 - val_loss: 56.0602 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.0802 - accuracy: 0.0000e+00 - val_loss: 59.2136 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4910 - accuracy: 0.0000e+00 - val_loss: 56.3356 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9801 - accuracy: 0.0000e+00 - val_loss: 56.2655 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.6027 - accuracy: 0.0000e+00 - val_loss: 56.5052 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.5618 - accuracy: 0.0000e+00 - val_loss: 63.5020 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.9399 - accuracy: 0.0000e+00 - val_loss: 59.1525 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.8319 - accuracy: 0.0000e+00 - val_loss: 56.5395 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.2711 - accuracy: 0.0000e+00 - val_loss: 57.3222 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1875 - accuracy: 0.0000e+00 - val_loss: 57.9394 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.8421 - accuracy: 0.0000e+00 - val_loss: 60.1544 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0522 - accuracy: 0.0000e+00 - val_loss: 57.8205 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.4185 - accuracy: 0.0000e+00 - val_loss: 66.1781 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.6846 - accuracy: 0.0000e+00 - val_loss: 55.9851 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6862 - accuracy: 0.0000e+00 - val_loss: 56.4444 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.6856 - accuracy: 0.0000e+00 - val_loss: 64.6318 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.8922 - accuracy: 0.0000e+00 - val_loss: 57.5279 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.9015 - accuracy: 0.0000e+00 - val_loss: 67.6510 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.8566 - accuracy: 0.0000e+00 - val_loss: 60.5683 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.7114 - accuracy: 0.0000e+00 - val_loss: 61.4102 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.2116 - accuracy: 0.0000e+00 - val_loss: 58.8148 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7143 - accuracy: 0.0000e+00 - val_loss: 66.7872 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.1443 - accuracy: 0.0000e+00 - val_loss: 60.2258 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.1114 - accuracy: 0.0000e+00 - val_loss: 61.4693 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 47.4877 - accuracy: 0.0000e+00 - val_loss: 59.1648 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.8769 - accuracy: 0.0000e+00 - val_loss: 56.5038 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.2984 - accuracy: 0.0000e+00 - val_loss: 59.5701 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3227 - accuracy: 0.0000e+00 - val_loss: 61.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.8485 - accuracy: 0.0000e+00 - val_loss: 57.3555 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.9905 - accuracy: 0.0000e+00 - val_loss: 56.3600 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.3847 - accuracy: 0.0000e+00 - val_loss: 55.9507 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.5643 - accuracy: 0.0000e+00 - val_loss: 55.8202 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.8906 - accuracy: 0.0000e+00 - val_loss: 59.6829 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.1437 - accuracy: 0.0000e+00 - val_loss: 58.5776 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 46.4061 - accuracy: 0.0000e+00 - val_loss: 58.0542 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6027 - accuracy: 0.0000e+00 - val_loss: 56.3248 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.6475 - accuracy: 0.0000e+00 - val_loss: 58.1160 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3324 - accuracy: 0.0000e+00 - val_loss: 55.9916 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.1642 - accuracy: 0.0000e+00 - val_loss: 57.5784 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6887 - accuracy: 0.0000e+00 - val_loss: 55.8291 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.9738 - accuracy: 0.0000e+00 - val_loss: 60.5843 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9491 - accuracy: 0.0000e+00 - val_loss: 58.4098 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.7256 - accuracy: 0.0000e+00 - val_loss: 56.3745 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 49.5073 - accuracy: 0.0000e+00 - val_loss: 57.8644 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.5949 - accuracy: 0.0000e+00 - val_loss: 60.2055 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7441 - accuracy: 0.0000e+00 - val_loss: 57.3901 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.4102 - accuracy: 0.0000e+00 - val_loss: 69.9361 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5643 - accuracy: 0.0000e+00 - val_loss: 59.3284 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.2528 - accuracy: 0.0000e+00 - val_loss: 56.3895 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.6818 - accuracy: 0.0000e+00 - val_loss: 56.0731 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.3342 - accuracy: 0.0000e+00 - val_loss: 55.8805 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.8370 - accuracy: 0.0000e+00 - val_loss: 59.9297 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1803 - accuracy: 0.0000e+00 - val_loss: 56.2340 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8090 - accuracy: 0.0000e+00 - val_loss: 56.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.5486 - accuracy: 0.0000e+00 - val_loss: 56.4623 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2043 - accuracy: 0.0000e+00 - val_loss: 62.2688 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.4996 - accuracy: 0.0000e+00 - val_loss: 58.4332 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.5338 - accuracy: 0.0000e+00 - val_loss: 56.1633 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9623 - accuracy: 0.0000e+00 - val_loss: 57.7313 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1132 - accuracy: 0.0000e+00 - val_loss: 57.8658 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.7942 - accuracy: 0.0000e+00 - val_loss: 59.5715 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9613 - accuracy: 0.0000e+00 - val_loss: 57.9464 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.2410 - accuracy: 0.0000e+00 - val_loss: 64.3808 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2729 - accuracy: 0.0000e+00 - val_loss: 55.7552 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.5073 - accuracy: 0.0000e+00 - val_loss: 56.5231 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.4978 - accuracy: 0.0000e+00 - val_loss: 63.3760 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.5535 - accuracy: 0.0000e+00 - val_loss: 56.8680 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.7253 - accuracy: 0.0000e+00 - val_loss: 64.7130 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.3612 - accuracy: 0.0000e+00 - val_loss: 61.5458 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.7065 - accuracy: 0.0000e+00 - val_loss: 60.8596 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.7681 - accuracy: 0.0000e+00 - val_loss: 59.0474 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.6951 - accuracy: 0.0000e+00 - val_loss: 66.3190 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 50.2433 - accuracy: 0.0000e+00 - val_loss: 59.2282 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 52.7211 - accuracy: 0.0000e+00 - val_loss: 59.9170 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.2351 - accuracy: 0.0000e+00 - val_loss: 59.2624 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.7387 - accuracy: 0.0000e+00 - val_loss: 57.1468 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.2207 - accuracy: 0.0000e+00 - val_loss: 59.8965 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.4168 - accuracy: 0.0000e+00 - val_loss: 61.2704 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.8860 - accuracy: 0.0000e+00 - val_loss: 57.1890 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.8154 - accuracy: 0.0000e+00 - val_loss: 56.2627 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.2955 - accuracy: 0.0000e+00 - val_loss: 55.8376 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.4002 - accuracy: 0.0000e+00 - val_loss: 55.7401 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7434 - accuracy: 0.0000e+00 - val_loss: 60.0140 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0994 - accuracy: 0.0000e+00 - val_loss: 58.5678 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3544 - accuracy: 0.0000e+00 - val_loss: 58.3503 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5799 - accuracy: 0.0000e+00 - val_loss: 56.2418 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.4990 - accuracy: 0.0000e+00 - val_loss: 57.8166 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2119 - accuracy: 0.0000e+00 - val_loss: 56.0967 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.2017 - accuracy: 0.0000e+00 - val_loss: 57.8723 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.5558 - accuracy: 0.0000e+00 - val_loss: 55.7813 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.6080 - accuracy: 0.0000e+00 - val_loss: 59.5853 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.4448 - accuracy: 0.0000e+00 - val_loss: 57.9020 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 45.5034 - accuracy: 0.0000e+00 - val_loss: 56.3033 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 49.2918 - accuracy: 0.0000e+00 - val_loss: 58.6733 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.2154 - accuracy: 0.0000e+00 - val_loss: 60.9441 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7708 - accuracy: 0.0000e+00 - val_loss: 57.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.2591 - accuracy: 0.0000e+00 - val_loss: 68.6690 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.3108 - accuracy: 0.0000e+00 - val_loss: 59.4301 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1398 - accuracy: 0.0000e+00 - val_loss: 56.4883 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.3785 - accuracy: 0.0000e+00 - val_loss: 55.8322 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.0179 - accuracy: 0.0000e+00 - val_loss: 55.8760 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5974 - accuracy: 0.0000e+00 - val_loss: 60.6691 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9295 - accuracy: 0.0000e+00 - val_loss: 56.2237 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.6995 - accuracy: 0.0000e+00 - val_loss: 55.8283 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.4543 - accuracy: 0.0000e+00 - val_loss: 56.6602 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.8302 - accuracy: 0.0000e+00 - val_loss: 61.0773 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.8811 - accuracy: 0.0000e+00 - val_loss: 57.6750 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.1040 - accuracy: 0.0000e+00 - val_loss: 56.0262 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7467 - accuracy: 0.0000e+00 - val_loss: 57.6133 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1502 - accuracy: 0.0000e+00 - val_loss: 58.0800 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.8449 - accuracy: 0.0000e+00 - val_loss: 59.2540 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8752 - accuracy: 0.0000e+00 - val_loss: 58.6314 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.1593 - accuracy: 0.0000e+00 - val_loss: 62.6350 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.7951 - accuracy: 0.0000e+00 - val_loss: 55.6657 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3928 - accuracy: 0.0000e+00 - val_loss: 56.9129 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.4267 - accuracy: 0.0000e+00 - val_loss: 62.5643 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.3045 - accuracy: 0.0000e+00 - val_loss: 56.5171 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 53.5335 - accuracy: 0.0000e+00 - val_loss: 62.6889 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.9899 - accuracy: 0.0000e+00 - val_loss: 62.5653 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7627 - accuracy: 0.0000e+00 - val_loss: 60.3655 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4080 - accuracy: 0.0000e+00 - val_loss: 59.1697 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6649 - accuracy: 0.0000e+00 - val_loss: 65.8709 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 50.2638 - accuracy: 0.0000e+00 - val_loss: 58.3626 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 52.2259 - accuracy: 0.0000e+00 - val_loss: 58.7235 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.0875 - accuracy: 0.0000e+00 - val_loss: 59.2234 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.7831 - accuracy: 0.0000e+00 - val_loss: 57.9082 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.2080 - accuracy: 0.0000e+00 - val_loss: 60.0467 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.4720 - accuracy: 0.0000e+00 - val_loss: 61.9610 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.9278 - accuracy: 0.0000e+00 - val_loss: 56.9476 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6545 - accuracy: 0.0000e+00 - val_loss: 56.2211 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.2038 - accuracy: 0.0000e+00 - val_loss: 55.8308 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3152 - accuracy: 0.0000e+00 - val_loss: 55.7593 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.6332 - accuracy: 0.0000e+00 - val_loss: 60.4141 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0787 - accuracy: 0.0000e+00 - val_loss: 58.6190 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.3487 - accuracy: 0.0000e+00 - val_loss: 58.8081 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5725 - accuracy: 0.0000e+00 - val_loss: 56.1888 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3700 - accuracy: 0.0000e+00 - val_loss: 57.5962 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1178 - accuracy: 0.0000e+00 - val_loss: 56.2848 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.2967 - accuracy: 0.0000e+00 - val_loss: 58.2847 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.4451 - accuracy: 0.0000e+00 - val_loss: 55.7996 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2200 - accuracy: 0.0000e+00 - val_loss: 58.8561 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.0371 - accuracy: 0.0000e+00 - val_loss: 57.6417 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3653 - accuracy: 0.0000e+00 - val_loss: 56.2849 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 49.1874 - accuracy: 0.0000e+00 - val_loss: 59.6581 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.9626 - accuracy: 0.0000e+00 - val_loss: 61.5930 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.8322 - accuracy: 0.0000e+00 - val_loss: 57.2389 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 47.1057 - accuracy: 0.0000e+00 - val_loss: 67.4718 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1458 - accuracy: 0.0000e+00 - val_loss: 59.6274 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0625 - accuracy: 0.0000e+00 - val_loss: 56.6162 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.1509 - accuracy: 0.0000e+00 - val_loss: 55.7431 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7423 - accuracy: 0.0000e+00 - val_loss: 55.9396 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.3762 - accuracy: 0.0000e+00 - val_loss: 61.3579 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7277 - accuracy: 0.0000e+00 - val_loss: 56.1795 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.6155 - accuracy: 0.0000e+00 - val_loss: 55.7265 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.2842 - accuracy: 0.0000e+00 - val_loss: 57.0863 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.4644 - accuracy: 0.0000e+00 - val_loss: 60.2337 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.4423 - accuracy: 0.0000e+00 - val_loss: 57.2369 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8301 - accuracy: 0.0000e+00 - val_loss: 55.9361 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.4803 - accuracy: 0.0000e+00 - val_loss: 58.0004 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.1765 - accuracy: 0.0000e+00 - val_loss: 58.2644 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 47.9061 - accuracy: 0.0000e+00 - val_loss: 58.7043 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.8291 - accuracy: 0.0000e+00 - val_loss: 59.0972 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 49.9619 - accuracy: 0.0000e+00 - val_loss: 61.1303 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 47.3870 - accuracy: 0.0000e+00 - val_loss: 55.5865 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.2569 - accuracy: 0.0000e+00 - val_loss: 57.0490 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 47.2625 - accuracy: 0.0000e+00 - val_loss: 61.7206 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.0253 - accuracy: 0.0000e+00 - val_loss: 56.2205 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 53.2613 - accuracy: 0.0000e+00 - val_loss: 60.7489 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 49.5971 - accuracy: 0.0000e+00 - val_loss: 63.4390 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.8304 - accuracy: 0.0000e+00 - val_loss: 59.6175 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 46.1375 - accuracy: 0.0000e+00 - val_loss: 59.2794 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 46.6573 - accuracy: 0.0000e+00 - val_loss: 65.4265 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.2976 - accuracy: 0.0000e+00 - val_loss: 57.4857 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 51.6072 - accuracy: 0.0000e+00 - val_loss: 57.6796 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 47.1178 - accuracy: 0.0000e+00 - val_loss: 59.1018 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 53.9263 - accuracy: 0.0000e+00 - val_loss: 59.0438 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 47.2338 - accuracy: 0.0000e+00 - val_loss: 59.9595 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.5857 - accuracy: 0.0000e+00 - val_loss: 62.8145 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.9964 - accuracy: 0.0000e+00 - val_loss: 56.6728 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.4886 - accuracy: 0.0000e+00 - val_loss: 56.2056 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 44.1595 - accuracy: 0.0000e+00 - val_loss: 55.7825 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 45.2367 - accuracy: 0.0000e+00 - val_loss: 55.7416 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 44.5496 - accuracy: 0.0000e+00 - val_loss: 60.8454 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.0985 - accuracy: 0.0000e+00 - val_loss: 58.7479 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 46.4271 - accuracy: 0.0000e+00 - val_loss: 59.3694 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.6283 - accuracy: 0.0000e+00 - val_loss: 56.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2540 - accuracy: 0.0000e+00 - val_loss: 57.3276 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0493 - accuracy: 0.0000e+00 - val_loss: 56.3866 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.3990 - accuracy: 0.0000e+00 - val_loss: 58.9532 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3775 - accuracy: 0.0000e+00 - val_loss: 55.7947 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.9541 - accuracy: 0.0000e+00 - val_loss: 58.5220 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7897 - accuracy: 0.0000e+00 - val_loss: 57.5087 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1479 - accuracy: 0.0000e+00 - val_loss: 56.2635 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 48.9865 - accuracy: 0.0000e+00 - val_loss: 60.5232 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 46.6883 - accuracy: 0.0000e+00 - val_loss: 62.0300 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 44.9040 - accuracy: 0.0000e+00 - val_loss: 57.0380 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 46.8837 - accuracy: 0.0000e+00 - val_loss: 66.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9551 - accuracy: 0.0000e+00 - val_loss: 59.3707 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9405 - accuracy: 0.0000e+00 - val_loss: 56.7643 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.8360 - accuracy: 0.0000e+00 - val_loss: 55.6993 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 45.5170 - accuracy: 0.0000e+00 - val_loss: 56.0292 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 46.1722 - accuracy: 0.0000e+00 - val_loss: 61.9180 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 45.5381 - accuracy: 0.0000e+00 - val_loss: 56.1600 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.5367 - accuracy: 0.0000e+00 - val_loss: 55.6782 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.2654 - accuracy: 0.0000e+00 - val_loss: 58.0427 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.1617 - accuracy: 0.0000e+00 - val_loss: 59.4770 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.8478 - accuracy: 0.0000e+00 - val_loss: 56.9340 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4852 - accuracy: 0.0000e+00 - val_loss: 55.8692 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2579 - accuracy: 0.0000e+00 - val_loss: 58.1422 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2050 - accuracy: 0.0000e+00 - val_loss: 58.5553 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.0483 - accuracy: 0.0000e+00 - val_loss: 58.1948 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.7992 - accuracy: 0.0000e+00 - val_loss: 59.5108 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.6770 - accuracy: 0.0000e+00 - val_loss: 59.9250 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.0022 - accuracy: 0.0000e+00 - val_loss: 55.6047 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1115 - accuracy: 0.0000e+00 - val_loss: 57.1936 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.0779 - accuracy: 0.0000e+00 - val_loss: 61.0988 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.8724 - accuracy: 0.0000e+00 - val_loss: 56.0252 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 52.9174 - accuracy: 0.0000e+00 - val_loss: 59.2960 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.2642 - accuracy: 0.0000e+00 - val_loss: 64.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8818 - accuracy: 0.0000e+00 - val_loss: 58.7606 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.9008 - accuracy: 0.0000e+00 - val_loss: 59.2243 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5558 - accuracy: 0.0000e+00 - val_loss: 64.4962 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.1836 - accuracy: 0.0000e+00 - val_loss: 56.7555 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.9357 - accuracy: 0.0000e+00 - val_loss: 56.9587 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.1921 - accuracy: 0.0000e+00 - val_loss: 58.6488 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.8845 - accuracy: 0.0000e+00 - val_loss: 60.3710 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.2740 - accuracy: 0.0000e+00 - val_loss: 59.4872 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6856 - accuracy: 0.0000e+00 - val_loss: 63.8956 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.1164 - accuracy: 0.0000e+00 - val_loss: 56.2728 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3275 - accuracy: 0.0000e+00 - val_loss: 56.1309 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.1030 - accuracy: 0.0000e+00 - val_loss: 55.7391 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2012 - accuracy: 0.0000e+00 - val_loss: 55.7020 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.4798 - accuracy: 0.0000e+00 - val_loss: 61.4544 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1673 - accuracy: 0.0000e+00 - val_loss: 58.7857 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4831 - accuracy: 0.0000e+00 - val_loss: 59.8936 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7778 - accuracy: 0.0000e+00 - val_loss: 56.0461 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1219 - accuracy: 0.0000e+00 - val_loss: 56.9913 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9201 - accuracy: 0.0000e+00 - val_loss: 56.3879 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.5353 - accuracy: 0.0000e+00 - val_loss: 59.7501 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.4240 - accuracy: 0.0000e+00 - val_loss: 55.8387 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.5796 - accuracy: 0.0000e+00 - val_loss: 57.5525 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.3176 - accuracy: 0.0000e+00 - val_loss: 57.0866 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0997 - accuracy: 0.0000e+00 - val_loss: 56.1016 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.9283 - accuracy: 0.0000e+00 - val_loss: 61.8322 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.4713 - accuracy: 0.0000e+00 - val_loss: 62.3101 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0313 - accuracy: 0.0000e+00 - val_loss: 56.4607 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5460 - accuracy: 0.0000e+00 - val_loss: 64.1488 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7302 - accuracy: 0.0000e+00 - val_loss: 59.5845 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.1063 - accuracy: 0.0000e+00 - val_loss: 57.0455 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.6206 - accuracy: 0.0000e+00 - val_loss: 55.6954 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1788 - accuracy: 0.0000e+00 - val_loss: 55.9674 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8195 - accuracy: 0.0000e+00 - val_loss: 62.3869 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3429 - accuracy: 0.0000e+00 - val_loss: 56.1242 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5921 - accuracy: 0.0000e+00 - val_loss: 55.5571 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.2202 - accuracy: 0.0000e+00 - val_loss: 59.4082 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7036 - accuracy: 0.0000e+00 - val_loss: 58.6161 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.1609 - accuracy: 0.0000e+00 - val_loss: 56.6154 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1616 - accuracy: 0.0000e+00 - val_loss: 55.9147 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8609 - accuracy: 0.0000e+00 - val_loss: 58.3968 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2057 - accuracy: 0.0000e+00 - val_loss: 59.0108 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.3162 - accuracy: 0.0000e+00 - val_loss: 56.9736 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6265 - accuracy: 0.0000e+00 - val_loss: 60.3131 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.9205 - accuracy: 0.0000e+00 - val_loss: 58.4216 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.4375 - accuracy: 0.0000e+00 - val_loss: 55.5252 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.0034 - accuracy: 0.0000e+00 - val_loss: 57.2677 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.0009 - accuracy: 0.0000e+00 - val_loss: 60.2062 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.6328 - accuracy: 0.0000e+00 - val_loss: 55.8798 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 52.3707 - accuracy: 0.0000e+00 - val_loss: 57.6001 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.7610 - accuracy: 0.0000e+00 - val_loss: 63.9500 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.9771 - accuracy: 0.0000e+00 - val_loss: 57.1287 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.7273 - accuracy: 0.0000e+00 - val_loss: 59.3029 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6854 - accuracy: 0.0000e+00 - val_loss: 63.3440 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.0620 - accuracy: 0.0000e+00 - val_loss: 55.9118 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.6314 - accuracy: 0.0000e+00 - val_loss: 56.2361 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.3886 - accuracy: 0.0000e+00 - val_loss: 57.8456 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 54.0053 - accuracy: 0.0000e+00 - val_loss: 62.5377 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.4179 - accuracy: 0.0000e+00 - val_loss: 58.5128 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9073 - accuracy: 0.0000e+00 - val_loss: 65.4468 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2081 - accuracy: 0.0000e+00 - val_loss: 55.6477 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0550 - accuracy: 0.0000e+00 - val_loss: 56.1554 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.0162 - accuracy: 0.0000e+00 - val_loss: 55.7265 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.1609 - accuracy: 0.0000e+00 - val_loss: 55.7244 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.3693 - accuracy: 0.0000e+00 - val_loss: 62.4471 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2249 - accuracy: 0.0000e+00 - val_loss: 58.9416 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5641 - accuracy: 0.0000e+00 - val_loss: 60.5640 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9135 - accuracy: 0.0000e+00 - val_loss: 56.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9828 - accuracy: 0.0000e+00 - val_loss: 56.7805 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 44.7102 - accuracy: 0.0000e+00 - val_loss: 56.3853 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7272 - accuracy: 0.0000e+00 - val_loss: 61.0246 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.3802 - accuracy: 0.0000e+00 - val_loss: 55.9916 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8145 - accuracy: 0.0000e+00 - val_loss: 57.1165 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.9644 - accuracy: 0.0000e+00 - val_loss: 57.0970 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9801 - accuracy: 0.0000e+00 - val_loss: 56.0076 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 48.6549 - accuracy: 0.0000e+00 - val_loss: 62.9928 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.0155 - accuracy: 0.0000e+00 - val_loss: 62.0225 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0385 - accuracy: 0.0000e+00 - val_loss: 56.0185 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0170 - accuracy: 0.0000e+00 - val_loss: 62.6431 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.4887 - accuracy: 0.0000e+00 - val_loss: 59.7048 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.1577 - accuracy: 0.0000e+00 - val_loss: 57.3303 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.1803 - accuracy: 0.0000e+00 - val_loss: 55.9307 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8788 - accuracy: 0.0000e+00 - val_loss: 56.1774 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.4738 - accuracy: 0.0000e+00 - val_loss: 62.6342 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1154 - accuracy: 0.0000e+00 - val_loss: 56.2772 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5272 - accuracy: 0.0000e+00 - val_loss: 55.6111 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.9966 - accuracy: 0.0000e+00 - val_loss: 60.6835 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.4414 - accuracy: 0.0000e+00 - val_loss: 58.3217 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.6934 - accuracy: 0.0000e+00 - val_loss: 56.5628 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7979 - accuracy: 0.0000e+00 - val_loss: 56.0328 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5998 - accuracy: 0.0000e+00 - val_loss: 58.4607 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2812 - accuracy: 0.0000e+00 - val_loss: 59.4506 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.2870 - accuracy: 0.0000e+00 - val_loss: 56.3137 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3646 - accuracy: 0.0000e+00 - val_loss: 61.1509 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2405 - accuracy: 0.0000e+00 - val_loss: 57.5255 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.7998 - accuracy: 0.0000e+00 - val_loss: 55.7160 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7928 - accuracy: 0.0000e+00 - val_loss: 57.5726 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.6584 - accuracy: 0.0000e+00 - val_loss: 59.4404 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.0956 - accuracy: 0.0000e+00 - val_loss: 56.2528 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 51.3096 - accuracy: 0.0000e+00 - val_loss: 57.0992 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.0992 - accuracy: 0.0000e+00 - val_loss: 63.3694 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7383 - accuracy: 0.0000e+00 - val_loss: 56.6990 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.7774 - accuracy: 0.0000e+00 - val_loss: 60.0902 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4633 - accuracy: 0.0000e+00 - val_loss: 62.4021 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.7144 - accuracy: 0.0000e+00 - val_loss: 56.2581 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.3539 - accuracy: 0.0000e+00 - val_loss: 56.8326 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.0366 - accuracy: 0.0000e+00 - val_loss: 57.9398 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 53.4509 - accuracy: 0.0000e+00 - val_loss: 64.1918 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.3144 - accuracy: 0.0000e+00 - val_loss: 58.2007 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.9777 - accuracy: 0.0000e+00 - val_loss: 67.0981 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9269 - accuracy: 0.0000e+00 - val_loss: 55.9737 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7262 - accuracy: 0.0000e+00 - val_loss: 56.8963 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 43.7673 - accuracy: 0.0000e+00 - val_loss: 56.2806 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 44.7998 - accuracy: 0.0000e+00 - val_loss: 56.2415 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 44.0776 - accuracy: 0.0000e+00 - val_loss: 63.8681 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.0652 - accuracy: 0.0000e+00 - val_loss: 59.8702 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.5516 - accuracy: 0.0000e+00 - val_loss: 61.9602 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8508 - accuracy: 0.0000e+00 - val_loss: 56.5405 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5625 - accuracy: 0.0000e+00 - val_loss: 57.0769 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3297 - accuracy: 0.0000e+00 - val_loss: 56.8849 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7438 - accuracy: 0.0000e+00 - val_loss: 62.8711 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2872 - accuracy: 0.0000e+00 - val_loss: 56.7115 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0143 - accuracy: 0.0000e+00 - val_loss: 57.4857 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5121 - accuracy: 0.0000e+00 - val_loss: 57.3619 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.4851 - accuracy: 0.0000e+00 - val_loss: 56.5103 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 48.0470 - accuracy: 0.0000e+00 - val_loss: 64.5598 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.5611 - accuracy: 0.0000e+00 - val_loss: 61.8372 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.8742 - accuracy: 0.0000e+00 - val_loss: 56.1793 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2846 - accuracy: 0.0000e+00 - val_loss: 61.8123 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1201 - accuracy: 0.0000e+00 - val_loss: 59.6848 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5795 - accuracy: 0.0000e+00 - val_loss: 57.9156 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.5066 - accuracy: 0.0000e+00 - val_loss: 56.6462 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.2251 - accuracy: 0.0000e+00 - val_loss: 56.4311 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.5840 - accuracy: 0.0000e+00 - val_loss: 62.5709 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7681 - accuracy: 0.0000e+00 - val_loss: 57.0130 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.4264 - accuracy: 0.0000e+00 - val_loss: 56.1123 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.7396 - accuracy: 0.0000e+00 - val_loss: 62.7399 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1480 - accuracy: 0.0000e+00 - val_loss: 58.4997 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.9316 - accuracy: 0.0000e+00 - val_loss: 57.1274 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2206 - accuracy: 0.0000e+00 - val_loss: 56.3060 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.4389 - accuracy: 0.0000e+00 - val_loss: 58.0937 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2644 - accuracy: 0.0000e+00 - val_loss: 60.1895 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.1602 - accuracy: 0.0000e+00 - val_loss: 56.4979 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2135 - accuracy: 0.0000e+00 - val_loss: 62.6409 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.7425 - accuracy: 0.0000e+00 - val_loss: 57.7060 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3202 - accuracy: 0.0000e+00 - val_loss: 56.2116 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5061 - accuracy: 0.0000e+00 - val_loss: 57.9763 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.3595 - accuracy: 0.0000e+00 - val_loss: 59.3910 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.6352 - accuracy: 0.0000e+00 - val_loss: 56.7395 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.6284 - accuracy: 0.0000e+00 - val_loss: 57.1108 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.5213 - accuracy: 0.0000e+00 - val_loss: 62.7937 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.3373 - accuracy: 0.0000e+00 - val_loss: 56.7311 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.6235 - accuracy: 0.0000e+00 - val_loss: 60.9501 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.2416 - accuracy: 0.0000e+00 - val_loss: 61.6842 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.0345 - accuracy: 0.0000e+00 - val_loss: 56.8099 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.6661 - accuracy: 0.0000e+00 - val_loss: 57.2266 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.8179 - accuracy: 0.0000e+00 - val_loss: 57.8669 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 52.7606 - accuracy: 0.0000e+00 - val_loss: 64.0257 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8352 - accuracy: 0.0000e+00 - val_loss: 57.7708 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.5687 - accuracy: 0.0000e+00 - val_loss: 66.5063 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 47.2875 - accuracy: 0.0000e+00 - val_loss: 56.0650 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3895 - accuracy: 0.0000e+00 - val_loss: 56.9371 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5213 - accuracy: 0.0000e+00 - val_loss: 56.2803 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.5489 - accuracy: 0.0000e+00 - val_loss: 56.2464 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.8073 - accuracy: 0.0000e+00 - val_loss: 64.0436 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9210 - accuracy: 0.0000e+00 - val_loss: 60.4826 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.5819 - accuracy: 0.0000e+00 - val_loss: 62.5589 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8662 - accuracy: 0.0000e+00 - val_loss: 56.6799 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3963 - accuracy: 0.0000e+00 - val_loss: 57.1584 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.1054 - accuracy: 0.0000e+00 - val_loss: 56.8962 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5631 - accuracy: 0.0000e+00 - val_loss: 63.2160 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1847 - accuracy: 0.0000e+00 - val_loss: 56.7221 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7390 - accuracy: 0.0000e+00 - val_loss: 57.3091 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3371 - accuracy: 0.0000e+00 - val_loss: 57.3786 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.2264 - accuracy: 0.0000e+00 - val_loss: 56.6548 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.8172 - accuracy: 0.0000e+00 - val_loss: 65.1480 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.3258 - accuracy: 0.0000e+00 - val_loss: 61.2285 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.7464 - accuracy: 0.0000e+00 - val_loss: 56.1521 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0005 - accuracy: 0.0000e+00 - val_loss: 61.7876 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.8938 - accuracy: 0.0000e+00 - val_loss: 59.6231 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2741 - accuracy: 0.0000e+00 - val_loss: 57.9417 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.3750 - accuracy: 0.0000e+00 - val_loss: 56.7966 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.0750 - accuracy: 0.0000e+00 - val_loss: 56.5239 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.4837 - accuracy: 0.0000e+00 - val_loss: 62.8362 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.6277 - accuracy: 0.0000e+00 - val_loss: 57.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2021 - accuracy: 0.0000e+00 - val_loss: 56.0679 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 49.4322 - accuracy: 0.0000e+00 - val_loss: 62.8742 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0031 - accuracy: 0.0000e+00 - val_loss: 58.4552 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.7881 - accuracy: 0.0000e+00 - val_loss: 57.0569 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0499 - accuracy: 0.0000e+00 - val_loss: 56.2674 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.1949 - accuracy: 0.0000e+00 - val_loss: 58.0787 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0982 - accuracy: 0.0000e+00 - val_loss: 60.2040 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.0948 - accuracy: 0.0000e+00 - val_loss: 56.5364 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1656 - accuracy: 0.0000e+00 - val_loss: 62.9939 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 47.5544 - accuracy: 0.0000e+00 - val_loss: 57.7529 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2893 - accuracy: 0.0000e+00 - val_loss: 56.1252 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.4086 - accuracy: 0.0000e+00 - val_loss: 57.9692 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.3092 - accuracy: 0.0000e+00 - val_loss: 59.5381 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.6048 - accuracy: 0.0000e+00 - val_loss: 56.7892 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 50.4039 - accuracy: 0.0000e+00 - val_loss: 56.9832 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.3969 - accuracy: 0.0000e+00 - val_loss: 62.7903 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1972 - accuracy: 0.0000e+00 - val_loss: 56.6157 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5653 - accuracy: 0.0000e+00 - val_loss: 61.2392 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.2124 - accuracy: 0.0000e+00 - val_loss: 61.4082 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.8577 - accuracy: 0.0000e+00 - val_loss: 56.9401 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.3574 - accuracy: 0.0000e+00 - val_loss: 57.0888 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7597 - accuracy: 0.0000e+00 - val_loss: 57.5765 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 52.4475 - accuracy: 0.0000e+00 - val_loss: 64.1906 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6234 - accuracy: 0.0000e+00 - val_loss: 57.4910 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.4008 - accuracy: 0.0000e+00 - val_loss: 66.1404 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.0167 - accuracy: 0.0000e+00 - val_loss: 56.0509 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.2426 - accuracy: 0.0000e+00 - val_loss: 56.8902 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.4191 - accuracy: 0.0000e+00 - val_loss: 56.1953 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 44.4465 - accuracy: 0.0000e+00 - val_loss: 56.1089 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.6610 - accuracy: 0.0000e+00 - val_loss: 64.0471 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.8652 - accuracy: 0.0000e+00 - val_loss: 60.6270 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5494 - accuracy: 0.0000e+00 - val_loss: 62.8469 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9158 - accuracy: 0.0000e+00 - val_loss: 56.8200 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 44.3711 - accuracy: 0.0000e+00 - val_loss: 57.1856 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.9615 - accuracy: 0.0000e+00 - val_loss: 56.8153 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4446 - accuracy: 0.0000e+00 - val_loss: 63.4261 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1399 - accuracy: 0.0000e+00 - val_loss: 56.7863 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.5510 - accuracy: 0.0000e+00 - val_loss: 57.3328 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2321 - accuracy: 0.0000e+00 - val_loss: 57.2486 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.1260 - accuracy: 0.0000e+00 - val_loss: 56.5666 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 47.7194 - accuracy: 0.0000e+00 - val_loss: 65.5062 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2160 - accuracy: 0.0000e+00 - val_loss: 60.6639 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.4572 - accuracy: 0.0000e+00 - val_loss: 55.9358 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9181 - accuracy: 0.0000e+00 - val_loss: 61.6036 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8156 - accuracy: 0.0000e+00 - val_loss: 59.4330 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2090 - accuracy: 0.0000e+00 - val_loss: 57.8432 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.1933 - accuracy: 0.0000e+00 - val_loss: 56.7156 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.0281 - accuracy: 0.0000e+00 - val_loss: 56.3607 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3655 - accuracy: 0.0000e+00 - val_loss: 62.7887 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5342 - accuracy: 0.0000e+00 - val_loss: 56.8745 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0954 - accuracy: 0.0000e+00 - val_loss: 55.9780 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 49.2776 - accuracy: 0.0000e+00 - val_loss: 63.2611 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9621 - accuracy: 0.0000e+00 - val_loss: 58.5192 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.6930 - accuracy: 0.0000e+00 - val_loss: 57.0237 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9736 - accuracy: 0.0000e+00 - val_loss: 56.1424 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.2157 - accuracy: 0.0000e+00 - val_loss: 57.9228 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.0385 - accuracy: 0.0000e+00 - val_loss: 60.4036 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.1701 - accuracy: 0.0000e+00 - val_loss: 56.3965 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0778 - accuracy: 0.0000e+00 - val_loss: 63.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.3498 - accuracy: 0.0000e+00 - val_loss: 57.6057 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.2440 - accuracy: 0.0000e+00 - val_loss: 56.0419 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.3856 - accuracy: 0.0000e+00 - val_loss: 57.8223 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1497 - accuracy: 0.0000e+00 - val_loss: 59.2384 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 47.4263 - accuracy: 0.0000e+00 - val_loss: 56.7655 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.0904 - accuracy: 0.0000e+00 - val_loss: 56.7532 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 47.2294 - accuracy: 0.0000e+00 - val_loss: 62.3362 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.0720 - accuracy: 0.0000e+00 - val_loss: 56.2799 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.6618 - accuracy: 0.0000e+00 - val_loss: 61.6353 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.3148 - accuracy: 0.0000e+00 - val_loss: 60.8096 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 48.7490 - accuracy: 0.0000e+00 - val_loss: 56.9630 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.8547 - accuracy: 0.0000e+00 - val_loss: 57.0313 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.6916 - accuracy: 0.0000e+00 - val_loss: 57.2501 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 52.1362 - accuracy: 0.0000e+00 - val_loss: 64.2389 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.4830 - accuracy: 0.0000e+00 - val_loss: 57.0697 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3055 - accuracy: 0.0000e+00 - val_loss: 65.8402 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7837 - accuracy: 0.0000e+00 - val_loss: 56.1197 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 44.1262 - accuracy: 0.0000e+00 - val_loss: 56.8824 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.3560 - accuracy: 0.0000e+00 - val_loss: 56.2113 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.4183 - accuracy: 0.0000e+00 - val_loss: 56.1514 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5923 - accuracy: 0.0000e+00 - val_loss: 64.5491 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9455 - accuracy: 0.0000e+00 - val_loss: 60.8325 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.5898 - accuracy: 0.0000e+00 - val_loss: 63.0751 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9549 - accuracy: 0.0000e+00 - val_loss: 56.7787 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.2791 - accuracy: 0.0000e+00 - val_loss: 57.0351 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.8404 - accuracy: 0.0000e+00 - val_loss: 56.6195 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.3230 - accuracy: 0.0000e+00 - val_loss: 64.0893 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2912 - accuracy: 0.0000e+00 - val_loss: 57.0674 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.3059 - accuracy: 0.0000e+00 - val_loss: 57.2765 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1949 - accuracy: 0.0000e+00 - val_loss: 57.2052 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.0114 - accuracy: 0.0000e+00 - val_loss: 56.4819 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.3892 - accuracy: 0.0000e+00 - val_loss: 65.3094 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.9967 - accuracy: 0.0000e+00 - val_loss: 60.2739 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.5002 - accuracy: 0.0000e+00 - val_loss: 55.8726 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.7705 - accuracy: 0.0000e+00 - val_loss: 61.4194 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7482 - accuracy: 0.0000e+00 - val_loss: 59.3298 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.2180 - accuracy: 0.0000e+00 - val_loss: 57.9222 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.9162 - accuracy: 0.0000e+00 - val_loss: 56.6547 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 43.9287 - accuracy: 0.0000e+00 - val_loss: 56.1485 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.2800 - accuracy: 0.0000e+00 - val_loss: 62.8308 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.5167 - accuracy: 0.0000e+00 - val_loss: 56.8310 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0407 - accuracy: 0.0000e+00 - val_loss: 56.0411 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.0503 - accuracy: 0.0000e+00 - val_loss: 63.5580 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.8188 - accuracy: 0.0000e+00 - val_loss: 58.7326 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6943 - accuracy: 0.0000e+00 - val_loss: 57.0522 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9025 - accuracy: 0.0000e+00 - val_loss: 56.0523 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.1848 - accuracy: 0.0000e+00 - val_loss: 57.6346 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0127 - accuracy: 0.0000e+00 - val_loss: 60.3069 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2060 - accuracy: 0.0000e+00 - val_loss: 56.3287 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9635 - accuracy: 0.0000e+00 - val_loss: 62.8908 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.1311 - accuracy: 0.0000e+00 - val_loss: 57.3939 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1869 - accuracy: 0.0000e+00 - val_loss: 55.8546 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.3326 - accuracy: 0.0000e+00 - val_loss: 57.8333 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0311 - accuracy: 0.0000e+00 - val_loss: 58.8600 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.1917 - accuracy: 0.0000e+00 - val_loss: 56.8554 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.6072 - accuracy: 0.0000e+00 - val_loss: 56.6229 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.1140 - accuracy: 0.0000e+00 - val_loss: 62.1942 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0330 - accuracy: 0.0000e+00 - val_loss: 56.0248 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7386 - accuracy: 0.0000e+00 - val_loss: 62.1442 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.4413 - accuracy: 0.0000e+00 - val_loss: 59.7209 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.4765 - accuracy: 0.0000e+00 - val_loss: 57.2607 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4601 - accuracy: 0.0000e+00 - val_loss: 56.7116 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5878 - accuracy: 0.0000e+00 - val_loss: 56.6633 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 51.6586 - accuracy: 0.0000e+00 - val_loss: 63.9642 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.2672 - accuracy: 0.0000e+00 - val_loss: 56.4405 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1310 - accuracy: 0.0000e+00 - val_loss: 65.2687 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 46.5508 - accuracy: 0.0000e+00 - val_loss: 55.9812 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.0155 - accuracy: 0.0000e+00 - val_loss: 56.5735 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.3011 - accuracy: 0.0000e+00 - val_loss: 56.0231 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3383 - accuracy: 0.0000e+00 - val_loss: 55.9855 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.5554 - accuracy: 0.0000e+00 - val_loss: 64.7571 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.0433 - accuracy: 0.0000e+00 - val_loss: 60.7768 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 46.6957 - accuracy: 0.0000e+00 - val_loss: 63.2139 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 46.0403 - accuracy: 0.0000e+00 - val_loss: 56.5627 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.1727 - accuracy: 0.0000e+00 - val_loss: 56.9044 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 43.7438 - accuracy: 0.0000e+00 - val_loss: 56.1962 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 46.0587 - accuracy: 0.0000e+00 - val_loss: 64.3018 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.4806 - accuracy: 0.0000e+00 - val_loss: 57.2337 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.1321 - accuracy: 0.0000e+00 - val_loss: 57.0902 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.1253 - accuracy: 0.0000e+00 - val_loss: 56.9516 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 43.9211 - accuracy: 0.0000e+00 - val_loss: 56.2451 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 47.2983 - accuracy: 0.0000e+00 - val_loss: 65.3677 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 44.8680 - accuracy: 0.0000e+00 - val_loss: 59.5575 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 44.3813 - accuracy: 0.0000e+00 - val_loss: 55.7648 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 44.7182 - accuracy: 0.0000e+00 - val_loss: 61.1551 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 44.7368 - accuracy: 0.0000e+00 - val_loss: 59.3470 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 45.2408 - accuracy: 0.0000e+00 - val_loss: 58.0153 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 46.5556 - accuracy: 0.0000e+00 - val_loss: 56.4602 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 43.8245 - accuracy: 0.0000e+00 - val_loss: 55.9242 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 44.1814 - accuracy: 0.0000e+00 - val_loss: 62.4525 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 44.4276 - accuracy: 0.0000e+00 - val_loss: 56.7111 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.1235 - accuracy: 0.0000e+00 - val_loss: 55.8187 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.8743 - accuracy: 0.0000e+00 - val_loss: 63.6684 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.7738 - accuracy: 0.0000e+00 - val_loss: 58.7749 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7702 - accuracy: 0.0000e+00 - val_loss: 57.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8690 - accuracy: 0.0000e+00 - val_loss: 55.8288 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.9965 - accuracy: 0.0000e+00 - val_loss: 57.4237 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9209 - accuracy: 0.0000e+00 - val_loss: 60.2222 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2659 - accuracy: 0.0000e+00 - val_loss: 56.4227 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.8106 - accuracy: 0.0000e+00 - val_loss: 62.7435 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8784 - accuracy: 0.0000e+00 - val_loss: 57.2558 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0650 - accuracy: 0.0000e+00 - val_loss: 55.7404 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.2610 - accuracy: 0.0000e+00 - val_loss: 57.8279 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9006 - accuracy: 0.0000e+00 - val_loss: 58.3856 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.9850 - accuracy: 0.0000e+00 - val_loss: 56.9757 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 49.0914 - accuracy: 0.0000e+00 - val_loss: 56.3593 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8538 - accuracy: 0.0000e+00 - val_loss: 61.4858 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8905 - accuracy: 0.0000e+00 - val_loss: 55.7467 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.8915 - accuracy: 0.0000e+00 - val_loss: 62.9125 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6590 - accuracy: 0.0000e+00 - val_loss: 58.7861 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.2721 - accuracy: 0.0000e+00 - val_loss: 57.5349 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9740 - accuracy: 0.0000e+00 - val_loss: 56.7371 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 46.5069 - accuracy: 0.0000e+00 - val_loss: 56.4460 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 51.1728 - accuracy: 0.0000e+00 - val_loss: 63.4475 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.0024 - accuracy: 0.0000e+00 - val_loss: 56.0520 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.9806 - accuracy: 0.0000e+00 - val_loss: 64.8101 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.2271 - accuracy: 0.0000e+00 - val_loss: 56.2338 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.9408 - accuracy: 0.0000e+00 - val_loss: 56.5309 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.2714 - accuracy: 0.0000e+00 - val_loss: 55.9596 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3265 - accuracy: 0.0000e+00 - val_loss: 56.0161 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.4964 - accuracy: 0.0000e+00 - val_loss: 64.8933 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0700 - accuracy: 0.0000e+00 - val_loss: 61.1368 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8247 - accuracy: 0.0000e+00 - val_loss: 63.8880 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.2290 - accuracy: 0.0000e+00 - val_loss: 56.7096 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.1230 - accuracy: 0.0000e+00 - val_loss: 57.0141 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.6048 - accuracy: 0.0000e+00 - val_loss: 56.1214 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7937 - accuracy: 0.0000e+00 - val_loss: 64.8267 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6558 - accuracy: 0.0000e+00 - val_loss: 58.0132 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8897 - accuracy: 0.0000e+00 - val_loss: 57.3200 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0859 - accuracy: 0.0000e+00 - val_loss: 56.6010 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.7144 - accuracy: 0.0000e+00 - val_loss: 56.3544 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.1850 - accuracy: 0.0000e+00 - val_loss: 65.3201 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.6171 - accuracy: 0.0000e+00 - val_loss: 58.7255 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.1523 - accuracy: 0.0000e+00 - val_loss: 55.7111 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.7121 - accuracy: 0.0000e+00 - val_loss: 60.6874 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7031 - accuracy: 0.0000e+00 - val_loss: 59.6612 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.1188 - accuracy: 0.0000e+00 - val_loss: 58.2821 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0670 - accuracy: 0.0000e+00 - val_loss: 56.4123 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.6461 - accuracy: 0.0000e+00 - val_loss: 55.9718 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.9881 - accuracy: 0.0000e+00 - val_loss: 61.9765 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.2431 - accuracy: 0.0000e+00 - val_loss: 56.6602 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9336 - accuracy: 0.0000e+00 - val_loss: 56.2834 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 48.5432 - accuracy: 0.0000e+00 - val_loss: 63.7185 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.6874 - accuracy: 0.0000e+00 - val_loss: 59.2866 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 46.7946 - accuracy: 0.0000e+00 - val_loss: 57.3763 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7806 - accuracy: 0.0000e+00 - val_loss: 55.7042 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.9759 - accuracy: 0.0000e+00 - val_loss: 57.0955 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.6951 - accuracy: 0.0000e+00 - val_loss: 59.9950 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.9779 - accuracy: 0.0000e+00 - val_loss: 56.8798 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.4972 - accuracy: 0.0000e+00 - val_loss: 62.0321 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.4272 - accuracy: 0.0000e+00 - val_loss: 57.2219 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8554 - accuracy: 0.0000e+00 - val_loss: 55.7069 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.0460 - accuracy: 0.0000e+00 - val_loss: 57.9653 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6812 - accuracy: 0.0000e+00 - val_loss: 58.0786 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.6507 - accuracy: 0.0000e+00 - val_loss: 57.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.0528 - accuracy: 0.0000e+00 - val_loss: 56.2402 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.2970 - accuracy: 0.0000e+00 - val_loss: 60.2495 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5275 - accuracy: 0.0000e+00 - val_loss: 55.7395 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0906 - accuracy: 0.0000e+00 - val_loss: 64.3340 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.8293 - accuracy: 0.0000e+00 - val_loss: 57.3791 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.4047 - accuracy: 0.0000e+00 - val_loss: 58.5169 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1592 - accuracy: 0.0000e+00 - val_loss: 57.0222 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 46.0419 - accuracy: 0.0000e+00 - val_loss: 56.1015 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 50.1306 - accuracy: 0.0000e+00 - val_loss: 62.4533 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 45.4899 - accuracy: 0.0000e+00 - val_loss: 56.0310 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5578 - accuracy: 0.0000e+00 - val_loss: 64.3305 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6177 - accuracy: 0.0000e+00 - val_loss: 56.7837 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.7579 - accuracy: 0.0000e+00 - val_loss: 56.9541 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.9542 - accuracy: 0.0000e+00 - val_loss: 56.1322 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.9992 - accuracy: 0.0000e+00 - val_loss: 56.1449 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.1159 - accuracy: 0.0000e+00 - val_loss: 64.8125 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9692 - accuracy: 0.0000e+00 - val_loss: 62.0813 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.7874 - accuracy: 0.0000e+00 - val_loss: 64.6400 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.2537 - accuracy: 0.0000e+00 - val_loss: 57.2337 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.9573 - accuracy: 0.0000e+00 - val_loss: 57.3307 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.2294 - accuracy: 0.0000e+00 - val_loss: 56.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1216 - accuracy: 0.0000e+00 - val_loss: 64.7949 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8207 - accuracy: 0.0000e+00 - val_loss: 59.5615 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.4505 - accuracy: 0.0000e+00 - val_loss: 57.9238 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7364 - accuracy: 0.0000e+00 - val_loss: 56.1840 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 43.3971 - accuracy: 0.0000e+00 - val_loss: 56.2327 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 46.7515 - accuracy: 0.0000e+00 - val_loss: 64.6746 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.0088 - accuracy: 0.0000e+00 - val_loss: 57.5265 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 43.3931 - accuracy: 0.0000e+00 - val_loss: 55.6964 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.6803 - accuracy: 0.0000e+00 - val_loss: 60.4569 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.4084 - accuracy: 0.0000e+00 - val_loss: 59.2674 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.8766 - accuracy: 0.0000e+00 - val_loss: 58.6173 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.2973 - accuracy: 0.0000e+00 - val_loss: 56.2257 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.1362 - accuracy: 0.0000e+00 - val_loss: 55.9271 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5567 - accuracy: 0.0000e+00 - val_loss: 61.9280 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.8323 - accuracy: 0.0000e+00 - val_loss: 56.7717 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5246 - accuracy: 0.0000e+00 - val_loss: 56.4190 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 47.8482 - accuracy: 0.0000e+00 - val_loss: 63.0475 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1755 - accuracy: 0.0000e+00 - val_loss: 60.1210 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.5452 - accuracy: 0.0000e+00 - val_loss: 57.2348 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.1493 - accuracy: 0.0000e+00 - val_loss: 55.5747 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.3500 - accuracy: 0.0000e+00 - val_loss: 57.1664 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.9107 - accuracy: 0.0000e+00 - val_loss: 59.3399 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 47.2356 - accuracy: 0.0000e+00 - val_loss: 57.0313 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.8638 - accuracy: 0.0000e+00 - val_loss: 60.4206 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9780 - accuracy: 0.0000e+00 - val_loss: 56.6297 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3353 - accuracy: 0.0000e+00 - val_loss: 55.4811 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 43.5063 - accuracy: 0.0000e+00 - val_loss: 57.3845 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.0629 - accuracy: 0.0000e+00 - val_loss: 57.3860 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.8868 - accuracy: 0.0000e+00 - val_loss: 57.3521 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 46.6601 - accuracy: 0.0000e+00 - val_loss: 55.9207 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.6580 - accuracy: 0.0000e+00 - val_loss: 59.5293 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.7804 - accuracy: 0.0000e+00 - val_loss: 55.2310 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.0144 - accuracy: 0.0000e+00 - val_loss: 66.3664 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8399 - accuracy: 0.0000e+00 - val_loss: 55.9134 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 46.1927 - accuracy: 0.0000e+00 - val_loss: 57.4356 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.1580 - accuracy: 0.0000e+00 - val_loss: 56.0237 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2161 - accuracy: 0.0000e+00 - val_loss: 55.9173 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 48.8972 - accuracy: 0.0000e+00 - val_loss: 60.8308 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.8580 - accuracy: 0.0000e+00 - val_loss: 55.0653 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 44.0739 - accuracy: 0.0000e+00 - val_loss: 62.2389 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.6360 - accuracy: 0.0000e+00 - val_loss: 56.5436 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.1039 - accuracy: 0.0000e+00 - val_loss: 55.5146 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.1664 - accuracy: 0.0000e+00 - val_loss: 55.0673 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.1266 - accuracy: 0.0000e+00 - val_loss: 54.9982 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1212 - accuracy: 0.0000e+00 - val_loss: 64.2606 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5084 - accuracy: 0.0000e+00 - val_loss: 61.5281 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9577 - accuracy: 0.0000e+00 - val_loss: 63.6722 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.2905 - accuracy: 0.0000e+00 - val_loss: 56.1030 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.2244 - accuracy: 0.0000e+00 - val_loss: 56.2966 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.4012 - accuracy: 0.0000e+00 - val_loss: 54.3468 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.7147 - accuracy: 0.0000e+00 - val_loss: 64.2206 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.3784 - accuracy: 0.0000e+00 - val_loss: 58.4199 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.6911 - accuracy: 0.0000e+00 - val_loss: 56.9046 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.2381 - accuracy: 0.0000e+00 - val_loss: 54.3215 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.5092 - accuracy: 0.0000e+00 - val_loss: 54.3471 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.1698 - accuracy: 0.0000e+00 - val_loss: 61.0263 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.6483 - accuracy: 0.0000e+00 - val_loss: 55.0682 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.9180 - accuracy: 0.0000e+00 - val_loss: 54.0103 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 43.5627 - accuracy: 0.0000e+00 - val_loss: 58.8917 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 43.7726 - accuracy: 0.0000e+00 - val_loss: 57.2410 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 44.2077 - accuracy: 0.0000e+00 - val_loss: 57.6281 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.9959 - accuracy: 0.0000e+00 - val_loss: 54.8554 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8993 - accuracy: 0.0000e+00 - val_loss: 53.9010 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 42.1419 - accuracy: 0.0000e+00 - val_loss: 61.2201 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.8018 - accuracy: 0.0000e+00 - val_loss: 55.3056 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5436 - accuracy: 0.0000e+00 - val_loss: 54.5053 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.9345 - accuracy: 0.0000e+00 - val_loss: 59.3117 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.0611 - accuracy: 0.0000e+00 - val_loss: 59.5641 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.8402 - accuracy: 0.0000e+00 - val_loss: 56.3215 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.8520 - accuracy: 0.0000e+00 - val_loss: 53.4224 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0062 - accuracy: 0.0000e+00 - val_loss: 55.3566 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.2886 - accuracy: 0.0000e+00 - val_loss: 55.9990 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.2760 - accuracy: 0.0000e+00 - val_loss: 54.1633 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.1894 - accuracy: 0.0000e+00 - val_loss: 57.7972 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.4439 - accuracy: 0.0000e+00 - val_loss: 53.9796 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.7311 - accuracy: 0.0000e+00 - val_loss: 54.0242 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.8310 - accuracy: 0.0000e+00 - val_loss: 54.6602 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.1620 - accuracy: 0.0000e+00 - val_loss: 54.7483 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3586 - accuracy: 0.0000e+00 - val_loss: 55.7642 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.6775 - accuracy: 0.0000e+00 - val_loss: 53.9329 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5370 - accuracy: 0.0000e+00 - val_loss: 57.8180 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.5646 - accuracy: 0.0000e+00 - val_loss: 53.3027 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.4910 - accuracy: 0.0000e+00 - val_loss: 67.3150 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.9013 - accuracy: 0.0000e+00 - val_loss: 53.2025 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.4176 - accuracy: 0.0000e+00 - val_loss: 55.5752 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.9774 - accuracy: 0.0000e+00 - val_loss: 53.8375 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.8202 - accuracy: 0.0000e+00 - val_loss: 53.9282 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.7351 - accuracy: 0.0000e+00 - val_loss: 57.5439 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.4971 - accuracy: 0.0000e+00 - val_loss: 53.6427 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.7382 - accuracy: 0.0000e+00 - val_loss: 58.2583 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.8915 - accuracy: 0.0000e+00 - val_loss: 54.7217 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.9860 - accuracy: 0.0000e+00 - val_loss: 53.7494 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.1734 - accuracy: 0.0000e+00 - val_loss: 53.6146 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.0902 - accuracy: 0.0000e+00 - val_loss: 53.3745 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7140 - accuracy: 0.0000e+00 - val_loss: 61.7752 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.2212 - accuracy: 0.0000e+00 - val_loss: 59.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8095 - accuracy: 0.0000e+00 - val_loss: 61.7789 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.9954 - accuracy: 0.0000e+00 - val_loss: 55.1537 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1288 - accuracy: 0.0000e+00 - val_loss: 55.1328 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.5412 - accuracy: 0.0000e+00 - val_loss: 52.9032 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.4099 - accuracy: 0.0000e+00 - val_loss: 62.8558 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.1318 - accuracy: 0.0000e+00 - val_loss: 56.9451 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.8080 - accuracy: 0.0000e+00 - val_loss: 54.3086 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.9769 - accuracy: 0.0000e+00 - val_loss: 52.9830 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.5476 - accuracy: 0.0000e+00 - val_loss: 53.1937 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 44.3435 - accuracy: 0.0000e+00 - val_loss: 58.8646 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.7428 - accuracy: 0.0000e+00 - val_loss: 53.6518 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9795 - accuracy: 0.0000e+00 - val_loss: 53.2351 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.7642 - accuracy: 0.0000e+00 - val_loss: 56.9496 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.7710 - accuracy: 0.0000e+00 - val_loss: 56.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.4972 - accuracy: 0.0000e+00 - val_loss: 56.7004 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.8086 - accuracy: 0.0000e+00 - val_loss: 53.6583 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2580 - accuracy: 0.0000e+00 - val_loss: 52.9769 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.6366 - accuracy: 0.0000e+00 - val_loss: 62.5379 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.5681 - accuracy: 0.0000e+00 - val_loss: 54.2900 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.9017 - accuracy: 0.0000e+00 - val_loss: 53.8712 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.7405 - accuracy: 0.0000e+00 - val_loss: 57.4936 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.3862 - accuracy: 0.0000e+00 - val_loss: 58.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.3487 - accuracy: 0.0000e+00 - val_loss: 55.3757 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0279 - accuracy: 0.0000e+00 - val_loss: 52.6808 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.4230 - accuracy: 0.0000e+00 - val_loss: 54.4219 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.4909 - accuracy: 0.0000e+00 - val_loss: 54.3957 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.9819 - accuracy: 0.0000e+00 - val_loss: 53.4436 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.3972 - accuracy: 0.0000e+00 - val_loss: 57.2902 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.6428 - accuracy: 0.0000e+00 - val_loss: 53.3590 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1031 - accuracy: 0.0000e+00 - val_loss: 53.3258 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.4946 - accuracy: 0.0000e+00 - val_loss: 53.9088 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.4401 - accuracy: 0.0000e+00 - val_loss: 54.0635 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 43.6265 - accuracy: 0.0000e+00 - val_loss: 54.7825 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.7662 - accuracy: 0.0000e+00 - val_loss: 53.0962 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5129 - accuracy: 0.0000e+00 - val_loss: 56.5705 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 41.8147 - accuracy: 0.0000e+00 - val_loss: 52.8280 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.0658 - accuracy: 0.0000e+00 - val_loss: 68.2881 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1518 - accuracy: 0.0000e+00 - val_loss: 52.7509 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.0471 - accuracy: 0.0000e+00 - val_loss: 54.3286 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0964 - accuracy: 0.0000e+00 - val_loss: 53.6146 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.0291 - accuracy: 0.0000e+00 - val_loss: 53.1481 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.3476 - accuracy: 0.0000e+00 - val_loss: 57.1852 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.9308 - accuracy: 0.0000e+00 - val_loss: 53.4019 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.1592 - accuracy: 0.0000e+00 - val_loss: 56.9160 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1135 - accuracy: 0.0000e+00 - val_loss: 54.3241 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.5864 - accuracy: 0.0000e+00 - val_loss: 53.1480 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.7831 - accuracy: 0.0000e+00 - val_loss: 53.0358 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.7700 - accuracy: 0.0000e+00 - val_loss: 53.2750 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2422 - accuracy: 0.0000e+00 - val_loss: 61.6652 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.0208 - accuracy: 0.0000e+00 - val_loss: 59.3899 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.5525 - accuracy: 0.0000e+00 - val_loss: 60.8550 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.4078 - accuracy: 0.0000e+00 - val_loss: 54.6805 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7381 - accuracy: 0.0000e+00 - val_loss: 55.5837 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.2676 - accuracy: 0.0000e+00 - val_loss: 53.0325 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0073 - accuracy: 0.0000e+00 - val_loss: 62.6355 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8567 - accuracy: 0.0000e+00 - val_loss: 57.3859 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.2168 - accuracy: 0.0000e+00 - val_loss: 54.3174 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.6268 - accuracy: 0.0000e+00 - val_loss: 53.0972 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9973 - accuracy: 0.0000e+00 - val_loss: 53.1880 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 43.6465 - accuracy: 0.0000e+00 - val_loss: 57.9037 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.4805 - accuracy: 0.0000e+00 - val_loss: 53.5859 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5022 - accuracy: 0.0000e+00 - val_loss: 53.1210 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1083 - accuracy: 0.0000e+00 - val_loss: 56.0412 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.3299 - accuracy: 0.0000e+00 - val_loss: 55.9701 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.9651 - accuracy: 0.0000e+00 - val_loss: 56.5594 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.2628 - accuracy: 0.0000e+00 - val_loss: 53.7186 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7920 - accuracy: 0.0000e+00 - val_loss: 53.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3370 - accuracy: 0.0000e+00 - val_loss: 62.8960 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.9399 - accuracy: 0.0000e+00 - val_loss: 53.8730 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.4439 - accuracy: 0.0000e+00 - val_loss: 54.4038 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.2161 - accuracy: 0.0000e+00 - val_loss: 56.9700 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.1697 - accuracy: 0.0000e+00 - val_loss: 58.9473 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 46.1860 - accuracy: 0.0000e+00 - val_loss: 55.5796 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7736 - accuracy: 0.0000e+00 - val_loss: 52.6760 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.9786 - accuracy: 0.0000e+00 - val_loss: 54.5932 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.1400 - accuracy: 0.0000e+00 - val_loss: 54.2825 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.6086 - accuracy: 0.0000e+00 - val_loss: 53.3371 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8926 - accuracy: 0.0000e+00 - val_loss: 57.2468 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.9075 - accuracy: 0.0000e+00 - val_loss: 53.5721 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.9217 - accuracy: 0.0000e+00 - val_loss: 53.3866 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.2701 - accuracy: 0.0000e+00 - val_loss: 53.7515 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.8622 - accuracy: 0.0000e+00 - val_loss: 54.4460 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.3232 - accuracy: 0.0000e+00 - val_loss: 54.4711 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.0546 - accuracy: 0.0000e+00 - val_loss: 53.1077 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.0949 - accuracy: 0.0000e+00 - val_loss: 56.7354 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.4302 - accuracy: 0.0000e+00 - val_loss: 52.7016 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8253 - accuracy: 0.0000e+00 - val_loss: 69.0507 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8686 - accuracy: 0.0000e+00 - val_loss: 52.6916 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.4116 - accuracy: 0.0000e+00 - val_loss: 53.9257 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.4894 - accuracy: 0.0000e+00 - val_loss: 53.6486 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.6358 - accuracy: 0.0000e+00 - val_loss: 53.0200 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.6606 - accuracy: 0.0000e+00 - val_loss: 56.1840 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.5274 - accuracy: 0.0000e+00 - val_loss: 53.1506 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8008 - accuracy: 0.0000e+00 - val_loss: 56.8188 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.6318 - accuracy: 0.0000e+00 - val_loss: 54.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.2023 - accuracy: 0.0000e+00 - val_loss: 52.9068 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.5974 - accuracy: 0.0000e+00 - val_loss: 52.8278 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 41.5704 - accuracy: 0.0000e+00 - val_loss: 53.3468 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.8940 - accuracy: 0.0000e+00 - val_loss: 60.9781 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.6023 - accuracy: 0.0000e+00 - val_loss: 58.9762 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3221 - accuracy: 0.0000e+00 - val_loss: 60.8662 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.3168 - accuracy: 0.0000e+00 - val_loss: 54.8143 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3148 - accuracy: 0.0000e+00 - val_loss: 55.5472 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.9487 - accuracy: 0.0000e+00 - val_loss: 52.9349 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.7108 - accuracy: 0.0000e+00 - val_loss: 62.5579 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8893 - accuracy: 0.0000e+00 - val_loss: 57.7653 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7052 - accuracy: 0.0000e+00 - val_loss: 54.3714 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2465 - accuracy: 0.0000e+00 - val_loss: 52.8165 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.6116 - accuracy: 0.0000e+00 - val_loss: 53.0312 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 43.1530 - accuracy: 0.0000e+00 - val_loss: 57.2318 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.1242 - accuracy: 0.0000e+00 - val_loss: 53.2455 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.1106 - accuracy: 0.0000e+00 - val_loss: 53.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7017 - accuracy: 0.0000e+00 - val_loss: 55.2864 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.0329 - accuracy: 0.0000e+00 - val_loss: 55.3411 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.4756 - accuracy: 0.0000e+00 - val_loss: 55.9920 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.6064 - accuracy: 0.0000e+00 - val_loss: 53.5271 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5416 - accuracy: 0.0000e+00 - val_loss: 52.8734 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.1828 - accuracy: 0.0000e+00 - val_loss: 62.8669 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 41.6305 - accuracy: 0.0000e+00 - val_loss: 53.4766 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.3039 - accuracy: 0.0000e+00 - val_loss: 54.4958 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.6251 - accuracy: 0.0000e+00 - val_loss: 55.9309 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.9021 - accuracy: 0.0000e+00 - val_loss: 58.6305 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.8847 - accuracy: 0.0000e+00 - val_loss: 55.0102 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2557 - accuracy: 0.0000e+00 - val_loss: 52.2955 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5604 - accuracy: 0.0000e+00 - val_loss: 54.4159 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8961 - accuracy: 0.0000e+00 - val_loss: 53.7970 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.0069 - accuracy: 0.0000e+00 - val_loss: 53.2364 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4734 - accuracy: 0.0000e+00 - val_loss: 57.1054 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.5739 - accuracy: 0.0000e+00 - val_loss: 53.2779 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.5826 - accuracy: 0.0000e+00 - val_loss: 53.2235 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.8891 - accuracy: 0.0000e+00 - val_loss: 53.7434 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.5632 - accuracy: 0.0000e+00 - val_loss: 54.2003 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.9300 - accuracy: 0.0000e+00 - val_loss: 54.1058 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.4267 - accuracy: 0.0000e+00 - val_loss: 52.8324 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.7072 - accuracy: 0.0000e+00 - val_loss: 56.2480 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.1175 - accuracy: 0.0000e+00 - val_loss: 52.5177 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5942 - accuracy: 0.0000e+00 - val_loss: 69.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.3777 - accuracy: 0.0000e+00 - val_loss: 52.7338 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.5967 - accuracy: 0.0000e+00 - val_loss: 53.2607 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0376 - accuracy: 0.0000e+00 - val_loss: 53.4318 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1952 - accuracy: 0.0000e+00 - val_loss: 52.7256 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.4706 - accuracy: 0.0000e+00 - val_loss: 55.3656 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.1643 - accuracy: 0.0000e+00 - val_loss: 52.8325 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 41.2484 - accuracy: 0.0000e+00 - val_loss: 55.8320 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.1880 - accuracy: 0.0000e+00 - val_loss: 53.5118 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8938 - accuracy: 0.0000e+00 - val_loss: 52.7349 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1367 - accuracy: 0.0000e+00 - val_loss: 52.4990 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2844 - accuracy: 0.0000e+00 - val_loss: 53.3098 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.6555 - accuracy: 0.0000e+00 - val_loss: 60.5698 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.4756 - accuracy: 0.0000e+00 - val_loss: 59.0798 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.4985 - accuracy: 0.0000e+00 - val_loss: 60.4861 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.2254 - accuracy: 0.0000e+00 - val_loss: 54.9939 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.3166 - accuracy: 0.0000e+00 - val_loss: 55.4507 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.8284 - accuracy: 0.0000e+00 - val_loss: 52.7741 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.4782 - accuracy: 0.0000e+00 - val_loss: 62.2772 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.6528 - accuracy: 0.0000e+00 - val_loss: 57.9355 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.1268 - accuracy: 0.0000e+00 - val_loss: 54.4970 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.0020 - accuracy: 0.0000e+00 - val_loss: 52.6537 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.3150 - accuracy: 0.0000e+00 - val_loss: 52.6326 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 42.7319 - accuracy: 0.0000e+00 - val_loss: 56.5872 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7733 - accuracy: 0.0000e+00 - val_loss: 53.0108 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8582 - accuracy: 0.0000e+00 - val_loss: 53.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.4915 - accuracy: 0.0000e+00 - val_loss: 54.4913 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7963 - accuracy: 0.0000e+00 - val_loss: 55.0520 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 42.1599 - accuracy: 0.0000e+00 - val_loss: 55.4804 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.1595 - accuracy: 0.0000e+00 - val_loss: 53.0786 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2410 - accuracy: 0.0000e+00 - val_loss: 52.7417 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0396 - accuracy: 0.0000e+00 - val_loss: 62.6857 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.4768 - accuracy: 0.0000e+00 - val_loss: 52.9483 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.9778 - accuracy: 0.0000e+00 - val_loss: 54.5281 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.2625 - accuracy: 0.0000e+00 - val_loss: 55.2589 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.9401 - accuracy: 0.0000e+00 - val_loss: 57.8610 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 45.8288 - accuracy: 0.0000e+00 - val_loss: 54.4705 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.8450 - accuracy: 0.0000e+00 - val_loss: 52.1348 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 40.3921 - accuracy: 0.0000e+00 - val_loss: 53.8504 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.7853 - accuracy: 0.0000e+00 - val_loss: 53.6410 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 42.8755 - accuracy: 0.0000e+00 - val_loss: 53.1041 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.8639 - accuracy: 0.0000e+00 - val_loss: 58.0961 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 42.8223 - accuracy: 0.0000e+00 - val_loss: 52.9710 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.3721 - accuracy: 0.0000e+00 - val_loss: 52.9783 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.5904 - accuracy: 0.0000e+00 - val_loss: 53.6001 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 42.3398 - accuracy: 0.0000e+00 - val_loss: 54.2295 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 42.7591 - accuracy: 0.0000e+00 - val_loss: 53.8511 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.2548 - accuracy: 0.0000e+00 - val_loss: 52.3845 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 42.5268 - accuracy: 0.0000e+00 - val_loss: 55.9325 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 40.9615 - accuracy: 0.0000e+00 - val_loss: 52.2424 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 44.5180 - accuracy: 0.0000e+00 - val_loss: 69.1355 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 44.0674 - accuracy: 0.0000e+00 - val_loss: 52.6055 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 41.1320 - accuracy: 0.0000e+00 - val_loss: 52.8436 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.8635 - accuracy: 0.0000e+00 - val_loss: 53.2832 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.9506 - accuracy: 0.0000e+00 - val_loss: 52.2555 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 45.0854 - accuracy: 0.0000e+00 - val_loss: 54.2019 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.8412 - accuracy: 0.0000e+00 - val_loss: 52.3237 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8460 - accuracy: 0.0000e+00 - val_loss: 55.3348 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8661 - accuracy: 0.0000e+00 - val_loss: 53.1079 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.7008 - accuracy: 0.0000e+00 - val_loss: 52.4621 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 39.9495 - accuracy: 0.0000e+00 - val_loss: 52.1402 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 41.0014 - accuracy: 0.0000e+00 - val_loss: 53.0981 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 39.4419 - accuracy: 0.0000e+00 - val_loss: 59.7209 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0348 - accuracy: 0.0000e+00 - val_loss: 58.0472 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 44.1924 - accuracy: 0.0000e+00 - val_loss: 59.4444 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.0195 - accuracy: 0.0000e+00 - val_loss: 54.5181 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9457 - accuracy: 0.0000e+00 - val_loss: 55.2770 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7638 - accuracy: 0.0000e+00 - val_loss: 52.6098 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3795 - accuracy: 0.0000e+00 - val_loss: 62.4324 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.6562 - accuracy: 0.0000e+00 - val_loss: 57.9007 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8950 - accuracy: 0.0000e+00 - val_loss: 54.5244 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8661 - accuracy: 0.0000e+00 - val_loss: 52.3711 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.1357 - accuracy: 0.0000e+00 - val_loss: 52.5043 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 42.5609 - accuracy: 0.0000e+00 - val_loss: 55.9986 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.4884 - accuracy: 0.0000e+00 - val_loss: 52.6629 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 39.7235 - accuracy: 0.0000e+00 - val_loss: 53.1824 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1829 - accuracy: 0.0000e+00 - val_loss: 54.0153 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.5312 - accuracy: 0.0000e+00 - val_loss: 54.8172 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8427 - accuracy: 0.0000e+00 - val_loss: 55.1202 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8094 - accuracy: 0.0000e+00 - val_loss: 52.5706 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0577 - accuracy: 0.0000e+00 - val_loss: 52.5621 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.9010 - accuracy: 0.0000e+00 - val_loss: 62.2065 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3239 - accuracy: 0.0000e+00 - val_loss: 52.9268 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8948 - accuracy: 0.0000e+00 - val_loss: 54.0449 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.0367 - accuracy: 0.0000e+00 - val_loss: 54.8007 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.8395 - accuracy: 0.0000e+00 - val_loss: 57.8044 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.7719 - accuracy: 0.0000e+00 - val_loss: 54.1257 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6659 - accuracy: 0.0000e+00 - val_loss: 51.8752 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.2023 - accuracy: 0.0000e+00 - val_loss: 53.6332 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5249 - accuracy: 0.0000e+00 - val_loss: 53.0929 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.4297 - accuracy: 0.0000e+00 - val_loss: 52.8157 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1351 - accuracy: 0.0000e+00 - val_loss: 57.2379 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.3573 - accuracy: 0.0000e+00 - val_loss: 52.6906 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2128 - accuracy: 0.0000e+00 - val_loss: 52.7929 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3829 - accuracy: 0.0000e+00 - val_loss: 53.1732 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.2783 - accuracy: 0.0000e+00 - val_loss: 54.0854 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.6878 - accuracy: 0.0000e+00 - val_loss: 53.4800 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0487 - accuracy: 0.0000e+00 - val_loss: 52.1313 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.3171 - accuracy: 0.0000e+00 - val_loss: 55.6564 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8028 - accuracy: 0.0000e+00 - val_loss: 51.9987 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.1907 - accuracy: 0.0000e+00 - val_loss: 68.4094 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.8072 - accuracy: 0.0000e+00 - val_loss: 52.4143 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.8546 - accuracy: 0.0000e+00 - val_loss: 52.4486 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7269 - accuracy: 0.0000e+00 - val_loss: 52.9623 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.0250 - accuracy: 0.0000e+00 - val_loss: 52.0664 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.0978 - accuracy: 0.0000e+00 - val_loss: 53.3236 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.6081 - accuracy: 0.0000e+00 - val_loss: 52.0585 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5506 - accuracy: 0.0000e+00 - val_loss: 54.8916 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6421 - accuracy: 0.0000e+00 - val_loss: 52.9646 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.5549 - accuracy: 0.0000e+00 - val_loss: 52.4622 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6925 - accuracy: 0.0000e+00 - val_loss: 51.7414 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8322 - accuracy: 0.0000e+00 - val_loss: 52.8807 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 39.3558 - accuracy: 0.0000e+00 - val_loss: 59.1241 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 41.7071 - accuracy: 0.0000e+00 - val_loss: 57.2024 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 43.7483 - accuracy: 0.0000e+00 - val_loss: 58.7521 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.0786 - accuracy: 0.0000e+00 - val_loss: 54.1902 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9358 - accuracy: 0.0000e+00 - val_loss: 54.8770 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7486 - accuracy: 0.0000e+00 - val_loss: 52.3017 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.2715 - accuracy: 0.0000e+00 - val_loss: 61.8212 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5794 - accuracy: 0.0000e+00 - val_loss: 57.7527 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6784 - accuracy: 0.0000e+00 - val_loss: 54.4149 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8139 - accuracy: 0.0000e+00 - val_loss: 52.1942 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.0710 - accuracy: 0.0000e+00 - val_loss: 52.2159 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 42.3429 - accuracy: 0.0000e+00 - val_loss: 55.4538 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3811 - accuracy: 0.0000e+00 - val_loss: 52.3180 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6517 - accuracy: 0.0000e+00 - val_loss: 53.0455 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.9837 - accuracy: 0.0000e+00 - val_loss: 53.5120 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.4256 - accuracy: 0.0000e+00 - val_loss: 54.4275 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.5773 - accuracy: 0.0000e+00 - val_loss: 54.4417 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6241 - accuracy: 0.0000e+00 - val_loss: 52.2641 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9964 - accuracy: 0.0000e+00 - val_loss: 52.4136 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8271 - accuracy: 0.0000e+00 - val_loss: 61.8834 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2467 - accuracy: 0.0000e+00 - val_loss: 52.6665 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7657 - accuracy: 0.0000e+00 - val_loss: 54.0699 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.7220 - accuracy: 0.0000e+00 - val_loss: 54.2168 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.7164 - accuracy: 0.0000e+00 - val_loss: 56.9937 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 45.5523 - accuracy: 0.0000e+00 - val_loss: 53.2555 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4497 - accuracy: 0.0000e+00 - val_loss: 51.5796 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.0629 - accuracy: 0.0000e+00 - val_loss: 53.1566 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4648 - accuracy: 0.0000e+00 - val_loss: 52.8015 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.2404 - accuracy: 0.0000e+00 - val_loss: 52.7355 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1006 - accuracy: 0.0000e+00 - val_loss: 56.9467 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.2538 - accuracy: 0.0000e+00 - val_loss: 52.3914 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1771 - accuracy: 0.0000e+00 - val_loss: 52.4862 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1856 - accuracy: 0.0000e+00 - val_loss: 52.9901 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.2553 - accuracy: 0.0000e+00 - val_loss: 53.6680 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.4895 - accuracy: 0.0000e+00 - val_loss: 53.1725 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.0801 - accuracy: 0.0000e+00 - val_loss: 51.8373 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.2536 - accuracy: 0.0000e+00 - val_loss: 54.5629 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.5796 - accuracy: 0.0000e+00 - val_loss: 51.7220 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.0582 - accuracy: 0.0000e+00 - val_loss: 67.7768 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5234 - accuracy: 0.0000e+00 - val_loss: 52.3553 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7168 - accuracy: 0.0000e+00 - val_loss: 52.1960 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6479 - accuracy: 0.0000e+00 - val_loss: 52.3811 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8433 - accuracy: 0.0000e+00 - val_loss: 52.0113 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.8688 - accuracy: 0.0000e+00 - val_loss: 52.7170 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.3368 - accuracy: 0.0000e+00 - val_loss: 51.8693 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3403 - accuracy: 0.0000e+00 - val_loss: 54.6790 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5083 - accuracy: 0.0000e+00 - val_loss: 52.7535 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.4792 - accuracy: 0.0000e+00 - val_loss: 52.3089 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.5947 - accuracy: 0.0000e+00 - val_loss: 51.5373 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.6420 - accuracy: 0.0000e+00 - val_loss: 52.7832 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.2569 - accuracy: 0.0000e+00 - val_loss: 58.6297 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.5799 - accuracy: 0.0000e+00 - val_loss: 56.7633 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.6327 - accuracy: 0.0000e+00 - val_loss: 57.8073 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.8065 - accuracy: 0.0000e+00 - val_loss: 53.8635 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8020 - accuracy: 0.0000e+00 - val_loss: 54.7715 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8177 - accuracy: 0.0000e+00 - val_loss: 52.2444 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1959 - accuracy: 0.0000e+00 - val_loss: 61.1876 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3907 - accuracy: 0.0000e+00 - val_loss: 57.1844 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3834 - accuracy: 0.0000e+00 - val_loss: 54.4040 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.7689 - accuracy: 0.0000e+00 - val_loss: 52.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9879 - accuracy: 0.0000e+00 - val_loss: 52.0417 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 42.1948 - accuracy: 0.0000e+00 - val_loss: 54.9467 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2319 - accuracy: 0.0000e+00 - val_loss: 52.1992 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.5209 - accuracy: 0.0000e+00 - val_loss: 52.7796 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7907 - accuracy: 0.0000e+00 - val_loss: 53.1684 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.2143 - accuracy: 0.0000e+00 - val_loss: 54.2382 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.3848 - accuracy: 0.0000e+00 - val_loss: 53.9620 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4547 - accuracy: 0.0000e+00 - val_loss: 52.0821 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8986 - accuracy: 0.0000e+00 - val_loss: 52.2733 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.7280 - accuracy: 0.0000e+00 - val_loss: 61.8944 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2764 - accuracy: 0.0000e+00 - val_loss: 52.7777 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7264 - accuracy: 0.0000e+00 - val_loss: 54.4302 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.3683 - accuracy: 0.0000e+00 - val_loss: 53.3600 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.4406 - accuracy: 0.0000e+00 - val_loss: 55.9530 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 45.1388 - accuracy: 0.0000e+00 - val_loss: 52.7157 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.1565 - accuracy: 0.0000e+00 - val_loss: 51.4834 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9661 - accuracy: 0.0000e+00 - val_loss: 53.0862 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.3553 - accuracy: 0.0000e+00 - val_loss: 52.5473 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.9848 - accuracy: 0.0000e+00 - val_loss: 52.6485 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0070 - accuracy: 0.0000e+00 - val_loss: 56.9029 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1116 - accuracy: 0.0000e+00 - val_loss: 52.2897 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0196 - accuracy: 0.0000e+00 - val_loss: 52.5331 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0018 - accuracy: 0.0000e+00 - val_loss: 53.0398 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.9785 - accuracy: 0.0000e+00 - val_loss: 53.3007 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.0922 - accuracy: 0.0000e+00 - val_loss: 52.7764 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8967 - accuracy: 0.0000e+00 - val_loss: 51.7215 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.2083 - accuracy: 0.0000e+00 - val_loss: 54.3129 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4860 - accuracy: 0.0000e+00 - val_loss: 51.6642 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5769 - accuracy: 0.0000e+00 - val_loss: 66.1561 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 42.8931 - accuracy: 0.0000e+00 - val_loss: 52.2736 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 40.5441 - accuracy: 0.0000e+00 - val_loss: 52.0764 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 40.3716 - accuracy: 0.0000e+00 - val_loss: 52.3739 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 41.5822 - accuracy: 0.0000e+00 - val_loss: 52.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 44.4339 - accuracy: 0.0000e+00 - val_loss: 52.0596 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 41.1394 - accuracy: 0.0000e+00 - val_loss: 52.0379 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 40.1866 - accuracy: 0.0000e+00 - val_loss: 55.6590 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 40.6151 - accuracy: 0.0000e+00 - val_loss: 52.8616 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 40.4002 - accuracy: 0.0000e+00 - val_loss: 52.2344 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 39.5038 - accuracy: 0.0000e+00 - val_loss: 51.5063 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 40.5470 - accuracy: 0.0000e+00 - val_loss: 52.6884 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.1296 - accuracy: 0.0000e+00 - val_loss: 58.3252 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.4810 - accuracy: 0.0000e+00 - val_loss: 56.0845 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5372 - accuracy: 0.0000e+00 - val_loss: 56.8872 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.7447 - accuracy: 0.0000e+00 - val_loss: 53.6133 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.7822 - accuracy: 0.0000e+00 - val_loss: 54.5602 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8792 - accuracy: 0.0000e+00 - val_loss: 52.0478 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.0947 - accuracy: 0.0000e+00 - val_loss: 61.0976 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.3753 - accuracy: 0.0000e+00 - val_loss: 57.0292 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2796 - accuracy: 0.0000e+00 - val_loss: 54.3931 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7258 - accuracy: 0.0000e+00 - val_loss: 51.8390 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9313 - accuracy: 0.0000e+00 - val_loss: 52.0850 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 5ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.9981 - accuracy: 0.0000e+00 - val_loss: 54.6376 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0820 - accuracy: 0.0000e+00 - val_loss: 52.1524 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 39.4113 - accuracy: 0.0000e+00 - val_loss: 52.7204 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6199 - accuracy: 0.0000e+00 - val_loss: 52.8839 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.0697 - accuracy: 0.0000e+00 - val_loss: 54.4007 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.2786 - accuracy: 0.0000e+00 - val_loss: 53.2660 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.3535 - accuracy: 0.0000e+00 - val_loss: 51.8995 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8650 - accuracy: 0.0000e+00 - val_loss: 51.9380 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.7252 - accuracy: 0.0000e+00 - val_loss: 61.4492 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.1669 - accuracy: 0.0000e+00 - val_loss: 52.5768 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.5258 - accuracy: 0.0000e+00 - val_loss: 54.6387 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0735 - accuracy: 0.0000e+00 - val_loss: 53.1034 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.3186 - accuracy: 0.0000e+00 - val_loss: 55.2575 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.9520 - accuracy: 0.0000e+00 - val_loss: 52.0494 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9086 - accuracy: 0.0000e+00 - val_loss: 51.3252 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8929 - accuracy: 0.0000e+00 - val_loss: 52.8600 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4302 - accuracy: 0.0000e+00 - val_loss: 52.2665 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.7473 - accuracy: 0.0000e+00 - val_loss: 52.5182 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9940 - accuracy: 0.0000e+00 - val_loss: 57.0676 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.9977 - accuracy: 0.0000e+00 - val_loss: 52.3016 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.9887 - accuracy: 0.0000e+00 - val_loss: 52.2648 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8051 - accuracy: 0.0000e+00 - val_loss: 52.9442 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8393 - accuracy: 0.0000e+00 - val_loss: 52.9226 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.7427 - accuracy: 0.0000e+00 - val_loss: 52.3582 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.9377 - accuracy: 0.0000e+00 - val_loss: 51.5627 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.2039 - accuracy: 0.0000e+00 - val_loss: 54.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4160 - accuracy: 0.0000e+00 - val_loss: 51.5188 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.0466 - accuracy: 0.0000e+00 - val_loss: 64.3445 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.4703 - accuracy: 0.0000e+00 - val_loss: 52.3076 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4054 - accuracy: 0.0000e+00 - val_loss: 52.0551 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3172 - accuracy: 0.0000e+00 - val_loss: 52.3721 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.6434 - accuracy: 0.0000e+00 - val_loss: 52.1465 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.5449 - accuracy: 0.0000e+00 - val_loss: 51.8303 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9533 - accuracy: 0.0000e+00 - val_loss: 51.6948 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9312 - accuracy: 0.0000e+00 - val_loss: 54.3401 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3158 - accuracy: 0.0000e+00 - val_loss: 52.3925 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.3017 - accuracy: 0.0000e+00 - val_loss: 52.1608 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.4068 - accuracy: 0.0000e+00 - val_loss: 51.4387 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4130 - accuracy: 0.0000e+00 - val_loss: 52.7239 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.0444 - accuracy: 0.0000e+00 - val_loss: 58.2877 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.4342 - accuracy: 0.0000e+00 - val_loss: 55.8922 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.3953 - accuracy: 0.0000e+00 - val_loss: 56.4123 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.5816 - accuracy: 0.0000e+00 - val_loss: 53.3571 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7044 - accuracy: 0.0000e+00 - val_loss: 54.4623 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8872 - accuracy: 0.0000e+00 - val_loss: 51.9183 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0033 - accuracy: 0.0000e+00 - val_loss: 60.8451 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.2701 - accuracy: 0.0000e+00 - val_loss: 56.8242 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.2102 - accuracy: 0.0000e+00 - val_loss: 54.2487 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.7304 - accuracy: 0.0000e+00 - val_loss: 51.7154 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8003 - accuracy: 0.0000e+00 - val_loss: 52.0037 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.7512 - accuracy: 0.0000e+00 - val_loss: 54.6385 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0481 - accuracy: 0.0000e+00 - val_loss: 51.9920 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 39.3310 - accuracy: 0.0000e+00 - val_loss: 52.6486 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5174 - accuracy: 0.0000e+00 - val_loss: 52.5810 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8381 - accuracy: 0.0000e+00 - val_loss: 54.1450 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0419 - accuracy: 0.0000e+00 - val_loss: 53.0160 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2729 - accuracy: 0.0000e+00 - val_loss: 51.8014 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8307 - accuracy: 0.0000e+00 - val_loss: 52.0867 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5425 - accuracy: 0.0000e+00 - val_loss: 60.4074 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0154 - accuracy: 0.0000e+00 - val_loss: 52.4526 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3896 - accuracy: 0.0000e+00 - val_loss: 54.6570 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7942 - accuracy: 0.0000e+00 - val_loss: 53.1135 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 42.1390 - accuracy: 0.0000e+00 - val_loss: 54.4757 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.4591 - accuracy: 0.0000e+00 - val_loss: 51.5497 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6808 - accuracy: 0.0000e+00 - val_loss: 51.2488 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8288 - accuracy: 0.0000e+00 - val_loss: 52.5752 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3315 - accuracy: 0.0000e+00 - val_loss: 52.2153 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.6660 - accuracy: 0.0000e+00 - val_loss: 52.5055 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9641 - accuracy: 0.0000e+00 - val_loss: 57.1274 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.8676 - accuracy: 0.0000e+00 - val_loss: 52.2021 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8183 - accuracy: 0.0000e+00 - val_loss: 51.9897 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.7424 - accuracy: 0.0000e+00 - val_loss: 53.0832 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8657 - accuracy: 0.0000e+00 - val_loss: 52.9075 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.6521 - accuracy: 0.0000e+00 - val_loss: 52.3719 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7460 - accuracy: 0.0000e+00 - val_loss: 51.4848 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0233 - accuracy: 0.0000e+00 - val_loss: 53.8090 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2831 - accuracy: 0.0000e+00 - val_loss: 51.5733 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.8462 - accuracy: 0.0000e+00 - val_loss: 63.7765 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.1818 - accuracy: 0.0000e+00 - val_loss: 52.2288 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.2624 - accuracy: 0.0000e+00 - val_loss: 51.8922 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.3154 - accuracy: 0.0000e+00 - val_loss: 52.1955 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.5772 - accuracy: 0.0000e+00 - val_loss: 52.1211 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.3803 - accuracy: 0.0000e+00 - val_loss: 51.6149 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.9902 - accuracy: 0.0000e+00 - val_loss: 51.7065 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6806 - accuracy: 0.0000e+00 - val_loss: 54.2744 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2784 - accuracy: 0.0000e+00 - val_loss: 52.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.2508 - accuracy: 0.0000e+00 - val_loss: 51.9807 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.3984 - accuracy: 0.0000e+00 - val_loss: 51.3355 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.2805 - accuracy: 0.0000e+00 - val_loss: 52.6704 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0393 - accuracy: 0.0000e+00 - val_loss: 57.9291 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3973 - accuracy: 0.0000e+00 - val_loss: 55.5945 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 43.3050 - accuracy: 0.0000e+00 - val_loss: 55.5546 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.4461 - accuracy: 0.0000e+00 - val_loss: 53.2038 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6961 - accuracy: 0.0000e+00 - val_loss: 54.1228 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.9157 - accuracy: 0.0000e+00 - val_loss: 51.6968 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7033 - accuracy: 0.0000e+00 - val_loss: 60.4146 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.3002 - accuracy: 0.0000e+00 - val_loss: 56.6724 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.0514 - accuracy: 0.0000e+00 - val_loss: 54.1251 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.7221 - accuracy: 0.0000e+00 - val_loss: 51.7080 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6955 - accuracy: 0.0000e+00 - val_loss: 51.9236 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.7906 - accuracy: 0.0000e+00 - val_loss: 54.2117 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 39.9071 - accuracy: 0.0000e+00 - val_loss: 51.9487 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.2898 - accuracy: 0.0000e+00 - val_loss: 52.5111 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4764 - accuracy: 0.0000e+00 - val_loss: 52.5171 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8114 - accuracy: 0.0000e+00 - val_loss: 54.0748 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8997 - accuracy: 0.0000e+00 - val_loss: 52.7525 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1656 - accuracy: 0.0000e+00 - val_loss: 51.7192 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.7259 - accuracy: 0.0000e+00 - val_loss: 52.1179 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.5401 - accuracy: 0.0000e+00 - val_loss: 60.4351 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0396 - accuracy: 0.0000e+00 - val_loss: 52.3970 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1345 - accuracy: 0.0000e+00 - val_loss: 54.8751 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.6436 - accuracy: 0.0000e+00 - val_loss: 52.9120 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0282 - accuracy: 0.0000e+00 - val_loss: 54.6085 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.3917 - accuracy: 0.0000e+00 - val_loss: 51.5605 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.5094 - accuracy: 0.0000e+00 - val_loss: 51.2208 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.7481 - accuracy: 0.0000e+00 - val_loss: 52.4292 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.3006 - accuracy: 0.0000e+00 - val_loss: 52.1810 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.4561 - accuracy: 0.0000e+00 - val_loss: 52.4795 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9802 - accuracy: 0.0000e+00 - val_loss: 57.2387 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8361 - accuracy: 0.0000e+00 - val_loss: 52.1697 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.7931 - accuracy: 0.0000e+00 - val_loss: 52.0157 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6159 - accuracy: 0.0000e+00 - val_loss: 53.1773 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8803 - accuracy: 0.0000e+00 - val_loss: 52.5654 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.4175 - accuracy: 0.0000e+00 - val_loss: 52.0769 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.6309 - accuracy: 0.0000e+00 - val_loss: 51.4415 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.9852 - accuracy: 0.0000e+00 - val_loss: 53.6681 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2802 - accuracy: 0.0000e+00 - val_loss: 51.5725 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 42.6411 - accuracy: 0.0000e+00 - val_loss: 63.0464 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.9409 - accuracy: 0.0000e+00 - val_loss: 52.1789 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2047 - accuracy: 0.0000e+00 - val_loss: 51.8369 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2157 - accuracy: 0.0000e+00 - val_loss: 52.1154 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.5472 - accuracy: 0.0000e+00 - val_loss: 52.1425 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.2603 - accuracy: 0.0000e+00 - val_loss: 51.3754 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.9706 - accuracy: 0.0000e+00 - val_loss: 51.7049 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.5030 - accuracy: 0.0000e+00 - val_loss: 54.5249 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2492 - accuracy: 0.0000e+00 - val_loss: 51.9854 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2147 - accuracy: 0.0000e+00 - val_loss: 51.8686 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.4180 - accuracy: 0.0000e+00 - val_loss: 51.2382 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.1439 - accuracy: 0.0000e+00 - val_loss: 52.7061 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.9633 - accuracy: 0.0000e+00 - val_loss: 57.8364 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3789 - accuracy: 0.0000e+00 - val_loss: 55.2050 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.3594 - accuracy: 0.0000e+00 - val_loss: 55.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.5136 - accuracy: 0.0000e+00 - val_loss: 53.1851 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9653 - accuracy: 0.0000e+00 - val_loss: 53.5382 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9801 - accuracy: 0.0000e+00 - val_loss: 51.5284 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.6593 - accuracy: 0.0000e+00 - val_loss: 60.0618 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 44.0989 - accuracy: 0.0000e+00 - val_loss: 56.2340 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9029 - accuracy: 0.0000e+00 - val_loss: 53.8935 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.6706 - accuracy: 0.0000e+00 - val_loss: 51.6025 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6789 - accuracy: 0.0000e+00 - val_loss: 51.7126 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.5478 - accuracy: 0.0000e+00 - val_loss: 54.1982 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 39.8696 - accuracy: 0.0000e+00 - val_loss: 51.9458 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.2585 - accuracy: 0.0000e+00 - val_loss: 52.3640 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3666 - accuracy: 0.0000e+00 - val_loss: 52.3811 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.7719 - accuracy: 0.0000e+00 - val_loss: 54.0308 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8605 - accuracy: 0.0000e+00 - val_loss: 52.6276 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.0348 - accuracy: 0.0000e+00 - val_loss: 51.6295 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.6200 - accuracy: 0.0000e+00 - val_loss: 51.9934 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4808 - accuracy: 0.0000e+00 - val_loss: 60.0240 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.9765 - accuracy: 0.0000e+00 - val_loss: 52.3019 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.9138 - accuracy: 0.0000e+00 - val_loss: 54.6491 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.4252 - accuracy: 0.0000e+00 - val_loss: 52.8459 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8699 - accuracy: 0.0000e+00 - val_loss: 54.2334 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 44.1753 - accuracy: 0.0000e+00 - val_loss: 51.2891 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 39.3922 - accuracy: 0.0000e+00 - val_loss: 51.1655 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 39.7234 - accuracy: 0.0000e+00 - val_loss: 52.2080 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 40.2948 - accuracy: 0.0000e+00 - val_loss: 52.0792 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.3397 - accuracy: 0.0000e+00 - val_loss: 52.4140 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.0202 - accuracy: 0.0000e+00 - val_loss: 57.1954 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.7895 - accuracy: 0.0000e+00 - val_loss: 52.0114 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.7372 - accuracy: 0.0000e+00 - val_loss: 51.8361 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 40.5303 - accuracy: 0.0000e+00 - val_loss: 53.2477 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.9674 - accuracy: 0.0000e+00 - val_loss: 52.4356 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.3999 - accuracy: 0.0000e+00 - val_loss: 51.8373 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.6488 - accuracy: 0.0000e+00 - val_loss: 51.2015 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.8450 - accuracy: 0.0000e+00 - val_loss: 53.4936 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 40.2035 - accuracy: 0.0000e+00 - val_loss: 51.5157 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 42.3733 - accuracy: 0.0000e+00 - val_loss: 61.7607 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.6202 - accuracy: 0.0000e+00 - val_loss: 51.9415 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.1801 - accuracy: 0.0000e+00 - val_loss: 51.8387 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.1939 - accuracy: 0.0000e+00 - val_loss: 52.0258 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.4295 - accuracy: 0.0000e+00 - val_loss: 51.8935 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.8340 - accuracy: 0.0000e+00 - val_loss: 51.3161 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 40.7537 - accuracy: 0.0000e+00 - val_loss: 51.6106 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 39.3836 - accuracy: 0.0000e+00 - val_loss: 54.1222 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.1213 - accuracy: 0.0000e+00 - val_loss: 51.5724 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.0095 - accuracy: 0.0000e+00 - val_loss: 51.7491 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.2454 - accuracy: 0.0000e+00 - val_loss: 51.0645 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.1903 - accuracy: 0.0000e+00 - val_loss: 52.5978 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 38.9128 - accuracy: 0.0000e+00 - val_loss: 57.4040 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.2528 - accuracy: 0.0000e+00 - val_loss: 54.6993 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 43.2193 - accuracy: 0.0000e+00 - val_loss: 54.1973 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0924 - accuracy: 0.0000e+00 - val_loss: 52.3734 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4549 - accuracy: 0.0000e+00 - val_loss: 53.0755 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7625 - accuracy: 0.0000e+00 - val_loss: 51.3349 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4210 - accuracy: 0.0000e+00 - val_loss: 59.5433 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.0043 - accuracy: 0.0000e+00 - val_loss: 56.1138 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.7067 - accuracy: 0.0000e+00 - val_loss: 53.5793 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6972 - accuracy: 0.0000e+00 - val_loss: 51.3535 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.5239 - accuracy: 0.0000e+00 - val_loss: 51.5485 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.6359 - accuracy: 0.0000e+00 - val_loss: 53.8520 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.8539 - accuracy: 0.0000e+00 - val_loss: 51.8766 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.1982 - accuracy: 0.0000e+00 - val_loss: 52.2459 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.3017 - accuracy: 0.0000e+00 - val_loss: 52.2998 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9101 - accuracy: 0.0000e+00 - val_loss: 54.2491 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.7867 - accuracy: 0.0000e+00 - val_loss: 52.2477 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9821 - accuracy: 0.0000e+00 - val_loss: 51.4918 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.5816 - accuracy: 0.0000e+00 - val_loss: 51.9304 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4403 - accuracy: 0.0000e+00 - val_loss: 59.4125 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.9499 - accuracy: 0.0000e+00 - val_loss: 52.2192 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9549 - accuracy: 0.0000e+00 - val_loss: 54.5381 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.2852 - accuracy: 0.0000e+00 - val_loss: 52.6600 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8689 - accuracy: 0.0000e+00 - val_loss: 53.9057 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.9577 - accuracy: 0.0000e+00 - val_loss: 51.1971 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.2445 - accuracy: 0.0000e+00 - val_loss: 50.8333 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6082 - accuracy: 0.0000e+00 - val_loss: 52.1221 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2246 - accuracy: 0.0000e+00 - val_loss: 51.7001 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 41.2100 - accuracy: 0.0000e+00 - val_loss: 52.4612 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9721 - accuracy: 0.0000e+00 - val_loss: 57.2622 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.5583 - accuracy: 0.0000e+00 - val_loss: 51.9659 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.6825 - accuracy: 0.0000e+00 - val_loss: 51.7138 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3157 - accuracy: 0.0000e+00 - val_loss: 53.1388 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7757 - accuracy: 0.0000e+00 - val_loss: 52.2539 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2876 - accuracy: 0.0000e+00 - val_loss: 51.3569 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.7792 - accuracy: 0.0000e+00 - val_loss: 50.9676 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 42.0732 - accuracy: 0.0000e+00 - val_loss: 53.4501 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2980 - accuracy: 0.0000e+00 - val_loss: 51.3342 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.2678 - accuracy: 0.0000e+00 - val_loss: 61.1635 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3679 - accuracy: 0.0000e+00 - val_loss: 51.7517 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1364 - accuracy: 0.0000e+00 - val_loss: 51.7550 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.0755 - accuracy: 0.0000e+00 - val_loss: 51.8517 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3884 - accuracy: 0.0000e+00 - val_loss: 51.8963 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.6071 - accuracy: 0.0000e+00 - val_loss: 51.0212 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7589 - accuracy: 0.0000e+00 - val_loss: 51.6508 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.2096 - accuracy: 0.0000e+00 - val_loss: 54.1871 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.0311 - accuracy: 0.0000e+00 - val_loss: 51.3049 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.8980 - accuracy: 0.0000e+00 - val_loss: 51.5528 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.1608 - accuracy: 0.0000e+00 - val_loss: 50.8009 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9270 - accuracy: 0.0000e+00 - val_loss: 52.3149 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.8935 - accuracy: 0.0000e+00 - val_loss: 57.4142 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3539 - accuracy: 0.0000e+00 - val_loss: 54.4703 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.3435 - accuracy: 0.0000e+00 - val_loss: 53.9159 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.2008 - accuracy: 0.0000e+00 - val_loss: 52.4243 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3254 - accuracy: 0.0000e+00 - val_loss: 52.7343 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6681 - accuracy: 0.0000e+00 - val_loss: 51.0546 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2596 - accuracy: 0.0000e+00 - val_loss: 58.6263 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 43.6931 - accuracy: 0.0000e+00 - val_loss: 55.5697 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 39.6288 - accuracy: 0.0000e+00 - val_loss: 53.1606 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6395 - accuracy: 0.0000e+00 - val_loss: 51.0429 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 39.3745 - accuracy: 0.0000e+00 - val_loss: 51.3780 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.4864 - accuracy: 0.0000e+00 - val_loss: 53.3778 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.7147 - accuracy: 0.0000e+00 - val_loss: 51.6780 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 39.1529 - accuracy: 0.0000e+00 - val_loss: 51.9250 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2526 - accuracy: 0.0000e+00 - val_loss: 51.6646 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4878 - accuracy: 0.0000e+00 - val_loss: 53.4050 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.3824 - accuracy: 0.0000e+00 - val_loss: 52.4131 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.7581 - accuracy: 0.0000e+00 - val_loss: 51.1777 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.3969 - accuracy: 0.0000e+00 - val_loss: 52.0402 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.3997 - accuracy: 0.0000e+00 - val_loss: 58.6117 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.7969 - accuracy: 0.0000e+00 - val_loss: 51.8838 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.8696 - accuracy: 0.0000e+00 - val_loss: 54.2797 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.1912 - accuracy: 0.0000e+00 - val_loss: 52.0488 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.7440 - accuracy: 0.0000e+00 - val_loss: 53.1086 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.5901 - accuracy: 0.0000e+00 - val_loss: 50.8060 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.1199 - accuracy: 0.0000e+00 - val_loss: 50.5569 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.4861 - accuracy: 0.0000e+00 - val_loss: 51.8107 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1814 - accuracy: 0.0000e+00 - val_loss: 51.5458 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1886 - accuracy: 0.0000e+00 - val_loss: 52.2725 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9872 - accuracy: 0.0000e+00 - val_loss: 56.7985 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3540 - accuracy: 0.0000e+00 - val_loss: 51.8235 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.5824 - accuracy: 0.0000e+00 - val_loss: 51.3057 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.1042 - accuracy: 0.0000e+00 - val_loss: 52.6610 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7634 - accuracy: 0.0000e+00 - val_loss: 51.9851 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1831 - accuracy: 0.0000e+00 - val_loss: 50.9469 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.5222 - accuracy: 0.0000e+00 - val_loss: 50.5660 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7194 - accuracy: 0.0000e+00 - val_loss: 53.2699 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9514 - accuracy: 0.0000e+00 - val_loss: 50.9348 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.7629 - accuracy: 0.0000e+00 - val_loss: 60.2232 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.0747 - accuracy: 0.0000e+00 - val_loss: 51.3655 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9542 - accuracy: 0.0000e+00 - val_loss: 51.4131 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9801 - accuracy: 0.0000e+00 - val_loss: 51.5143 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.5793 - accuracy: 0.0000e+00 - val_loss: 51.7284 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 44.0315 - accuracy: 0.0000e+00 - val_loss: 50.5444 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.7016 - accuracy: 0.0000e+00 - val_loss: 51.4750 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0088 - accuracy: 0.0000e+00 - val_loss: 53.8913 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.8840 - accuracy: 0.0000e+00 - val_loss: 50.6933 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.6757 - accuracy: 0.0000e+00 - val_loss: 51.1775 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.0168 - accuracy: 0.0000e+00 - val_loss: 50.4338 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.7689 - accuracy: 0.0000e+00 - val_loss: 52.0874 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.6930 - accuracy: 0.0000e+00 - val_loss: 56.8898 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2129 - accuracy: 0.0000e+00 - val_loss: 54.7171 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.3701 - accuracy: 0.0000e+00 - val_loss: 53.5906 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.0410 - accuracy: 0.0000e+00 - val_loss: 51.9991 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1559 - accuracy: 0.0000e+00 - val_loss: 52.5080 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5947 - accuracy: 0.0000e+00 - val_loss: 50.7868 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.0851 - accuracy: 0.0000e+00 - val_loss: 58.0229 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.5413 - accuracy: 0.0000e+00 - val_loss: 55.3910 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.7295 - accuracy: 0.0000e+00 - val_loss: 52.7548 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6841 - accuracy: 0.0000e+00 - val_loss: 50.8648 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.3169 - accuracy: 0.0000e+00 - val_loss: 50.9110 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.3148 - accuracy: 0.0000e+00 - val_loss: 52.8042 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.5696 - accuracy: 0.0000e+00 - val_loss: 51.3889 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.9787 - accuracy: 0.0000e+00 - val_loss: 51.8907 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9876 - accuracy: 0.0000e+00 - val_loss: 51.3774 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.3474 - accuracy: 0.0000e+00 - val_loss: 52.8497 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.0994 - accuracy: 0.0000e+00 - val_loss: 52.0739 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6638 - accuracy: 0.0000e+00 - val_loss: 50.8777 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.2205 - accuracy: 0.0000e+00 - val_loss: 51.6696 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2975 - accuracy: 0.0000e+00 - val_loss: 57.9154 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6819 - accuracy: 0.0000e+00 - val_loss: 51.2564 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.5709 - accuracy: 0.0000e+00 - val_loss: 53.6452 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9667 - accuracy: 0.0000e+00 - val_loss: 51.8447 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.8564 - accuracy: 0.0000e+00 - val_loss: 52.6167 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.4582 - accuracy: 0.0000e+00 - val_loss: 50.5815 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.9478 - accuracy: 0.0000e+00 - val_loss: 50.4191 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.3761 - accuracy: 0.0000e+00 - val_loss: 51.2016 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8660 - accuracy: 0.0000e+00 - val_loss: 51.1641 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.7758 - accuracy: 0.0000e+00 - val_loss: 51.7902 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.7647 - accuracy: 0.0000e+00 - val_loss: 57.0561 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.3096 - accuracy: 0.0000e+00 - val_loss: 51.6880 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5017 - accuracy: 0.0000e+00 - val_loss: 51.3909 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.0155 - accuracy: 0.0000e+00 - val_loss: 52.3625 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7070 - accuracy: 0.0000e+00 - val_loss: 51.8496 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9458 - accuracy: 0.0000e+00 - val_loss: 50.7040 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.3670 - accuracy: 0.0000e+00 - val_loss: 50.3010 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.6643 - accuracy: 0.0000e+00 - val_loss: 53.0480 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8376 - accuracy: 0.0000e+00 - val_loss: 50.9312 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.6818 - accuracy: 0.0000e+00 - val_loss: 60.2544 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.1838 - accuracy: 0.0000e+00 - val_loss: 51.6076 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8443 - accuracy: 0.0000e+00 - val_loss: 51.2146 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.7174 - accuracy: 0.0000e+00 - val_loss: 51.2313 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.2161 - accuracy: 0.0000e+00 - val_loss: 51.5556 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.4755 - accuracy: 0.0000e+00 - val_loss: 50.3356 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.2988 - accuracy: 0.0000e+00 - val_loss: 51.0420 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0387 - accuracy: 0.0000e+00 - val_loss: 53.2789 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6217 - accuracy: 0.0000e+00 - val_loss: 50.1080 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 39.4979 - accuracy: 0.0000e+00 - val_loss: 50.6879 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.9494 - accuracy: 0.0000e+00 - val_loss: 50.4574 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.6367 - accuracy: 0.0000e+00 - val_loss: 52.1737 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.5391 - accuracy: 0.0000e+00 - val_loss: 56.3416 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1101 - accuracy: 0.0000e+00 - val_loss: 54.8102 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 43.3946 - accuracy: 0.0000e+00 - val_loss: 53.0784 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.9331 - accuracy: 0.0000e+00 - val_loss: 51.6559 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.1253 - accuracy: 0.0000e+00 - val_loss: 51.5412 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6232 - accuracy: 0.0000e+00 - val_loss: 50.3638 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8509 - accuracy: 0.0000e+00 - val_loss: 56.7991 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 42.7933 - accuracy: 0.0000e+00 - val_loss: 54.8478 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.6420 - accuracy: 0.0000e+00 - val_loss: 52.2737 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4148 - accuracy: 0.0000e+00 - val_loss: 50.5415 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 39.0380 - accuracy: 0.0000e+00 - val_loss: 50.6212 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 41.0117 - accuracy: 0.0000e+00 - val_loss: 52.3299 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.3822 - accuracy: 0.0000e+00 - val_loss: 50.9034 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.7572 - accuracy: 0.0000e+00 - val_loss: 51.4642 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8982 - accuracy: 0.0000e+00 - val_loss: 50.6941 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0825 - accuracy: 0.0000e+00 - val_loss: 52.7479 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9046 - accuracy: 0.0000e+00 - val_loss: 51.4968 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 39.4402 - accuracy: 0.0000e+00 - val_loss: 50.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.9031 - accuracy: 0.0000e+00 - val_loss: 51.5373 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0500 - accuracy: 0.0000e+00 - val_loss: 56.5988 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3481 - accuracy: 0.0000e+00 - val_loss: 50.5724 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2818 - accuracy: 0.0000e+00 - val_loss: 52.7112 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.4283 - accuracy: 0.0000e+00 - val_loss: 51.8977 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.5937 - accuracy: 0.0000e+00 - val_loss: 52.2786 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.2034 - accuracy: 0.0000e+00 - val_loss: 49.9077 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.8084 - accuracy: 0.0000e+00 - val_loss: 49.7467 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0452 - accuracy: 0.0000e+00 - val_loss: 50.7656 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.7802 - accuracy: 0.0000e+00 - val_loss: 51.0346 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8617 - accuracy: 0.0000e+00 - val_loss: 51.2210 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 39.9979 - accuracy: 0.0000e+00 - val_loss: 56.3812 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1463 - accuracy: 0.0000e+00 - val_loss: 51.1957 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1052 - accuracy: 0.0000e+00 - val_loss: 51.3952 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0981 - accuracy: 0.0000e+00 - val_loss: 52.2718 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.4318 - accuracy: 0.0000e+00 - val_loss: 51.5646 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5363 - accuracy: 0.0000e+00 - val_loss: 50.2260 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.0358 - accuracy: 0.0000e+00 - val_loss: 50.0680 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 41.2521 - accuracy: 0.0000e+00 - val_loss: 52.4436 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.4946 - accuracy: 0.0000e+00 - val_loss: 50.4855 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.4619 - accuracy: 0.0000e+00 - val_loss: 59.8535 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2440 - accuracy: 0.0000e+00 - val_loss: 51.3898 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.7185 - accuracy: 0.0000e+00 - val_loss: 50.8681 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.5199 - accuracy: 0.0000e+00 - val_loss: 51.1242 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.2934 - accuracy: 0.0000e+00 - val_loss: 51.3755 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.2729 - accuracy: 0.0000e+00 - val_loss: 50.3177 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4693 - accuracy: 0.0000e+00 - val_loss: 50.5772 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.8834 - accuracy: 0.0000e+00 - val_loss: 52.7837 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.4379 - accuracy: 0.0000e+00 - val_loss: 49.5904 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 39.2381 - accuracy: 0.0000e+00 - val_loss: 50.0922 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.7994 - accuracy: 0.0000e+00 - val_loss: 49.8028 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.3932 - accuracy: 0.0000e+00 - val_loss: 51.6655 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.5173 - accuracy: 0.0000e+00 - val_loss: 55.5563 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 41.3202 - accuracy: 0.0000e+00 - val_loss: 54.4630 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 43.3362 - accuracy: 0.0000e+00 - val_loss: 52.2550 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.7079 - accuracy: 0.0000e+00 - val_loss: 50.9455 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9370 - accuracy: 0.0000e+00 - val_loss: 51.4261 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5255 - accuracy: 0.0000e+00 - val_loss: 49.8276 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8652 - accuracy: 0.0000e+00 - val_loss: 56.6083 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 42.7055 - accuracy: 0.0000e+00 - val_loss: 54.2914 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.4294 - accuracy: 0.0000e+00 - val_loss: 51.6169 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.1807 - accuracy: 0.0000e+00 - val_loss: 49.9879 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.8515 - accuracy: 0.0000e+00 - val_loss: 49.9883 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 40.8520 - accuracy: 0.0000e+00 - val_loss: 51.7727 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 39.3072 - accuracy: 0.0000e+00 - val_loss: 50.3247 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.5717 - accuracy: 0.0000e+00 - val_loss: 50.6359 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9104 - accuracy: 0.0000e+00 - val_loss: 50.2094 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.2665 - accuracy: 0.0000e+00 - val_loss: 52.7920 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8698 - accuracy: 0.0000e+00 - val_loss: 50.4785 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.3905 - accuracy: 0.0000e+00 - val_loss: 49.6877 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.9172 - accuracy: 0.0000e+00 - val_loss: 51.4861 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.2161 - accuracy: 0.0000e+00 - val_loss: 56.4561 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.2522 - accuracy: 0.0000e+00 - val_loss: 50.3041 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.9721 - accuracy: 0.0000e+00 - val_loss: 51.8789 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.4278 - accuracy: 0.0000e+00 - val_loss: 51.1401 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.2883 - accuracy: 0.0000e+00 - val_loss: 51.4944 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.9132 - accuracy: 0.0000e+00 - val_loss: 49.3769 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.5749 - accuracy: 0.0000e+00 - val_loss: 49.2529 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.8860 - accuracy: 0.0000e+00 - val_loss: 50.0145 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.5288 - accuracy: 0.0000e+00 - val_loss: 50.0115 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2449 - accuracy: 0.0000e+00 - val_loss: 50.4804 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.6129 - accuracy: 0.0000e+00 - val_loss: 55.8472 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.0000 - accuracy: 0.0000e+00 - val_loss: 50.0322 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.6995 - accuracy: 0.0000e+00 - val_loss: 50.6111 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6903 - accuracy: 0.0000e+00 - val_loss: 51.3662 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.0822 - accuracy: 0.0000e+00 - val_loss: 50.6958 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.2466 - accuracy: 0.0000e+00 - val_loss: 49.3118 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9258 - accuracy: 0.0000e+00 - val_loss: 48.9984 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.9202 - accuracy: 0.0000e+00 - val_loss: 51.4903 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0263 - accuracy: 0.0000e+00 - val_loss: 49.4074 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 40.8281 - accuracy: 0.0000e+00 - val_loss: 57.4754 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.6858 - accuracy: 0.0000e+00 - val_loss: 50.1781 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.1782 - accuracy: 0.0000e+00 - val_loss: 49.9648 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0066 - accuracy: 0.0000e+00 - val_loss: 50.4481 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8632 - accuracy: 0.0000e+00 - val_loss: 50.7722 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.5242 - accuracy: 0.0000e+00 - val_loss: 48.4349 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.2961 - accuracy: 0.0000e+00 - val_loss: 48.6708 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.1451 - accuracy: 0.0000e+00 - val_loss: 51.2876 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.5644 - accuracy: 0.0000e+00 - val_loss: 47.8335 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.0976 - accuracy: 0.0000e+00 - val_loss: 48.2851 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.9142 - accuracy: 0.0000e+00 - val_loss: 47.8499 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.3069 - accuracy: 0.0000e+00 - val_loss: 49.6876 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 37.4430 - accuracy: 0.0000e+00 - val_loss: 52.8009 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 39.9265 - accuracy: 0.0000e+00 - val_loss: 51.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1737 - accuracy: 0.0000e+00 - val_loss: 50.0770 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8512 - accuracy: 0.0000e+00 - val_loss: 49.8182 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.0086 - accuracy: 0.0000e+00 - val_loss: 48.8150 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.9039 - accuracy: 0.0000e+00 - val_loss: 48.2538 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.1833 - accuracy: 0.0000e+00 - val_loss: 53.7271 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.1634 - accuracy: 0.0000e+00 - val_loss: 51.7194 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.4245 - accuracy: 0.0000e+00 - val_loss: 48.6159 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0733 - accuracy: 0.0000e+00 - val_loss: 48.1937 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.9410 - accuracy: 0.0000e+00 - val_loss: 47.7808 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 39.7474 - accuracy: 0.0000e+00 - val_loss: 49.8442 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.1169 - accuracy: 0.0000e+00 - val_loss: 47.6383 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.4726 - accuracy: 0.0000e+00 - val_loss: 49.1832 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.1394 - accuracy: 0.0000e+00 - val_loss: 47.6371 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.7577 - accuracy: 0.0000e+00 - val_loss: 50.2677 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.4652 - accuracy: 0.0000e+00 - val_loss: 48.6974 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.1122 - accuracy: 0.0000e+00 - val_loss: 47.1561 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.7677 - accuracy: 0.0000e+00 - val_loss: 49.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.8006 - accuracy: 0.0000e+00 - val_loss: 54.2476 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.7443 - accuracy: 0.0000e+00 - val_loss: 47.6278 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.4834 - accuracy: 0.0000e+00 - val_loss: 49.6131 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.9488 - accuracy: 0.0000e+00 - val_loss: 49.3687 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8013 - accuracy: 0.0000e+00 - val_loss: 49.7872 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 42.1326 - accuracy: 0.0000e+00 - val_loss: 47.1832 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.5507 - accuracy: 0.0000e+00 - val_loss: 47.0920 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.6009 - accuracy: 0.0000e+00 - val_loss: 47.8498 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.6750 - accuracy: 0.0000e+00 - val_loss: 48.0288 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.1547 - accuracy: 0.0000e+00 - val_loss: 48.7722 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.5952 - accuracy: 0.0000e+00 - val_loss: 53.1815 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.4728 - accuracy: 0.0000e+00 - val_loss: 47.7048 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.3793 - accuracy: 0.0000e+00 - val_loss: 48.2028 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.3302 - accuracy: 0.0000e+00 - val_loss: 49.3581 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.3928 - accuracy: 0.0000e+00 - val_loss: 49.0782 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 38.8425 - accuracy: 0.0000e+00 - val_loss: 47.0461 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 38.9658 - accuracy: 0.0000e+00 - val_loss: 46.7230 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.4337 - accuracy: 0.0000e+00 - val_loss: 48.5431 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.9852 - accuracy: 0.0000e+00 - val_loss: 47.3202 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 40.5661 - accuracy: 0.0000e+00 - val_loss: 58.0128 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0052 - accuracy: 0.0000e+00 - val_loss: 48.4901 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.9092 - accuracy: 0.0000e+00 - val_loss: 47.9177 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.6996 - accuracy: 0.0000e+00 - val_loss: 49.2154 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.7313 - accuracy: 0.0000e+00 - val_loss: 49.1101 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 41.5006 - accuracy: 0.0000e+00 - val_loss: 46.7713 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.3913 - accuracy: 0.0000e+00 - val_loss: 46.8091 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.2547 - accuracy: 0.0000e+00 - val_loss: 49.8775 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.6411 - accuracy: 0.0000e+00 - val_loss: 47.0104 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.4123 - accuracy: 0.0000e+00 - val_loss: 46.9178 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.3054 - accuracy: 0.0000e+00 - val_loss: 46.3734 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.3657 - accuracy: 0.0000e+00 - val_loss: 48.2696 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.5841 - accuracy: 0.0000e+00 - val_loss: 52.5755 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.3143 - accuracy: 0.0000e+00 - val_loss: 50.8675 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.2870 - accuracy: 0.0000e+00 - val_loss: 49.5133 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 40.2144 - accuracy: 0.0000e+00 - val_loss: 49.0807 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.7536 - accuracy: 0.0000e+00 - val_loss: 48.5777 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0512 - accuracy: 0.0000e+00 - val_loss: 47.7434 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.8855 - accuracy: 0.0000e+00 - val_loss: 53.4642 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5943 - accuracy: 0.0000e+00 - val_loss: 51.2343 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.5718 - accuracy: 0.0000e+00 - val_loss: 47.6693 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.1544 - accuracy: 0.0000e+00 - val_loss: 46.5626 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.3698 - accuracy: 0.0000e+00 - val_loss: 47.2113 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 39.6779 - accuracy: 0.0000e+00 - val_loss: 49.5006 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.4998 - accuracy: 0.0000e+00 - val_loss: 46.6855 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.8102 - accuracy: 0.0000e+00 - val_loss: 48.4625 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.3401 - accuracy: 0.0000e+00 - val_loss: 47.1299 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.3058 - accuracy: 0.0000e+00 - val_loss: 50.2703 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.9881 - accuracy: 0.0000e+00 - val_loss: 48.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.5138 - accuracy: 0.0000e+00 - val_loss: 46.5987 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.9765 - accuracy: 0.0000e+00 - val_loss: 48.4859 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.8061 - accuracy: 0.0000e+00 - val_loss: 53.4292 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.9545 - accuracy: 0.0000e+00 - val_loss: 47.4567 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.7319 - accuracy: 0.0000e+00 - val_loss: 49.4206 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.3334 - accuracy: 0.0000e+00 - val_loss: 48.9300 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8082 - accuracy: 0.0000e+00 - val_loss: 49.1752 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 41.5921 - accuracy: 0.0000e+00 - val_loss: 46.7128 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.0630 - accuracy: 0.0000e+00 - val_loss: 46.6194 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 37.0098 - accuracy: 0.0000e+00 - val_loss: 47.0686 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.9651 - accuracy: 0.0000e+00 - val_loss: 47.3082 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.4298 - accuracy: 0.0000e+00 - val_loss: 48.3424 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.0058 - accuracy: 0.0000e+00 - val_loss: 53.9294 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0783 - accuracy: 0.0000e+00 - val_loss: 46.9333 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.5748 - accuracy: 0.0000e+00 - val_loss: 48.3095 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 37.7605 - accuracy: 0.0000e+00 - val_loss: 49.3587 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.4661 - accuracy: 0.0000e+00 - val_loss: 48.3388 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.9272 - accuracy: 0.0000e+00 - val_loss: 46.8315 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.2084 - accuracy: 0.0000e+00 - val_loss: 46.6726 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.8232 - accuracy: 0.0000e+00 - val_loss: 48.9328 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.3728 - accuracy: 0.0000e+00 - val_loss: 47.1002 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.8392 - accuracy: 0.0000e+00 - val_loss: 57.0257 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.6700 - accuracy: 0.0000e+00 - val_loss: 48.0589 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.1226 - accuracy: 0.0000e+00 - val_loss: 47.6515 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.7572 - accuracy: 0.0000e+00 - val_loss: 49.8265 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.7312 - accuracy: 0.0000e+00 - val_loss: 49.2057 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0185 - accuracy: 0.0000e+00 - val_loss: 47.0558 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.8328 - accuracy: 0.0000e+00 - val_loss: 47.3792 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.4721 - accuracy: 0.0000e+00 - val_loss: 50.3135 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.1208 - accuracy: 0.0000e+00 - val_loss: 47.1742 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 36.5412 - accuracy: 0.0000e+00 - val_loss: 47.6593 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.5580 - accuracy: 0.0000e+00 - val_loss: 46.5194 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.6092 - accuracy: 0.0000e+00 - val_loss: 48.6688 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.8144 - accuracy: 0.0000e+00 - val_loss: 53.0943 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.4306 - accuracy: 0.0000e+00 - val_loss: 50.0627 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.5390 - accuracy: 0.0000e+00 - val_loss: 48.4081 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.8397 - accuracy: 0.0000e+00 - val_loss: 48.9929 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.0450 - accuracy: 0.0000e+00 - val_loss: 48.5952 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.6073 - accuracy: 0.0000e+00 - val_loss: 47.5139 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.8555 - accuracy: 0.0000e+00 - val_loss: 53.3853 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 39.6589 - accuracy: 0.0000e+00 - val_loss: 50.4413 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.7947 - accuracy: 0.0000e+00 - val_loss: 47.6058 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.2233 - accuracy: 0.0000e+00 - val_loss: 46.9738 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.3028 - accuracy: 0.0000e+00 - val_loss: 47.7094 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 38.5879 - accuracy: 0.0000e+00 - val_loss: 50.0846 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 36.9230 - accuracy: 0.0000e+00 - val_loss: 47.1063 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 36.1218 - accuracy: 0.0000e+00 - val_loss: 49.1232 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.6836 - accuracy: 0.0000e+00 - val_loss: 47.2685 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.2385 - accuracy: 0.0000e+00 - val_loss: 49.7059 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.7389 - accuracy: 0.0000e+00 - val_loss: 48.2629 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.7050 - accuracy: 0.0000e+00 - val_loss: 47.1930 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.1626 - accuracy: 0.0000e+00 - val_loss: 48.9826 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.2098 - accuracy: 0.0000e+00 - val_loss: 54.2512 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.4787 - accuracy: 0.0000e+00 - val_loss: 47.5733 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.1104 - accuracy: 0.0000e+00 - val_loss: 49.8098 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.2318 - accuracy: 0.0000e+00 - val_loss: 48.9749 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.6952 - accuracy: 0.0000e+00 - val_loss: 49.4151 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.8879 - accuracy: 0.0000e+00 - val_loss: 47.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 36.2824 - accuracy: 0.0000e+00 - val_loss: 46.9609 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 36.4068 - accuracy: 0.0000e+00 - val_loss: 47.1763 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 37.3755 - accuracy: 0.0000e+00 - val_loss: 47.6889 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 37.8134 - accuracy: 0.0000e+00 - val_loss: 48.8342 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 37.4781 - accuracy: 0.0000e+00 - val_loss: 54.4351 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 38.5427 - accuracy: 0.0000e+00 - val_loss: 47.2813 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 37.2543 - accuracy: 0.0000e+00 - val_loss: 48.2539 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 37.4118 - accuracy: 0.0000e+00 - val_loss: 49.9172 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.4195 - accuracy: 0.0000e+00 - val_loss: 48.4304 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 37.6749 - accuracy: 0.0000e+00 - val_loss: 46.8484 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 37.8393 - accuracy: 0.0000e+00 - val_loss: 46.7249 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 38.5112 - accuracy: 0.0000e+00 - val_loss: 48.5869 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 37.2374 - accuracy: 0.0000e+00 - val_loss: 47.1884 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 39.8166 - accuracy: 0.0000e+00 - val_loss: 56.2801 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 38.4576 - accuracy: 0.0000e+00 - val_loss: 47.8751 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 36.7768 - accuracy: 0.0000e+00 - val_loss: 47.8384 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 36.5178 - accuracy: 0.0000e+00 - val_loss: 49.9608 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.1797 - accuracy: 0.0000e+00 - val_loss: 48.4755 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 39.2843 - accuracy: 0.0000e+00 - val_loss: 46.8711 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 37.4218 - accuracy: 0.0000e+00 - val_loss: 46.9282 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 36.2272 - accuracy: 0.0000e+00 - val_loss: 50.2947 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 36.7778 - accuracy: 0.0000e+00 - val_loss: 47.3311 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.1718 - accuracy: 0.0000e+00 - val_loss: 47.6325 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 36.3911 - accuracy: 0.0000e+00 - val_loss: 46.3404 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 36.2356 - accuracy: 0.0000e+00 - val_loss: 48.7768 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 35.5223 - accuracy: 0.0000e+00 - val_loss: 52.2454 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.7951 - accuracy: 0.0000e+00 - val_loss: 49.1854 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.0564 - accuracy: 0.0000e+00 - val_loss: 47.8682 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.3654 - accuracy: 0.0000e+00 - val_loss: 49.1215 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.7894 - accuracy: 0.0000e+00 - val_loss: 47.9428 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.5715 - accuracy: 0.0000e+00 - val_loss: 46.8712 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.3467 - accuracy: 0.0000e+00 - val_loss: 52.2800 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0145 - accuracy: 0.0000e+00 - val_loss: 49.6490 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.4590 - accuracy: 0.0000e+00 - val_loss: 47.0894 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.8114 - accuracy: 0.0000e+00 - val_loss: 46.5289 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.8956 - accuracy: 0.0000e+00 - val_loss: 47.1561 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 38.2469 - accuracy: 0.0000e+00 - val_loss: 49.6769 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.5484 - accuracy: 0.0000e+00 - val_loss: 46.7309 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.7255 - accuracy: 0.0000e+00 - val_loss: 48.7618 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.2557 - accuracy: 0.0000e+00 - val_loss: 46.8128 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.7372 - accuracy: 0.0000e+00 - val_loss: 48.5412 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.1479 - accuracy: 0.0000e+00 - val_loss: 47.4900 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.3225 - accuracy: 0.0000e+00 - val_loss: 46.4918 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.7753 - accuracy: 0.0000e+00 - val_loss: 47.6316 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.7391 - accuracy: 0.0000e+00 - val_loss: 53.2480 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.1761 - accuracy: 0.0000e+00 - val_loss: 46.3754 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.6527 - accuracy: 0.0000e+00 - val_loss: 49.0326 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.6329 - accuracy: 0.0000e+00 - val_loss: 48.2418 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.2915 - accuracy: 0.0000e+00 - val_loss: 48.5450 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 40.3649 - accuracy: 0.0000e+00 - val_loss: 46.3034 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.8798 - accuracy: 0.0000e+00 - val_loss: 45.8890 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.7775 - accuracy: 0.0000e+00 - val_loss: 46.2545 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.6911 - accuracy: 0.0000e+00 - val_loss: 46.8010 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.0701 - accuracy: 0.0000e+00 - val_loss: 48.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.0983 - accuracy: 0.0000e+00 - val_loss: 53.6562 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.6861 - accuracy: 0.0000e+00 - val_loss: 46.3384 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.7686 - accuracy: 0.0000e+00 - val_loss: 47.1565 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.7691 - accuracy: 0.0000e+00 - val_loss: 49.4450 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 37.3786 - accuracy: 0.0000e+00 - val_loss: 46.4166 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.6381 - accuracy: 0.0000e+00 - val_loss: 46.4748 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.8818 - accuracy: 0.0000e+00 - val_loss: 45.6080 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.6952 - accuracy: 0.0000e+00 - val_loss: 48.5451 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.5176 - accuracy: 0.0000e+00 - val_loss: 46.1619 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.6046 - accuracy: 0.0000e+00 - val_loss: 54.2043 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.0273 - accuracy: 0.0000e+00 - val_loss: 46.1412 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.9242 - accuracy: 0.0000e+00 - val_loss: 46.3960 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 35.6181 - accuracy: 0.0000e+00 - val_loss: 48.9858 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.1047 - accuracy: 0.0000e+00 - val_loss: 46.8990 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.0345 - accuracy: 0.0000e+00 - val_loss: 45.7041 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.6482 - accuracy: 0.0000e+00 - val_loss: 45.7419 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.6169 - accuracy: 0.0000e+00 - val_loss: 48.8903 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.9685 - accuracy: 0.0000e+00 - val_loss: 46.5599 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 35.3080 - accuracy: 0.0000e+00 - val_loss: 46.7358 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.8912 - accuracy: 0.0000e+00 - val_loss: 44.9596 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.5567 - accuracy: 0.0000e+00 - val_loss: 47.2864 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.6597 - accuracy: 0.0000e+00 - val_loss: 51.6921 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 36.9401 - accuracy: 0.0000e+00 - val_loss: 47.0045 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.0790 - accuracy: 0.0000e+00 - val_loss: 47.1983 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.6508 - accuracy: 0.0000e+00 - val_loss: 49.3228 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.4441 - accuracy: 0.0000e+00 - val_loss: 47.0959 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.5456 - accuracy: 0.0000e+00 - val_loss: 45.4392 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.8155 - accuracy: 0.0000e+00 - val_loss: 51.6549 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.2478 - accuracy: 0.0000e+00 - val_loss: 47.8981 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.8172 - accuracy: 0.0000e+00 - val_loss: 45.5625 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.9949 - accuracy: 0.0000e+00 - val_loss: 45.5982 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 35.1545 - accuracy: 0.0000e+00 - val_loss: 45.9606 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 37.0384 - accuracy: 0.0000e+00 - val_loss: 48.5031 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 35.7363 - accuracy: 0.0000e+00 - val_loss: 45.3239 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 34.9841 - accuracy: 0.0000e+00 - val_loss: 47.5352 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.4362 - accuracy: 0.0000e+00 - val_loss: 45.4977 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.7578 - accuracy: 0.0000e+00 - val_loss: 47.3051 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.4536 - accuracy: 0.0000e+00 - val_loss: 46.1643 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.6914 - accuracy: 0.0000e+00 - val_loss: 45.3935 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.9241 - accuracy: 0.0000e+00 - val_loss: 45.6439 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.8024 - accuracy: 0.0000e+00 - val_loss: 52.3801 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.3084 - accuracy: 0.0000e+00 - val_loss: 45.3134 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.0007 - accuracy: 0.0000e+00 - val_loss: 48.6328 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 35.8709 - accuracy: 0.0000e+00 - val_loss: 47.2635 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.9859 - accuracy: 0.0000e+00 - val_loss: 47.8748 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.6673 - accuracy: 0.0000e+00 - val_loss: 45.4346 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.1946 - accuracy: 0.0000e+00 - val_loss: 44.8654 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.2143 - accuracy: 0.0000e+00 - val_loss: 45.4036 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.9138 - accuracy: 0.0000e+00 - val_loss: 45.7715 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.3853 - accuracy: 0.0000e+00 - val_loss: 47.1670 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.5775 - accuracy: 0.0000e+00 - val_loss: 52.3939 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.1667 - accuracy: 0.0000e+00 - val_loss: 45.8328 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.5106 - accuracy: 0.0000e+00 - val_loss: 46.1765 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.1945 - accuracy: 0.0000e+00 - val_loss: 48.5532 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.9317 - accuracy: 0.0000e+00 - val_loss: 45.9929 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 36.3368 - accuracy: 0.0000e+00 - val_loss: 45.5961 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.4283 - accuracy: 0.0000e+00 - val_loss: 45.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.3299 - accuracy: 0.0000e+00 - val_loss: 47.7119 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 36.0549 - accuracy: 0.0000e+00 - val_loss: 45.5200 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.3969 - accuracy: 0.0000e+00 - val_loss: 53.0911 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.7241 - accuracy: 0.0000e+00 - val_loss: 45.4972 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.5377 - accuracy: 0.0000e+00 - val_loss: 46.1148 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.5292 - accuracy: 0.0000e+00 - val_loss: 48.2116 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.9847 - accuracy: 0.0000e+00 - val_loss: 46.5682 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.9780 - accuracy: 0.0000e+00 - val_loss: 45.2139 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.2692 - accuracy: 0.0000e+00 - val_loss: 45.4316 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.1230 - accuracy: 0.0000e+00 - val_loss: 48.7977 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.7013 - accuracy: 0.0000e+00 - val_loss: 46.3242 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.9402 - accuracy: 0.0000e+00 - val_loss: 46.6388 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.4139 - accuracy: 0.0000e+00 - val_loss: 44.5986 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.1569 - accuracy: 0.0000e+00 - val_loss: 46.7544 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.3161 - accuracy: 0.0000e+00 - val_loss: 51.1817 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.5480 - accuracy: 0.0000e+00 - val_loss: 46.3814 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 38.5631 - accuracy: 0.0000e+00 - val_loss: 46.4672 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.8851 - accuracy: 0.0000e+00 - val_loss: 48.3737 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.7692 - accuracy: 0.0000e+00 - val_loss: 46.8579 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.1758 - accuracy: 0.0000e+00 - val_loss: 45.0841 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.1686 - accuracy: 0.0000e+00 - val_loss: 51.1142 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.9808 - accuracy: 0.0000e+00 - val_loss: 47.8241 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.3529 - accuracy: 0.0000e+00 - val_loss: 45.4769 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.7500 - accuracy: 0.0000e+00 - val_loss: 44.9436 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.8700 - accuracy: 0.0000e+00 - val_loss: 45.6406 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 36.6581 - accuracy: 0.0000e+00 - val_loss: 48.1089 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.3538 - accuracy: 0.0000e+00 - val_loss: 45.0262 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.7046 - accuracy: 0.0000e+00 - val_loss: 46.8697 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.1698 - accuracy: 0.0000e+00 - val_loss: 45.1652 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.3601 - accuracy: 0.0000e+00 - val_loss: 46.5253 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.0167 - accuracy: 0.0000e+00 - val_loss: 45.5410 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.4423 - accuracy: 0.0000e+00 - val_loss: 45.3015 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.5542 - accuracy: 0.0000e+00 - val_loss: 45.2467 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.5328 - accuracy: 0.0000e+00 - val_loss: 51.4425 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.9860 - accuracy: 0.0000e+00 - val_loss: 45.1174 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.7964 - accuracy: 0.0000e+00 - val_loss: 48.8351 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.6020 - accuracy: 0.0000e+00 - val_loss: 46.9291 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.5289 - accuracy: 0.0000e+00 - val_loss: 47.5455 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 39.2267 - accuracy: 0.0000e+00 - val_loss: 45.1321 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.9365 - accuracy: 0.0000e+00 - val_loss: 44.6349 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.9883 - accuracy: 0.0000e+00 - val_loss: 45.0289 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.7592 - accuracy: 0.0000e+00 - val_loss: 45.4684 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.2083 - accuracy: 0.0000e+00 - val_loss: 46.9288 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.3990 - accuracy: 0.0000e+00 - val_loss: 52.3421 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.9021 - accuracy: 0.0000e+00 - val_loss: 45.8862 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.4781 - accuracy: 0.0000e+00 - val_loss: 45.9003 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.9409 - accuracy: 0.0000e+00 - val_loss: 47.8919 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 36.8734 - accuracy: 0.0000e+00 - val_loss: 45.2237 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.0338 - accuracy: 0.0000e+00 - val_loss: 45.3333 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.2111 - accuracy: 0.0000e+00 - val_loss: 44.8075 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.9343 - accuracy: 0.0000e+00 - val_loss: 47.1096 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.7647 - accuracy: 0.0000e+00 - val_loss: 45.3007 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.9962 - accuracy: 0.0000e+00 - val_loss: 52.3667 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.3704 - accuracy: 0.0000e+00 - val_loss: 45.1701 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.3383 - accuracy: 0.0000e+00 - val_loss: 45.6280 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.1195 - accuracy: 0.0000e+00 - val_loss: 48.3509 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.5838 - accuracy: 0.0000e+00 - val_loss: 46.1175 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.7425 - accuracy: 0.0000e+00 - val_loss: 44.9154 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.0826 - accuracy: 0.0000e+00 - val_loss: 45.1705 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 34.8432 - accuracy: 0.0000e+00 - val_loss: 47.9695 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 35.3586 - accuracy: 0.0000e+00 - val_loss: 46.3704 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.7557 - accuracy: 0.0000e+00 - val_loss: 46.6178 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.2921 - accuracy: 0.0000e+00 - val_loss: 44.4290 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.0054 - accuracy: 0.0000e+00 - val_loss: 46.3369 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.1130 - accuracy: 0.0000e+00 - val_loss: 50.8257 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.3393 - accuracy: 0.0000e+00 - val_loss: 46.0939 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.4389 - accuracy: 0.0000e+00 - val_loss: 45.8826 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.7216 - accuracy: 0.0000e+00 - val_loss: 48.2041 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.4547 - accuracy: 0.0000e+00 - val_loss: 46.8035 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.1043 - accuracy: 0.0000e+00 - val_loss: 44.8011 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.7854 - accuracy: 0.0000e+00 - val_loss: 50.6706 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.6267 - accuracy: 0.0000e+00 - val_loss: 47.4676 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.1111 - accuracy: 0.0000e+00 - val_loss: 45.2980 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.5569 - accuracy: 0.0000e+00 - val_loss: 44.6760 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.7056 - accuracy: 0.0000e+00 - val_loss: 45.3784 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 36.3736 - accuracy: 0.0000e+00 - val_loss: 47.9781 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.2076 - accuracy: 0.0000e+00 - val_loss: 44.7850 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.5971 - accuracy: 0.0000e+00 - val_loss: 46.7132 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.0167 - accuracy: 0.0000e+00 - val_loss: 44.6360 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.0453 - accuracy: 0.0000e+00 - val_loss: 46.2821 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.7704 - accuracy: 0.0000e+00 - val_loss: 45.3683 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.2373 - accuracy: 0.0000e+00 - val_loss: 44.9365 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.3299 - accuracy: 0.0000e+00 - val_loss: 44.9213 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.2139 - accuracy: 0.0000e+00 - val_loss: 50.8737 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.7290 - accuracy: 0.0000e+00 - val_loss: 45.0418 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.6935 - accuracy: 0.0000e+00 - val_loss: 48.0378 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.3043 - accuracy: 0.0000e+00 - val_loss: 46.7368 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.3529 - accuracy: 0.0000e+00 - val_loss: 47.3633 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 38.9494 - accuracy: 0.0000e+00 - val_loss: 44.4704 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.8304 - accuracy: 0.0000e+00 - val_loss: 44.6042 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.7529 - accuracy: 0.0000e+00 - val_loss: 44.7607 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.4756 - accuracy: 0.0000e+00 - val_loss: 45.3999 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.1782 - accuracy: 0.0000e+00 - val_loss: 46.5814 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.1349 - accuracy: 0.0000e+00 - val_loss: 51.7061 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.6614 - accuracy: 0.0000e+00 - val_loss: 45.4759 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 36.1600 - accuracy: 0.0000e+00 - val_loss: 45.8439 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.9418 - accuracy: 0.0000e+00 - val_loss: 47.5614 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.6554 - accuracy: 0.0000e+00 - val_loss: 45.2179 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 35.8954 - accuracy: 0.0000e+00 - val_loss: 45.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.9566 - accuracy: 0.0000e+00 - val_loss: 44.4335 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.6297 - accuracy: 0.0000e+00 - val_loss: 46.6447 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.5551 - accuracy: 0.0000e+00 - val_loss: 45.1280 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.9708 - accuracy: 0.0000e+00 - val_loss: 51.7986 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.3163 - accuracy: 0.0000e+00 - val_loss: 44.9224 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 35.1197 - accuracy: 0.0000e+00 - val_loss: 45.1715 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.9382 - accuracy: 0.0000e+00 - val_loss: 48.0444 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.4299 - accuracy: 0.0000e+00 - val_loss: 45.5994 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.5072 - accuracy: 0.0000e+00 - val_loss: 44.5378 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.8791 - accuracy: 0.0000e+00 - val_loss: 44.6658 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.6291 - accuracy: 0.0000e+00 - val_loss: 47.4915 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.1581 - accuracy: 0.0000e+00 - val_loss: 46.0698 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 34.5142 - accuracy: 0.0000e+00 - val_loss: 46.5103 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.0851 - accuracy: 0.0000e+00 - val_loss: 44.0552 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.8955 - accuracy: 0.0000e+00 - val_loss: 46.1199 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 33.9356 - accuracy: 0.0000e+00 - val_loss: 50.8440 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.1531 - accuracy: 0.0000e+00 - val_loss: 45.8012 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 38.0360 - accuracy: 0.0000e+00 - val_loss: 44.8705 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 37.3262 - accuracy: 0.0000e+00 - val_loss: 47.7010 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 36.0950 - accuracy: 0.0000e+00 - val_loss: 46.3563 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 37.9385 - accuracy: 0.0000e+00 - val_loss: 44.1623 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 35.6325 - accuracy: 0.0000e+00 - val_loss: 50.1369 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 37.4381 - accuracy: 0.0000e+00 - val_loss: 47.2239 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.8272 - accuracy: 0.0000e+00 - val_loss: 44.6212 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 35.1785 - accuracy: 0.0000e+00 - val_loss: 44.2546 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 34.5149 - accuracy: 0.0000e+00 - val_loss: 44.2590 - val_accuracy: 0.0000e+00\n",
            "7/7 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "print(\"Mean of MSE = \" + str(statistics.mean(MSE)))\n",
        "print(\"STDVE of MSE = \" + str(statistics.stdev(MSE)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sqj7J3p1Xjm",
        "outputId": "3aa5f711-cac7-4cd7-87b3-0db33cb82c21"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of MSE = 1529.1947844660197\n",
            "STDVE of MSE = 0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oe2C5jvxh7Pv",
        "676UIcVPikxN",
        "nm99uEWblOzi",
        "84fJ1pjds2s8"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}